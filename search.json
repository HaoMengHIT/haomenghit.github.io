[{"title":"论文阅读：Toward Fine-Grained Dynamic Tuning of HPC Applications on Modern Multi-Core Architectures (SC17)","url":"/2019/09/09/论文阅读：Toward-Fine-grained-Dynamic-Tuning-of-HPC-Applications-on-Modern-Multi-Core-Architectures-SC17/","content":"\n## 摘要\n\n人们一致认为，百亿亿次级系统应在20MW的功率范围内运行。因此，如果要实现这样的系统，节能仍然被认为是最关键的限制因素。\n\n到目前为止，大多数关于该主题的研究都集中在功率封顶和动态功率管理等策略上。虽然这些方法可以降低功耗，但我们认为它们可能不足以达到E级能效目标。因此，我们的目标是采用嵌入式系统的技术，其中能效始终是基本目标。\n\n嵌入式系统中使用的成功节能技术是将细粒度自动调谐与动态电压和频率调整相结合。在本文中，我们将类似的技术应用于实际的HPC应用程序。我们在HPC群集上的实验结果表明，与基线配置相比，这种方法可节省高达20％的能量，而性能损失可忽略不计。\n\n## 研究介绍\n\n为了提高能效，硬件供应商越来越多地采用嵌入式系统的技术。诸如去耦频域，动态电压和频率调节（DVFS），超低功耗状态以及融合CPU和FPGA的概念等特性表明了HPC和嵌入式系统正在融合的趋势。例如，最新一代的英特尔至强CPU不仅通过采用额外的内核或更宽的寄存器来提高性能，而且还包含一系列用户可控的开关[16,19,28]。访问这些开关使用户能够影响CPU的能量特性。在Haswell-EP和后续架构中，程序员可以操纵单个核心频率和非核心频率，即将核心连接到存储器控制器的环的频率[16]。这些用户可控制的硬件开关是嵌入式系统中节约能源的有效来源，而且它们越来越多地涌入HPC，这就引出了如何利用它们来提高能效的问题。\n\n为了回答这个问题，我们研究了嵌入式系统，其中代码级的细粒度自动调谐与用户可控开关紧密集成已得到广泛研究。一个例子是System-Scenarios [10]，其中创建了高度调整的系统配置，以便将底层硬件架构映射到应用程序行为。其他示例包括自我感知计算系统[18]和基于观察 - 决定 - 行为原则的系统[29]，其中系统监视器为给定行为选择最佳硬件和软件配置。\n\n无论采用何种方法，共同点都是平衡多种约束（如性能和能量）的任务。虽然这些方法中的一些被证明在嵌入式系统或其他领域中是成功的，但很少有应用于典型的HPC应用。因此，由于基本目标不同，无法保证这种方法在性能优先的环境中起作用。嵌入式系统通常在实时处理所需的期限限制下工作，而在HPC中，必须最小化解决方案的时间。\n\n在本文中，我们将细粒度自动调整与用户可控制的硬件开关和线程相结合，并将此技术应用于单个计算节点上的真实HPC应用程序。该应用程序反复求解弹性波方程，以创建地球地下的地震图像。它主要受存储器限制，这使其成为具有去耦频域的CPU节能的良好候选者，其中核心频率可以按比例缩小以节省能量。\n\n为了评估我们的方法，我们针对以下三个目标调整我们的应用：能量，能量延迟乘积（EDP）和能量延迟乘积平方（ED2P）。我们的总体结果显示，与参考实现相比，节能高达20％，运行时间仅增加3％。\n\n因此，我们在本文中的主要贡献是：\n\n* 我们实施并测试了一种受嵌入式系统启发的节能方法，该方法将细粒度自动调谐的优势与用户可控制的硬件开关结合在一个计算节点上的实际HPC程序中进行应用。\n* 我们提供实验结果，并将参考实施方案与静态和动态调整的版本进行比较。\n* 我们评估了我们的方法在能耗-性能权衡方面的可行性。\n* 我们提供了启用和不启用AVX2矢量化的测试应用程序的能量结果。\n\n本文中描述的工作是在READEX项目的背景下进行的，该项目旨在利用运行时的动态应用程序行为来实现节能的E级计算。\n\n## 研究背景\n\n本节简要概述了最先进的自动调节器，一些现代x86 CPU上的用户可控硬件开关，以及不同的能效指标。\n\n#### 现有的自动调优\n\n自动调节器的主要目标是通过找到给定系统的调节参数的最佳组合来优化应用。调整参数的典型示例是编译器选项、环境设置和特定于应用程序的参数。在自动调整的上下文中，应用程序的生命周期通常在设计时和运行时中分开。实际的调优过程要么在设计时进行，要么在执行应用程序之前进行，要么在运行时进行，即在执行期间进行。这分别称为离线和在线调整。一些自动调优器支持这两种方法。\n\n此外，自动调优器还可以提供静态或动态调整的支持。在前者中，为整个应用程序确定调整参数的最佳组合，而后者允许在运行时调整参数更改。通常，这需要将应用程序分解为更小的区域，从而实现细粒度调整。\n\n自动调调优器的一个关键假设是，调整所花费的时间和精力由生产运行分摊。因此，长期运行的科学应用，例如天气模拟或地震建模，是自动调优器的理想目标应用。自动调优器的调研见第3节。\n\n#### 用户可控的硬件开关\n\n动态电压和频率调节（DVFS）是一种常用的节能方法。在DVFS中，通过降低时钟频率实现节能，这会自动导致电源电压降低。\n\n最近基于英特尔Haswell、Broadwell和Skylake架构的CPU除了提供传统的核心频率扩展外，还提供用户访问非核心频率调整（UFS）的功能。此外，这些CPU允许更改单个内核的频率，提供精细的粒度级别。对于Haswell CPU，每个内核的转换延迟为20μs。然而，由于存在切换窗口，实际切换时间实际上可达500μs。我们的测量表明，核心转换延迟均匀分布在100-600μs之间，证实了[16]的发现。我们发现UFS的转换延迟接近20μs，这与[12]中给出的数字相同。\n\n通过基于温度、工作负载和空闲核心的数量监视启发式，CPU可以自动地将核心和非核心频率增加到超过其基频。这被称为睿频加速（turbo boost）[17]，并且频率可以增加到最大超频。但是，AVX2矢量化代码使用消耗更多功率的AVX2单元，如果CPU以其基频运行，则会超过热设计功耗（TDP）。在这种情况下，CPU会忽略高于可保证频率的请求。表1显示了在我们的实验中使用的CPU在有和没有AVX2的不同turbo频率。为了用户选择的核心和非核心频率之间的可重复性和相关性，我们仅在保证频率的范围内运行。\n\n","tags":["Papers","Energy Modeling","SC"]},{"title":"论文阅读：Energy-Aware High-Performance Computing: Survey of State-of-the-Art Tools, Techniques, and Environments (综述， Scientific Programming 19)","url":"/2019/09/04/论文阅读：Energy-Aware-High-Performance-Computing-Survey-of-State-of-the-Art-Tools-Techniques-and-Environments-综述，-Scientific-Programming-19/","content":"\n## 摘要\n\n本论文介绍了能量感知高性能计算（HPC）的最新技术，特别是系统和设备类型、优化指标和能量/功率控制方法的方法识别和分类。系统类型包括单个设备，集群，网格和云，同时考虑设备类型包括CPU，GPU，多处理器和混合系统。优化目标包括各种指标组合，如执行时间，能耗和温度，并考虑强加的功率限制。控制方法包括调度，DVFS / DFS / DCT，功能封顶与程序化API，如英特尔RAPL、NVIDIA NVML以及应用程序优化和混合方法。我们讨论用于能源/电源管理的工具和API以及用于预测的工具和环境和/或者模拟现代HPC系统中的能量/功耗。最后，讨论了编程实例，即在特定工作中使用的应用和基准。根据我们的评估，我们确定了一套开放领域以及有关现代HPC系统方法和工具的重要最新问题，这些方法和工具允许进行能量感知处理。\n\n## 研究背景\n\n在当今的高性能计算（HPC）系统中，对能量和功率的考虑起着越来越重要的作用。新的集群系统设计为在不超过20兆瓦的功率[1]达到百亿亿次级的性能。除了TOP500（ https://www.top500.org/lists/top500/ ）以性能为导向的排名，Green500（ https://www.top500.org/green500/ ）列表按每瓦特性能对每台计算机进行排名。GPU的广泛采用有助于提高可在此类系统上高效运行的应用程序的这一比率。这种混合系统中的编程和并行已经成为获得高性能的必要条件，但在使用多核和多核环境时也是一个挑战。在功率和能量控制方法方面，除了调度之外，DVFS/DFS/DCT和功率封顶API已经可用于移动、台式机和服务器中的CPU和GPU。功率封顶现在也可用于集群的作业管理系统，例如Slurm中允许关闭空闲节点，在需要时再次启动这些节点，允许我们设置通过DVFS使用的功率上限[2]。对于各种应用，诸如执行时间、能量、功率和温度的度量在各种上下文和各种组合中使用。需要对该领域的可能性、机制、工具和结果进行持续和彻底的分析，以确定当前和未来的挑战，这是这项工作的主要目标。\n\n## 综述总结\n\n最后，基于论文中的研究，我们可以为研究制定开放的研究领域，这对于能源感知高性能计算领域的进一步发展至关重要：\n\n* 表1中列出了用于能源/电源管理的各种HPC工具，表明需要统一不同供应商提供的各种API，以提出跨越可用HPC计算设备如多核CPU，GPU和加速器的统一功率感知API。支持与功率/能量以及性能测量和管理相关的通用参数的通用子集。\n* 表8中显示的当前使用的预测和模拟工具的可用性、精度和性能，在它们支持特定计算环境（表2）、设备类型（表3）和使用的指标的背景下，进一步显示需要为各种应用程序的各种CPU和GPU架构开发（可能是经验的）性能 - 能量模型（例如，表7中描述的那些），包括功率限制下的性能模型，可用于运行时使用以及模拟器环境。\n* 从表6中得出结论，我们可以认识到几个关于能量感知HPC领域的开放式研究方向，这些方向仍需要进一步发展：\n  * 用于混合（CPU +加速器）系统的能量/功率感知方法；\n  * 利用任何能量/功率控制方法进行优化，旨在最小化能耗和执行时间的积；\n  * 使用混合能量/控制方法来实现能耗和能源-时间积的最小化；\n* 最后，表5中给出的能量/功率控制方法的分析使我们得出以下结论：\n  * 需要开发用于自动配置包括功率上限的HPC系统的工具，用于关注性能和能量消耗并且可用于各种并行编程API的各种应用类别。虽然存在选定类别的应用程序和使用MPI的方法（例如，[65]），但是没有能够适应各种应用程序API的通用工具。这些工具可以使用上一步中提出的模型，并根据性能 - 能量曲线检测应用程序并将其分配给所选类别之一；\n  * 在运行时针对混合（CPU +加速器）应用的性能和能量自动配置HPC系统，其中计算的卸载可以被调节，这不仅取决于计算的时间而且取决于功率/能量约束。\n  * 进一步开发和验证当前现有的工具，重点关注能源/电源管理领域，包括功能扩展和质量改进，例如AMD的应用电源管理TDP Power Cap工具或IBM EnergyScale功能的验证。\n\n\n\n","tags":["Papers","Energy Modeling"]},{"title":"Writing for Computer Science (Third Edition)— Chapter 3","url":"/2019/08/31/Writing-for-Computer-science-Third-Edition-—-Chapter-3/","content":"\n## Chapter 3 Reading and Reviewing （阅读和审阅）\n\n新手研究人员可以相信，研究的主要内容包括运行实验、发展理论或进行分析。但是，凭借经验，研究人员发现了开拓理解（***developing an understanding***）的重要性。有人认为，许多实验研究人员在从事某一领域五年或更长时间后都会尽其所能，因为要深入、彻底地了解该领域、现有知识及其局限性需要时间。为了获得这种理解，你需要成为一个有效的研究论文读者。\n\n一个成功的读者可以在识别论文缺陷的同时，识别出论文的贡献和价值；并运用批判性审阅来识别论文中缺陷的严重程度。然后，这篇论文将直接作为知识的来源，间接地作为指导如何创造出值得赞赏的作品，为新作品提供信息。此外，阅读的一个特殊应用是成为一名可靠的审阅人或毕业论文审阅者。本章是关于阅读和审阅的，它是对有效阅读要素的介绍、也是审阅的指南。\n\n论文审阅是科学过程的核心部分。对其他科学家撰写的论文的批评和分析是识别良好研究和消除不良研究的主要机制，可以说与研究本身一样重要。很多人都被审稿的任务所吓倒，也许是因为它是一种智力测试：要求你对别人工作展现出一种透彻的理解。它也是令人生畏的，因为它带来了责任;你既不要错误地批评扎实的工作，也不想建议发表有缺陷的研究。然而无益的是，审稿的质量是高度可变的。大多数研究人员都有一些好的研究工作被拒绝的经历，仅仅只有几句仓促的解释，或者审稿人根本没有阅读过该工作。\n\n审稿可能是一件苦差事，但与其他任何研究活动一样，应该付出同样的努力、关心和道德标准。除了编辑和作者的感激之外，它还有回报。它可以引导你从一个全新的角度看待你自己的作品，并使你暴露在不同类型的错误或研究失败中——提交出版的作品的平均工作标准远低于已出版的作品。并且，虽然你可能不会被要求作为你研究的一部分来评判一篇论文，但是你自己的工作将被审阅或检查，因此本章提供了一个关于预期提交论文标准的观点。\n\n#### Research Literature （ 研究文献）\n\n当你的研究完成时，你需要确信你已阅读并理解与你的工作有重大联系的所有科学文献。你的阅读达到了几个目的。它证明了你的工作确实是新颖的或创新的;它可以帮助你了解当前的理论、发现和争论;它可以确定新的质疑或调查路线;它应该为你的工作提供不同的视角。此阅读最终将在背景部分和你撰写的相关工作的讨论中进行总结。\n\n您的作品所依赖的文献通常被认为是在一个声誉良好的场所推荐和发表的论文、在一个声誉良好的机构中被采取和审查的论文，以及基于所述信息中提供的信息的书籍。这些文件被研究界接受为知识的来源;实际上，它们可以被视为我们科学知识的整体。文献中不包括实验室笔记、调查回复或实验输出等主要来源。这些缺乏的内容是根据特定假设对内容的解释。例如，其他文献，包括新闻文章，科学杂志，维基百科页面或文档 - 可能会提醒您存在信誉良好的作品，但很少值得引用。也就是说，你的学习可能建立在更广泛的文献之上，但是你的写论文中的论据应该基于来自推荐来源的知识基础上。\n\n对文献的深入研究很容易发现数百篇潜在的相关论文。但是，论文不是教科书，不应该被当作教科书来对待。研究人员阅读论文不是为了考试而学习，很少需要理解每一行。从事某一特定项目的研究人员必须熟悉的论文数量通常很少，即使研究人员为了确定其相关性应该阅读的论文数量很大。\n\n因此，重要的是要成为一个有效的读者，通过给予每篇论文不多也不少的时间。当你第一次阅读一篇论文的时候，浏览它以确定它的相关程度 - 如果论文有价值的话，请仔细阅读。努力正确理解细节，但要时刻注意可能有错误或混淆的细节。\n\n期望有一系列的阅读模式：浏览寻找论文，了解论文工作概况，了解工作中的主要成果;论文和主流科学杂志的背景阅读;以及全面、集中地阅读能够拓展你能力或你理解的极限的论文。但是，不要让阅读发展成一种拖延形式，它需要成为生产性工作周期的一部分，而不是占主导地位的时间使用。\n\n#### Finding Research Papers (查找研究论文)\n\n每个研究项目都建立在以前的工作基础之上。做和描述研究需要全面了解他人的工作。然而，每年在主要计算机科学场所发表的论文数量至少达到数万篇，这一数量令人望而却步。\n\n值得安慰是，在一个活跃的领域，其他研究人员已经在一定程度上探索和消化了旧的文献。他们的工作为早期研究提供了指导， 因此很少需要对文献进行彻底的探索。但是，这也是仔细搜索当前工作的另一个原因。而且要注意：阅读一篇看似相关的论文绝不能代替阅读论文本身。如果你需要讨论或引用一篇论文，请先进行论文阅读。\n\n对相关文献的全面探索涉及以下几条相互关联的路径：\n\n* 使用明显的搜索词来探索Web。你可能会发现，不仅仅是论文，还有与同一研究领域相关的项目和团队的主页。你也可能会找到提供更有价值的搜索词的文档。在你的搜索结果中检索;有时一个领域的研究被分成不同的社区，他们有不同的词汇表。\n* 一些主要的搜索引擎具有专门用于学术论文的搜索工具。这些可以按个人，机构和引文进行索引。它们是今天找到相关工作的最有效方法。\n* 访问本领域工作的研究小组和研究人员的网站。这些网站应该会提供相关文献的链接：你应该调查他们团队研究人员的名字，他们的共同作者的名字，相关工作出现的会议，以及列有参考文献的论文。\n* 跟进有前景的研究论文中的参考文献。这些包括相关的个人、会议和期刊。\n* 浏览该领域最近的期刊和会议论文专辑;搜索可能包含相关论文的其他期刊和会议。\n* 搜索特定出版方的数字图书馆。其中包括Wiley和Springer等出版商，以及ACM和IEEE等专业协会。还有各种各样的在线档案，特别是 www.arXiv.org。\n* 大多数会议都有列出论文大纲的网站，即当年会议接受的论文。在会议中，论文通常按主题分组。\n* 考虑使用引文索引。传统的印刷引文索引已经迁移到网络上，但实践中，它们对计算机科学的价值是有限的，因为只有一小部分出版物包含在内。\n* 去图书馆。将类似材料搁置在一起的简单策略通常会导致意外的发现，而不会在浏览网页时产生分心。\n* 与尽可能多的人讨论您的工作。他们中的一些人可能很了解你没有遇到的相关工作。类似的问题经常出现在不同的研究领域，但和其他领域出现一样的困难 - 这种现象有时被称为“在孤岛中工作” - 意味着调查相似问题的人可能彼此不知情。\n\n搜索和发现有用论文的过程可以被认为是一种学习形式。您找到的每篇论文或页面都应该完善你对术语的理解，帮助指出哪些论文是重要的，建议新的跟进方向，并进一步阐明论文是“进入”还是“出局”的标准。\n\n有时候，同一篇论文会有多个版本：在线档案中的预印本、会议版本和期刊版本。你应该使用作者认为具有权威性的版本;这通常是发表在期刊上的精雕细琢的作品。\n\n在寻找论文时，要对“相关”有一个广义的定义。这不仅仅意味着那些提出竞争方法的论文。该论文是否对其他研究文献有了有趣的见解？它是否建立了基准？作者是否找到了一种巧妙的方法来证明一个可以在你自己的工作中应用的定理？该论文是否证明了不进行某些特定调查的决定是正当的？其他人的研究可能会对你的工作产生许多不同的影响。\n\n找到所有相关工作很难;例如，对医学研究文献进行详尽的专业搜索可能需要数月的全职工作。但是，找到所有重要的工作是进行研究的关键部分。只有当你完成了研究的调查阶段并起草了一份好的文献综述草稿后，与你相关的文献范围才会变得明显。在你的研究过程中，你的主题和兴趣可能会转移、集中或扩大，你的观点也会随着你的理解的发展而改变——随着你的学习更新你的搜索。\n\n搜索和阅读是独立的活动，尝试同时执行这两项操作是错误的。我建议您不加批判地收集材料，然后进行批判性分析和分类。将您找到的论文保存到目录中，稍后再浏览以了解您找到的内容。在单个搜索会话的上下文中，将注意力限制在一个或两个特定主题上也很有帮助。\n\n在搜索完文献之后，你可能会发现你最初的想法并不是那么新颖。如果是这样，请诚实地审查您的工作，看看哪些方面可能是新颖的，但不要欺骗自己去处理已经解决的问题。例如，有时也会发生这样的情况：在相当长的一段时间内，其他几个团队对同一个问题进行了调查。同时，其他人也在解决同一个问题，这并不意味着不可能在该领域做出进一步的贡献。\n\n#### Critical Reading （批判性阅读）\n\n阅读的主要目的是培养批判性思维能力。优秀的研究人员必须证明他们有能力客观地分析他人的工作和主张。有了经验，你可以把每一篇论文放在你所知道的其他工作的背景中，并根据一系列的特点对其进行评估。\n\n通过这样做，您将对常见错误和虚假主张保持警惕。研究文献的挑战在于是否相信你所读到的内容。在信誉良好的期刊或会议上发表的作品经过同行评审;网上可获得的作品可能有任何历史，从已接受期刊论文的预出版版本到非英文原文翻译得很糟糕的抄袭作品。一个玩世不恭但经常准确的经验法则是，超过一年或两年的作品尚未在重要场所发表，可能存在一些严重的缺陷。当你在网上找到一篇论文的版本时，请确定它是否已在某个地方发表过。使用诸如作者其他出版物质量等证据来确定它是否是严格研究计划的一部分。\n\n许多研究具有一定的误导性。人们研究已经被解决和理解地很好的问题，或者解决技术无关的问题，或者没有意识到所提出的改进方案实际上使方法变得更糟。数学方面的利用可能毫无意义;可能证明错误的性质，例如复杂性而不是正确性;所用的假设可能不可信;评估策略可能没有意义。使用的数据集可能非常小，结果毫无意义。这些结果显然是错误的。而且，虽然论文被评审的事实是一个有价值的指标，但它并不是一种保证。许多人从事的工作不值得写，有时它也会被发表。\n\n实际上，很少有论文是完美的。它们是对新工作的介绍，而不是对众所周知的结果的深思熟虑的解释，写在截止日期的限制意味着错误是无法发现的，一些问题未被探索。一些老的论文的某些方面可能会被取代或不相关，或者可能依赖于有限或技术上过时的假设。一篇论文可以被视为研究项目的快照，这和研究人员在提交时所发现的内容有关。由于所有这些原因，读者需要质疑、平衡和怀疑。简而言之，不要因为它被发表而接受论文内容是对的。但这并不能证明研究人员对过去的工作不屑一顾;相反，他们应该尊重并从中学习，因为他们自己的工作可能有类似的优点和缺点。一些缺乏经验的研究人员将其他工作视为完美或毫无价值，这些极端方式都是不正确的。\n\n虽然许多论文可能存在缺陷，但它们定义了科学知识。(与此相反，教科书通常是旧的、已确立的、不再处于前沿的工作的整合。）如果许多研究人员相信某篇论文，对其结果持怀疑态度仍然是合理的，但这需要与以下事实相平衡：如果怀疑是合理的，那么其他研究人员都错了。\n\n通过提出论文的关键问题来阅读论文，例如：\n\n* 论文是否有贡献？研究内容是否很重要？\n* 有没有感兴趣的贡献？\n* 结果是否正确？\n* 是否讨论过适当的文献？\n* 该方法实际上是否回答了最初的问题？\n* 是否批判性地分析了方案和结果？\n* 从结果中得出适当的结论，还是有其他可能的解释？\n* 所有技术细节都是正确的吗？它们是合理的吗？\n* 结果可以验证吗？\n* 是否有任何严重的含糊不清或不一致？\n\n也就是说，积极尝试找出贡献和缺点，而不是简单地从一端读到另一端。对论文的分析可以被认为是验证每个组件是否是健壮的。如果论文对你的工作很重要，你应该对其进行分析，直到你对其每个组成部分形成合理的观点;如果某些组成部分有问题，这应该反映在您的文献综述中。\n\n写下你对论文的分析 - 你将阅读数百篇论文，在某些情况下，在几个月或几年后才能正式描述它们。但是，在你开展自己的工作之前，进行详细的分析可能会很困难，因此形成一个成熟的视角。因此，文献回顾不应在调查开始时停止，而应与研究一起继续。\n\n#### Developing a Literature Review (建立文献综述)\n\n文献综述是对一组文献的结构化分析，可能涵盖多个独立研究领域的工作。这篇评论不仅仅是这些论文的列表。相反，论文应该按主题分组，并以一种能够让读者理解他们对该领域的贡献、局限性以及他们留下来的问题的方式进行批判性讨论。\n\n为论文撰写文献综述的任务可能具有挑战性，因为这种论文比任何其他单一活动都更为艰巨。因此，逐步开展审查是很有意义的。\n\n一旦开始阅读，就开始粗略的文献审阅，当你阅读一篇你认为需要讨论的论文时，将其添加进去。（你还应该在阅读过程中捕获书目数据，并保存你阅读的每一篇论文的副本。）最初，文献综述将是粗略和非结构化的，但是当您添加论文时，你可以按主题和贡献对它们进行分组，并在每篇论文中添加注释以及它们如何相互关联。简要总结每篇论文的贡献和用于支持这些主张的证据，并且还要注意任何感兴趣的缺点或特征。你可能还需要注意，为了你自己的参考，如何更好地完成工作：例如，是否有应该尝试的明显实验，或者说是合理的反驳？请记住，你对其他工作的理解有助于审查员判断你作为研究人员的能力。\n\n没有必要对你的文献综述的草稿进行完善 - 很可能除了你自己之外没有人会读到这些早期版本 - 所以可以认为这是写给未来自己的一封信。也就是说，在这个阶段，您应该专注于组织和内容而不是演示。只有在您的研究完成后，才能以一种集中的方式完成并产生最终文献综述的重写、编辑和润色。\n\n随着你的综述的进行，你将更容易决定是否包含你阅读的每篇论文。许多明显的因素将指导你的决策：其他一些工作与您的关系有多接近，或者它的影响力如何。有些因素可能更微妙。例如，你可能会发现一份调查论文，或者一篇最近发表的论文，对其本身进行了全面的文献综述，这意味着很多旧论文都不需要讨论;一些最初似乎很重要的论文可能在反思后看起来不那么相关，可以放在一边或简单提一下;虽然最初似乎过于理论化或抽象化的论文可能会在进一步研究中被选为基础性的工作。\n\n我建议你在早期的草稿中尽可能地包容。当您删除对一篇论文的讨论时，把讨论放在另一个文件中（或将其注释掉）而不是完全删除它，因为此文本是您阅读论文的记录。\n\n#### Author, Editors, and Referees (作者，编辑和审稿人)\n\n当作者完成一篇论文时，会将其提交给期刊的编辑（或会议的主持人）进行发布。编辑将论文发送给评审论文并返回评估的审稿人。然后编辑使用这些评估来决定是否应该接受该论文，或者，如果是期刊论文，是否需要进一步审阅或修订。\n\n在撰写论文时，作者应该诚实，道德，谨慎。最终由作者而不是期刊编辑或审稿人负责确保论文内容的正确性。除非另有说明，否则作者有责任确保论文描述符合适当的标准，并且是他们自己的作品。\n\n审稿人应公平客观、保密、避免利益冲突。此外，他们应该及时完成论文审阅，声明他们作为审稿人的限制，在评估论文时要小心谨慎，并且只有在他们确信论文满足足够的标准时才建议接受。虽然审稿人一般可以假设作者在道德上表现得很好，但很多提交的论文创新点弱或者有一定的缺陷，在这些论文上花费了大量时间来审阅 - 部分原因是因为他们经常在拒绝后重新提交。此外，因为一些表面上的原因，如好的写作、令人印象深刻的数学或作者的声望，如果审稿人认为一篇论文是正确的、有趣的，这是疏忽大意的。\n\n编辑的职责是适当地选择审稿人，确保论文审阅及时完成并达到适当的标准，在审稿人的评价不同或作者认为审稿人的评价不正确时进行仲裁，并使用评论来决定是否应该被接受。\n\n这些论文作者的观点是截然不同。在提交时，作者可能会认为这项工作非常出色并且完善，而且很可能对批评很敏感。即使不是在一流研究中心环境中工作的研究人员，或者从未接受过更有经验的研究人员指导的研究人员，也可能确信他们的论文非常出色并且负面评论是错误的。其结果是，他们可能只做最小的改变，寻求解决审稿人提出的问题的方法，因此需要通过令人信服的论据来说服他们认为审稿人的观点是合理的。\n\n相比之下，审稿人和编辑可能会感到不兴奋（大多数提交被拒绝），并且不相信提交的材料，强烈的结果通常是错误的。在这种情况下，他们也可能对典型的、令人沮丧的错误敏感，也可能对作者在评审意见中对自己作品的不当批评敏感。在某种意义上，审阅过程可以看作是协调这些不同观点的机制。\n\n#### Contribution （贡献）\n\n贡献是判断论文的主要标准。从广义上讲，如果一篇论文有两个属性：原创性和有效性，那么它就具有贡献。\n\n论文的原创性是所提出的想法具有重要性、新颖性和趣味性的程度。大多数论文在某种程度上是对以前发表的作品的延伸或变化;真正具有开创性的想法很少见。尽管如此，有趣或重要的想法比现有工作的微不足道的增量更有价值。决定是否有足够的原创性来保证发表是审稿人的主要任务。只有一篇真正优秀的描述，写得很透彻，写得很好，尽管是一些边缘性新思想论文也能被录用，而一篇开创性的论文在某些方面必须令人无语的程度，才能被拒绝。\n\n在评估贡献的重要性时，考虑其影响力是有帮助的：即，判断出版和论文被广泛阅读将会产生多少变化。如果唯一可能的影响是来自该领域的一些专家的兴趣，那么该论文就是微不足道的。另一方面，如果可能的影响是实践的广泛变化或来自其他研究人员的一系列有趣的新结果的产生，那么该论文确实是开创性的。\n\n一些想法虽然是显而易见但并不会减损它们的原创性。回想起来，很多优秀的想法都是显而易见的。此外，一篇陈述很好的论文中的想法往往看起来不像一篇报道不好的论文那么复杂，仅仅因为前者的作者有更好的解释诀窍。这明显不是拒绝论文的理由。真正的成就可能是首先提出正确的问题或以正确的方式提出问题，即注意到问题的存在。以新的方式或在替代框架内组织现有的想法也可以是原创的贡献，也可以重新评估现有的想法或方法。\n\n论文的有效性是这些想法被证明是合理的程度。仅仅凭直觉就认为提出的方案应该成立的论文是无效的。良好的科学需要以允许其他科学家验证的形式证明正确性。如第4章所述，这种演示通常是通过证明或分析、建模、模拟或实验，或者最好是这些方法中的几种，并且可能涉及到与现有想法的某种比较。\n\n在算法领域，证明和分析是证明一个方案是有价值的公认方法。理论和数学分析的运用是计算机科学的基石之一：计算机技术是短暂的，但理论结果是永恒的。然而，它们的耐用性创造了对确定性的需求：不可信的分析是没有价值的。因此，一篇报告实验工作的论文可能是一项重大贡献。为了引起足够的兴趣，这个实验应该测试以前没有经过经验检验的行为，或者与“已知的”结果相矛盾。\n\n无论是通过理论实验，有效性的证明都应该是严格的：仔细描述，透彻，可验证的。评估算法的实验应基于良好的实现；基于受试者统计测试的实验应使用足够大的样本和适当的对照。与现有工作的比较是证明其有效性的重要组成部分。一种不如现有替代方案的新算法不太可能具有重要意义。\n\n#### Evaluation of Papers （论文评估）\n\n评估论文的过程包括提出关键问题，如本章前面“批判性阅读”中列出的问题。此外，还有更多的问题需要问一篇正在审阅的论文，它不仅应该是正确的，而且应该适合可能的读者。\n\n* 这一贡献是及时的，还是只具有历史意义？\n* 该主题是否与领域的典型读者群相关？\n* 论文欠缺什么？什么会使论文描述更完整？是否有必要增加其他材料？\n* 可能的读者人数有多广？\n* 可以理解论文吗？它写得清楚吗？演示文稿是否符合标准？\n* 内容是否符合长度要求？\n\n其中，贡献是最重要的组成部分，需要进行价值判断。批判性分析的存在也很重要：作者应正确识别其工作的优点、缺点和影响，而不是忽视问题或缺点。当他们以公正的方式描述结果时，更容易信任结果。\n\n大多数论文都有一个明确或隐含的假设。试着找出假设是什么：如果你不能识别它，可能有些不对劲，如果可以，它将帮助你识别所有论文是否与假设相关，以及是否缺少重要材料。\n\n论文的质量可以反映在其参考文献中。例如，有多少参考文献？这是一个粗略的经验法则，但通常是有效的。对于一些研究问题，只有少数相关论文，但这种情况是例外。只有少数参考文献的存在可能是论文质量差的证据。此外，一些作者引用了相当数量的论文而没有实际引用相关文献，从而掩盖了参考文献少的事实。如果许多参考文献都是作者的，那么可能有些参考文献是多余的。如果近期的参考文献比较少，那么作者似乎并不熟悉其他研究。同样，对没有提及该领域主要期刊或会议的论文持怀疑态度。期望作者通过正确的引文提供新颖性和创新性的证据。\n\n有时，作者提交的论文严重不完整。没有努力找到相关的文献，或者只是粗略的校样，或者很明显论文从未被校对过，或者在极端情况下，论文只是概述了基本思想。这样的作者或许想证明一个想法是他们自己的，而不必费劲去证明它的正确性，或者只是厌倦了工作，希望审稿人自己理解具体的细节，而不必没有费心解释。这些论文不值得进行彻底的评估。但是，不要草率地将论文判断为此类别。\n\n审稿人应努力寻找不影响论文质量但应在出版前前予以纠正的错误。这些包括拼写和语法、书面表达、参考文献中的错误、是否定义或解释了所有概念和术语、任何公式或数学中的错误以及从变量名到表格布局到参考文献格式的任何内容的不一致。如果论文要出现在期刊上，在排版过程中可能会出现一些这类的错误，但其中很多错误都不会出现。尤其是，只有审稿人才有可能发现的数学上的错误。\n\n这些错误可能会成为更严重的缺陷，可能会使论文无法接受。例如，可以预期数学中会出现一些印刷错误，但如果下标混淆或符号不断变化，则作者很可能没有仔细检查结果;那么该论文很可能被拒绝接受并期望作者在再次提交之前对其进行审阅，这也是合理的。\n\n类似的论据也适用于这种陈述：在某种程度上，可以接受写得不好的论文（但是很不情愿），但是在陈述中不足才是拒绝的理由，因为如果一篇论文无法被阅读就没有价值。但请注意，反过来并不适用：优秀的陈述并不能成为接受的理由。有时，审稿人会收到一份写得很好的论文，并在给出审阅结果的过程中表现出真正的兴趣，但仅仅是复制现有的工作。遗憾的是，这些论文必须被拒绝。\n\n对于一些论文来说，一个困难的问题是，是建议彻底拒绝还是建议在重大修改后重新提交。后者意味着，在不超过合理数量的额外工作的情况下，该论文可以达到可接受的标准。该建议不应被用作“软拒绝”的一种形式，以不伤害作者的感受或其他一些类似的感受，同时要求实际上不可能完成的修改；最终的接受（可能在多轮审阅后）通常是此类建议的最终结果。如果使论文工作达到可接受的标准将涉及大量的额外研究和写作，则拒绝是适当的。这一裁决可以通过其他方式软化，例如建议在解决问题后重新提交该文件。\n\n作为同行评审系统的结果，活跃的研究人员应该期望审阅的论文数量是他们提交的论文数量的两到三倍（或者如果他们的论文通常是共同撰写的话，则会少一些），只有在有充分理由的情况下才拒绝对论文进行评判。对于许多论文，可能没有审稿人是该领域的真正的专家，所以即使你自己对论文的判断没有信心，也要准备好审阅。总是要陈述你作为审稿人的一些限制 - 例如，您不熟悉该领域的文献，或者无法检查某些证据是否正确。也就是说，你需要承认自己的无知。最终，如果论文在某些方面不符合标准，审稿人不应建议接受。 审稿人有责任对论文进行全面评估。\n\n#### Content of Reviews（论文审阅的内容）\n\n审阅论文有两个目的。直接的目的是它是编辑用来决定是否应该接受论文发表的机制。隐含的目的，也同样重要且经常被忽视 ， 是通过对作者的评论，是科学家之间分享专业知识的一种手段。除书面评论之外，评论通常包括其他内容（例如某些标准的分数，用于确定是否应该接受论文），作者可以从这些评论结果中发掘有价值东西。评论应该对论文提出某种具体问题：它是否满足相应的标准以及它的缺陷是什么。也就是说，它是对论文的分析，解释了为什么它适合或不适合出版。\n\n衡量审稿人评论的标准主要有两个：\n\n* 是否对该论文的反对令人信服？\n\n  在建议接受论文时，必须说服编辑认为它足够符合标准。简短而肤浅的评论，没有讨论该论文的细节，会引起编辑对该论文未经过仔细审查的怀疑。好的评论不应只是文章的摘要; 它应该包含一个明确的声明来说明你认为的贡献。\n\n  在建议拒绝论文时，应提供对论文问题的明确解释。例如，仅仅在没有参考和解释的情况下声称作品不是原创作品或者之前已经完成的工作是不合理的 - 如果没有提供证据，作者为何应该相信这样的评判？他们花了相当长的时间来开展和展示他们的研究工作，很少有作者会被一些轻蔑的评论说服而放弃它，相反，他们会在不做修改的情况下重新提交到其他地方。\n\n* 是否对作者进行了足够的引导？\n\n  当建议接受某篇论文时，审稿人应该描述为修复剩余的错误或以任何方式改进论文所需的任何变化——技术上、风格上，无论怎样。如果审稿人不建议这样的改变，他们就不会被改变。\n\n  \n\n  当建议拒绝某篇论文时，审稿人应该考虑作者下一步可能做些什么 - 他们如何从被拒绝达到到良好的研究。有两种情况。一个是该论文有一些有价值的核心内容，通过进一步的工作，将是可以接受的。审稿人应强调该核心内容，并至少用一般术语解释作者应如何改变和改进他们的工作。另一种情况是，该工作没有任何有价值的内容，在这种情况下，审稿人应该向作者解释如何得出相同的结论。由于论文陈述中的缺陷，审稿人有时无法判断是否有有价值的内容。通过列出作者应该考虑的问题等方式，有助于向作者解释他们如何判断自己研究工作的重要性。\n\n应该遵守这些标准的原因有很多。科学界以合作精神为荣，正是本着这种精神，审稿人应该帮助其他人改进他们的工作。不好的评审，尽管节省了审稿人的工作量，但是对于整个研究界来说，如果一篇论文的缺点没有得到充分的解释，那么如果论文被重新提交，它们仍然存在。最重要的是，糟糕的审查是自我强化的，对科学标准不利。它创造了一种对其他人的工作缺乏检查的文化，并最终削弱了对已发表研究的信心。\n\n在建议接受的评审中，没有进一步的机会纠正错误。审稿人是最后一位在论文出版前仔细检查论文的专家。如前所述，只有拼写和标点符号等明显错误可能会在以后被发现，审稿人应该检查论文内容是否基本正确：没有明显的数学错误，证明中没有逻辑错误，没有错误的实验结果，参考文献没有问题，没有虚假或夸大的主张，也没有严重遗漏重要信息或包含无关文本。\n\n在建议拒绝或实质性修订的评论中，这种细粒度检查并不重要，因为（大概）该论文包含某种严重错误。尽管如此，如果只是为了防止一个周期的纠正和重新提交，每次只解决几个问题，那么一定程度的谨慎是必不可少的。欢迎对改进论文有具体、明确的指导。但是不要为作者做研究。如果研究工作做的不好，退后一步;如果研究工作做的好，就不需要你的贡献;如果简单的改变会产生真正的影响，建议他们，但完善内容是作者的工作。\n\n#### Drafting a Review （起草评审意见）\n\n对论文的第一印象可能会产生误导。我的审阅过程是阅读论文并做出边注，然后决定是否应该接受论文，然后将评论写给作者。但通常情况下，即使在最后阶段，我对论文的看法也会发生变化。也许一个看似次要的问题被揭示为一个主要的缺陷，或者论文的深度变得更加明显，因此它具有比看起来更重要的意义。经验教训是，审稿人应该随时准备改变他们的想法，而不是过早地对某个特定的观点做出承诺。\n\n另一个教训是，积极因素与消极因素同样重要：评论应该是建设性的。例如，在审查过程中，有时可以代表作者匿名加强论文。审阅过程可以很容易地包括错误查找，但是对于作者来说，了解他们论文的哪些方面是好的以及哪些方面是坏的是很有价值的。好的方面将构成论文重新修改的基础，因此应在审阅中加以强调。\n\n有些裁判员认为论文中没有瑕疵。例如，评估可能包括一般性的陈述，这些陈述几乎可以与论文主题无关，例如关于文档处理的论文中的“作者没有考虑并行架构”。其他的例子是一些含糊不清的抱怨，比如“问题本可以被更深入地调查”或者“问题的某个方面没有被考虑”。这种评论表明，审稿人没有进行公证的评价。如果有真正的问题，最好用例子来描述，否则什么也不说。\n\n审稿人应提供明显或基本的被遗漏的参考文献，但不应让作者不必要地寻找论文，特别是当他们很难找到的时候。推荐接受的审稿人至少要对相关文献有足够的熟悉，以便对新作品有合理的信心，并根据需要推荐参考文献。\n\n审稿人需要有礼貌。打破这一规则（特别是在评估一篇特别令人沮丧或考虑不周的论文时）很有诱惑力，进而态度傲慢、讽刺或进行彻头彻尾的侮辱，这样的评论是不可接受的。\n\n有些审查过程允许不被作者看到的机密评论。你可以用这些评论来强调你的评论的特定方面，或者，如果编辑要求一个分数而不是一个接受或拒绝的建议，明确说明是否应该接受该论文。您还可以使用此空间告诉编辑你自己一些限制。然而，由于作者没有机会对他们看不见的评论进行辩护，因此除了作者可见的评论之外，这里并不适合提出批评意见。\n\n#### Checking Your Review （检查自己的评审意见）\n\n当您建议接受论文时，您应该：\n\n* 说服自己该论文没有严重的缺陷。\n* 通过解释为什么它是原创的、有效的和清晰的来说服编辑认为它是符合标准的。\n* 列出论文出版前应做的主要和次要的更改，并在可能的情况下，不仅指出要更改的内容，还要指出该部分内容更改的方向；但是，如果某些类型的错误过多，您可能希望给出一些示例并推荐这篇论文需要校对。\n* 在检查数学、公式和参考文献等细节时要小心谨慎。\n\n当您建议拒绝某篇论文或建议在重大修改后重新提交论文时，您应该：\n\n* 明确解释论文中存在的问题，并在可能的情况下讨论如何纠正这些问题。\n* 指出论文工作的哪些部分是有价值的，哪些部分应该被丢弃，即讨论您认为的贡献。\n* 检查论文是否达到合理的详细程度，除非它非常草率或考虑不周。\n\n无论哪种情况，你应该：\n\n* 提供作者应该熟悉的良好参考文献。\n* 问问自己你的评论是否公正、具体和礼貌。\n* 作为这篇论文的审稿人，要诚实地对待自己的局限性。\n* 在提交之前仔细检查你的评论，就像检查你自己的论文一样。\n\n以合理的细节陈述你的论点;你的写作和陈述可能与论文中的标准不同，但论证的严谨程度应该相似。请记住，编辑会倾向于相信您的判断和观点，而不是作者的判断和观点。不要滥用这种信任。","tags":["书籍阅读"]},{"title":"论文阅读：Predicting Optimal Power Allocation for CPU and DRAM Domains (IPDPSW 2015)","url":"/2019/08/30/论文阅读：Predicting-Optimal-Power-Allocation-for-CPU-and-DRAM-Domains-IPDPSW-2015/","content":"\n## 摘要\n\n功率输送和成本所带来的限制将成为下一代高性能计算（HPC）系统开发的关键设计障碍。为了弥补这些障碍，已经提出了对过度供应的计算系统施加功率限制（或上限）以保持在物理（和财务）功率限制内的解决方案。不知情的功率封顶（power capping）可以显着影响性能，功率封顶的成功在很大程度上取决于在计算节点的各个子系统上分配给定功率预算的智能程度。由于不同的计算对各种系统组件提出了截然不同的要求，因此在进行功率分配决策以减少性能下降时必须考虑这些需求的变化。给定目标功率限制，本文中提出的基于模型的方法考虑了计算特定属性，指导CPU和DRAM域的功率分配以最大化性能。我们的方法是准确的，可以预测功率上限分配方案对来自实际应用的不同类型计算的性能影响，绝对平均误差小于6％。\n\n## 研究背景\n\n电力成本和供电限制限制了大规模高性能计算（HPC）系统的扩展。未来的HPC系统很可能会过度配置并且功率受限，无法在严格的功率限制内运行[9]，[18]，[23];即，并非系统的所有组件都能以最大功率消耗运行。对于这些类别的系统，传统上最小化时间的性能优化目标将变为更复杂的目标 - 在功率预算下最大化性能，其中给定系统的功率预算将取决于物理（在电力输送和冷却基础设施方面）和成本考虑因素。\n\n为了有效地运行功率受限系统，必须做出决定，将可用功率预算分配给计算节点内的不同子组件（CPU，uncore和memory）。这些分配决策中的一些可能导致操作系统组件处于降低的功率水平，从而降低其性能。为了减少对应用程序执行时间的影响，功率分配决策必须是应用程序感知的;即，功率应限制在对给定应用程序的执行时间影响最小的组件上。例如，在访存密集型的计算阶段的功率封顶DRAM子系统队程序性能的影响要小于功率封顶CPU子系统。\n\n因此，**确定不同类型的计算对CPU和DRAM子系统上降低的功率上限敏感的程度是开发最佳功率上限策略的先决条件**。为此，本文提出了一种系统计算感知方法，用于理解和预测给定计算对CPU和DRAM子系统的不同功率上限的敏感程度，以确定给定功率下组件的最佳功率分配预算。除了对CPU和DRAM施加的不同功率限额之外，我们的预测机器学习模型还利用应用程序的计算属性作为预测器 - 例如，算术强度，内存访问模式，缓存命中率和数据依赖性。当在CPU和DRAM域上同时施加不同的功率上限时，这些模型可用于探索不同计算的性能灵敏度。在给定规定的功率预算的情况下，模型还可用于从一组使用不同代码优化的源代码变体中选择最佳的计算实现。\n\n**我们的工作与众不同之处在于，我们的机器学习模型使用一组基准测试中的计算特性进行训练，以预测CPU和DRAM功率上限对细粒度的任何给定应用的影响。**\n\n本文做出了以下贡献：\n\n* 我们提出了高度准确的模型，用于预测CPU和DRAM域上不同功率上限队各种HPC计算的性能灵敏度。\n* 我们说明了计算特征在开发由功率限制引入的性能退化的精确预测模型中的应用，并讨论了不同应用特性在驱动观察到的退化中的相对重要性。\n* 我们证明了我们的模型在预测实际应用的功率上限敏感度以及为给定功率限制选择性能最佳实现变体（在自动调整工作流程内）的有效性。\n\n## 动机和方法\n\n本节介绍了本文的研究动机，以及我们预测DRAM和CPU功率封顶设置的方法，这些设置可在给定功率预算下最大限度地提高性能。\n\n#### 研究动机\n\n我们的方法所基于的关键洞察力是，相同计算的不同实现在功率有限环境中将具有不同的性能行为。我们通过图1和图2中提供的简单示例来说明这种见解。我们采用了一系列不同的HPC计算（有关这些计算的更多详细信息包含在第IV节中的内容），并在我们的实验室测试平台上运行它们，这是一个基于SandyBridge的双插槽系统（也在第IV节中描述），没有功率限制（原始状态）。对于每个计算，我们运行两组实验 - 一组通过对DRAM域施加功率限制而另一组通过在CPU域中施加限制。每个域的限制是根据给定计算在没有对系统施加功率限制时绘制的功耗来选择的。图1显示了DRAM域的结果，图2显示了CPU域的结果。x轴表示功率上限水平，以基本情况下的功率比例表示;例如，0.62的电平表示在原始状态功率的62％的功率限制（即，功率减少38％）。因此，点越靠近y轴，功率减小越大。y轴表示相对于原始状态的性能下降，其范围从大约1.17X-5X。\n\n降低DRAM领域功率上限对性能的影响是相当广泛的。如果我们考虑DRAM域的功率水平为0.62（见图1），性能下降可能在2.5X到5X的范围内。虽然CPU功率降低的范围并不广泛，但范围仍然非常显着。**在性能下降范围内，计算的下降实际上取决于其特性，并确定哪些特征是这种退化的关键指标，这些都是针对在给定功率预算下最大化性能的任何方法需要达到的要求**。下一节将介绍我们用于提取HPC应用程序中计算的关键性能指标的工具。\n\n{% asset_img Figure1.png [20] [20]%}\n\n{% asset_img Figure2.png [20] [20]%}\n\n#### 计算特征\n\n为了开发能够捕获计算对CPU和DRAM域上不同功率限制的敏感度的模型，我们需要首先捕获应用程序如何与底层硬件子组件交互并执行底层硬件子组件的低级细节。为此，我们利用在PEBIL [15]之上开发的一套应用程序分析工具，这是一个用于x86 / Linux的二进制工具包。PEBIL将应用程序二进制文件作为输入;它反汇编二进制，分析它，并可以进行插桩。在PEBIL之上编写的工具可以对应用程序二进制文件执行静态和动态分析。\n\n在PEBIL之上编写的静态分析工具产生关于程序的近似结构（例如，函数和循环）以及在这些结构内发生的操作的信息。该工具还记录那些控制结构内的操作类（例如，存储器和浮动操作）的类型和大小。静态分析工具记录每个块中存储器操作数的平均大小，并测量寄存器或存储器定义与其使用之间的指令数（即数据依赖性）。\n\n为了收集有关应用程序内数据移动的详细信息，内存特征描述工具，一个在PEBIL之上编写的动态分析工具，应用程序中的每个内存访问，并管理要即时处理的地址流以进行估计各种数据运动相关度量（例如，重用距离，不同循环的工作集大小和高速缓存命中率）。另一个动态分析工具保存应用程序控制单元的访问计数信息（例如，基本块访问计数）。当与静态指令混合信息结合时，访问计数信息提供有关应用程序指令构成的详细信息。\n\n静态和动态工具收集的信息可以组合在一起，以识别大型应用程序中的计算阶段[27]，并**构建我们称之为每个已识别阶段的计算签名**。**计算签名包括应用程序以指令混合和计数形式所需的操作，数据位置属性，捕获应用程序与内存子系统交互的指标，如缓存命中率，加载和存储操作等**。\n\n#### 建模：问题的形式化和技术\n\n如公式1所示，我们的目标是开发一个函数 $f$ ，其输入是一组硬件参数（功率上限）和应用程序特征度量 $x_1,\\cdots,x_n$ ，其输出 $y$ 是对计算性能影响的一些度量。\n\n\n$$\ny=f(x_1,\\cdots,x_n)\\tag{1}\n$$\n\n\n在这项工作中，我们使用Cubist [22]，这是一种基于规则的机器学习技术，来估计方程1中的 $y$。Cubist模型由一系列线性回归模型组成; 预测基于在树的终端/叶节点处找到的线性模型。叶子的路径或终端节点的选择基于中间节点处的规则，这些规则也基于线性模型[19]。与其他形式的基于树的方法（如梯度增强）不同，Cubist模型易于解释。Cubist模型还能够封装预测变量（或输入）变量之间复杂的非线性关系。例如，中间规则可以识别和分离跨越缓存层次结构边界的工作集大小的功率上限带来的性能差异。\n\n为避免过度拟合，我们采用了两种技术。首先，我们将经验样本划分为非重叠的训练和测试集。该模型在训练子集上训练并在测试集上验证。其次，我们使用10倍交叉验证来生成模型。在k倍交叉验证中（在我们的例子中，k = 10），训练数据集被随机分成大小相等的k个子集。然后构造k个不同的模型，每个模型使用k个分区的（k-1）作为训练输入，使得k个集合中的1个可以用于模型验证。然后根据验证集验证每个k模型，并选择产生最小误差的模型。\n\n## 实验结果\n\n本节首先描述我们用于收集训练数据的实验系统。然后，我们描述了一组用于收集训练和测试数据的基准测试，然后讨论了我们的模型在测试数据集和迷你应用程序上的准确性。\n\n#### 实验测试平台\n\n我们的测试系统包括一个双插槽服务器，配备两个8核2.9GHz Intel Xeon E5-2690（SandyBridge）处理器和64GB DDR3内存。在系统上禁用同时多线程（SMT）和Turbo-boost。\n\n最近的Intel处理器上提供的RAPL（运行平均功率限制）[8]可以为CPU和DRAM子系统收集（建模）功率测量（RAPL文档将这些子系统称为“域”）。RAPL还允许用户在这些域上设置功率限制，并且底层硬件基础架构强制执行这些功率限制。在我们基于Sandybridge的测试系统中，RAPL公开了四个功率层 - Package（PKG），Power Plane 0（PP0），Power Plane 1（PP1）和DRAM。我们使用英特尔的Governor工具[1]来强制执行PKG和DRAM域的功率上限。我们还依靠Power Governor工具进行DRAM和CPU功率测量。我们每秒测量5个功率样本，根据我们的经验，这只会产生微不足道的开销。\n\n**虽然我们的重点是使用英特尔处理器，但其他芯片制造商也在其处理器中启用了功率封顶（例如 AMD [3]和IBM [6]，[5]）。本文提出的方法也应适用于这些架构。**\n\n#### 模型训练计算\n\n为了训练捕获各种类型的计算性能如何在CPU和DRAM域上受到不同功率上限级别变化的模型，我们使用了一组在HPC应用程序中非常普遍的各种计算内核。部分源自PolyBench [20]和SPAPT [4]套件的基准测试由来自不同计算域的内核组成 - 密集线性代数（例如，矩阵 - 矩阵乘法和矩阵 - 向量乘法），模板计算，线性代数求解器（例如，LU分解）等。此外，为了扩展和丰富训练空间，对于某些内核，我们使用两个源到源的编译器转换工具--Orio [17]和CHLLL [7]生成实现变体（代码变体）。我们用于生成这些变体的优化包括循环展开，缓存/寄存器平铺和标量替换。这些内核和内核变体中的每一个都配置为以多个工作集大小运行，并且每个计算配置为运行至少2秒。**通过将计算内核和内核变体配置为在多个工作集大小上运行，我们总共有538个计算形成了我们的经验数据集。**\n\n上述数据集中的每个计算在不同的DRAM和CPU功率上限下在测试系统上定时。我们首先运行没有功率限制的基准计算（基本情况），并将来自RAPL的CPU和DRAM域的平均功率测量值表示为 $P_{bCPU}$ 和 $P_{bDRAM}$ 。对于每次计算，我们然后随机生成[ $0.7\\times P_{bDRAM}$，$P_{bDRAM}$ ]区间的DRAM功率上限（即，我们选择随机配置，其中我们将DRAM功率上限降低多达30％）。生成CPU功率上限水平也是如此。对于大部分计算，将上限降低30％以上是不适用的，因为我们接近RAPL的适用DRAM和CPU功率上限的下限。简单的笛卡尔积将DRAM和CPU候选功率上限组合在一起，形成一组同时的DRAM和CPU功率上限配置。在完成评估所需的时间方面，对所有适用的功率限制配置运行计算是不切实际的。因此，在所有适用的配置中，我们选择18个随机配置并对这18个配置运行计算。选择18种随机配置的决定完全取决于我们在数据收集时间方面的经验以及我们希望缩短时间，同时为模型培训生成足够的培训点。我们执行六次配置，以获得六次功率和性能测量。为了降低功率和性能测量中的噪声，我们丢弃最小和最大测量值并平均剩余的四个。此外，对于每次计算，我们使用第III-B节中描述的工具生成表征特征。在后处理之后，我们在经验收集的数据集中总共有9550个数据点。\n\n#### 模型形式化、结果和诊断\n\n公式2显示了公式1的更具体的公式。 $P_d$ 是功率上限引起的性能下降。CPU和DRAM功率限制指标是当没有功率上限时相对于各个域汲取的功率减少百分比。$pi_v[0,1,2]$ 是每条指令的L1，L2和L3命中，而 $pi\\_v3m$ 测量每条指令在L3（因此转到主存储器）中丢失的访问。$fprat$ 是浮点比（每个内存操作的浮点运算），$bytespermemop$ 是每个内存访问传输的字节数。$ins\\_mix$ 由指令混合参数组成 - 分支操作、加载操作、存储操作等，表示为总动态指令的百分比。$idu$ 和 $fdu$ 是整数浮点数据依赖度量。\n\n\n$$\nP_d=f(dram\\_reduction, cpu\\_reduction, pi\\_v0m,pi\\_v1m,pi\\_v3m,fprat,ins\\_mix,bytespermemop,idu,fdu) \\tag{2}\n$$\n\n\n为了生成和评估 $P_d$ 模型（参见公式2），我们首先对我们的整体经验数据进60％-40％的分割。第一个60％部分用于使用10倍交叉验证训练模型。剩余的40％数据用于测试模型的准确性。模型评估结果如图3所示。该图显示了训练和测试数据的建模与测量的运行时间减速（相对于无功率上限）。对于性能良好且准确的模型，图中的点应该大致聚集在对角线45度线周围，如图3所示。预测测试数据集的绝对平均误差小于2％。\n\n{% asset_img Figure3.png [20] [20]%}\n\n我们计算方程2中每个输入预测变量的相对变量重要性，以确定主导预测变量（或输入变量）以及那些对性能退化影响最小且可能从模型中删除的预测变量。图4显示了变量的重要性。具有最高重要性的预测变量被缩放到值100（在这种情况下，$dram\\_reduction$）。正如预期的那样，CPU和DRAM功率上限水平影响最大，其次是量化计算与内存层次结构相互作用的指标。最后，指令组合参数完善了最高预测指标。从计算签名中的元素中，每个指令（ $pi\\_v3m$ ）的主存储器访问是最重要的，这是预期的，因为更多的主存储器访问意味着更多的CPU停顿，因此对CPU功率上限减少的敏感性降低（对于DRAM功率上限减少产生相反现象）。\n\n{% asset_img Figure4.png [20] [20]%}\n\n#### 基于模型的自动调优\n\n我们在这项工作中开发的模型的一个用例是它在基于搜索的自动调整工作流程中的易用性，其中生成并评估使用不同基于编译器的优化的给定代码的多个变体以查找表现最好的那个[24]。在具有响应操作环境变化能力的动态自动调整环境中，我们的模型可用于快速识别在功率预算内表现最佳的变体。我们合理地假设是我们可以在没有功率上限的基本设置中访问自动调整过程中评估的CPU和DRAM功耗数以及所有变量的性能。使用该数据和规定的功率预算，我们的模型可以通知所有可能配置的同类DRAM和CPU功率上限的变体执行时间，从而可以选择性能最佳的变体。\n\n为了说明，我们使用ATAX（矩阵转置和向量乘法）内核。我们使用Orio [17]工具生成200个ATAX内核变体。基于无功率上限的基本设置的性能，我们选择了前10种变体。然后通过施加100个随机选择的DRAM和CPU功率范围来评估这些所选变体中的每一个。我们想要通过这组实验回答的关键问题如下：**如何降低整体DRAM和CPU功率限制会影响最佳变体的选择？也就是说，性能最佳的变体在降低功率上限时是否会继续保持最佳状态？**如果我们假设需要将总功率上限降低10％的情况，那么运行不同的变体是否有意义。请注意，10％的减少将基于在基本设置下性能最佳变体所消耗的DRAM + CPU功率。\n\n在图5中，我们显示了这项调查的结果。X轴是总功率减少量，是最佳变体（变体v87）在无功率上限时所消耗的功率的百分比; Y轴显示所选前10个变体的执行时间范围（以秒为单位）。功耗降低5％时，应选择v192，如图所示。当变量旁边放置一颗星时，我们指示我们的模型不一致（即，使用我们模型预测的执行时间选择的变体与使用实际执行时间选择的变体不匹配，并且在六个案例中仅有一个）。我们提出的研究问题的答案是，变体在执行时间方面的排名确实在不同的功率上限下发生变化。本实验的目的是表明，给定一组DRAM和CPU的功率分配方案，我们的模型能够预测任何可用变体的性能下降。\n\n{% asset_img Figure5.png [20] [20]%}\n\n#### 小型应用程序上的模型评估\n\n最后，我们不仅在内核中说明模型的能力，而且利用模型来预测功率上限操作环境中两个迷你应用程序的行为 -  miniGhost [2]和CoMD [11]。miniGhost是一个有限差分的迷你应用程序，它在同质3D域上实现差异模板。我们考虑使用 $128^3$ 和 $256^3$ 大小的网格进行评估。CoMD是一类广泛的分子动力学模拟的代理应用程序，并提供计算简单Lennard-Jones（LJ）和嵌入原子方法（EAM）潜力的实现。我们在实验中都考虑了这两点。\n\n使用我们的应用程序表征工具套件，我们隔离了这些应用程序中的关键热点，并将特性提供给我们的模型，以请求针对一组随机生成的CPU和DRAM功率上限配置的性能降级预测。为了评估模型的准确性，我们通过在给定的CPU和DRAM功率限制下运行应用程序来测量这些配置的实际性能下降。\n\n然后比较预测的降级和实际降级以验证模型的预测精度。总体预测结果（直方图）如图6所示。此处报告的误差度量是针对“样本外”测试，即在模型训练过程中未看到应用热点的特征描述，从而证明了我们的HPC应用计算模型预测的准确性。总体而言，模型可以很好地预测结果 - 平均绝对平均误差为6％。对于超过86％的应用程序热点，预测误差小于10％。\n\n{% asset_img Figure6.png [20] [20]%}\n\n## 结论\n\n功率上限的性能影响在很大程度上取决于应用程序的计算特性，即，当在功率上限环境中运行时，不同的计算将具有不同的性能行为。本文介绍了一种高度精确的基于模型的方法，该方法利用应用程序特性为CPU和DRAM域的性能最大化功能上限配置选择提供信息。","tags":["Papers","Energy Modeling","IPDPS"]},{"title":"论文阅读：Application-Aware Power Coordination on Power Bounded NUMA Multicore Systems (ICPP 2017)","url":"/2019/08/28/论文阅读：Application-Aware-Power-Coordination-on-Power-Bounded-NUMA-Multicore-Systems-ICPP-2017/","content":"\n## 摘要\n\n功率是限制现代高性能计算机系统的性能和可扩展性的关键因素。将功率视为一阶约束和稀缺系统资源，功率有界计算代表了解决HPC功率挑战的新视角 。\n\n在这项工作中，我们提出了一个应用感知的多维功率分配框架，以支持在支持NUMA的多核系统上的功率有界并行计算。该框架利用多种互补的软件和硬件电源管理机制来管理总功率预算下的插槽、核心和NUMA内存节点之间的功率分配。更重要的是，该框架实现了一种分层功率协调方法，该方法利用应用程序的性能和功率可扩展性来有效地识别理想的功率分配。\n\n我们描述了框架的设计，并在具有24个内核的支持NUMA的多核系统上评估其性能。实验结果表明，所提出的框架与具有各种功率预算的并行程序的oracle解决方案接近。\n\n## 研究背景\n\n功率是限制现代高性能计算系统发展的主要因素。在几乎所有级别的HPC系统中，从IC芯片，微处理器，计算节点一直到整个数据中心，存在功率限制，由物理障碍，技术困难或经济负担造成。例如，在较低级别，IC芯片和电子元件必须在其热设计功率下工作，以防止操作失败和系统故障[9];在更高的层次上，数据中心的冷却能力有限，无法消散产生的热量并保持理想的服务器室温[16]。\n\n功率限制计算将功率视为稀缺资源，利用创新技术在强制或自愿功率预算下提高系统性能，对于维持HPC性能增长至关重要。最近主要的利益相关者明确要求即将到来的亿亿次级计算机以20兆瓦的功率预算运行[22]。然而，解决具有挑战性的计算问题和大量存储器密集型问题的需求要求具有更高性能的更大系统。\n\n智能地协调计算机组件之间的电源是有限计算的关键。为了获得最佳性能，参与的组件必须协同工作并满足应用程序的需求。同时，未使用的组件可以转换到省电状态，允许为激活的组件分配更多功率以获得更好的性能。\n\n最近几个小组研究了CPU内核之间的功率协调[5,26]。在我们之前的工作中，我们研究了处理器和内存之间的功率协调，并重新发现处理器之间的功率分配对应用程序性能有显着影响[10]。尽管如此，这项研究没有考虑非均匀内存访问（NUMA）的影响，NUMA是现代多进程和多核系统采用的内存系统架构。\n\n将NUMA架构整合到功率有限的计算中，为降低功耗、提高性能或实现两者提供了新的机会。但是，NUMA多核系统上的有效功率协调可能具有挑战性。首先，每个应用程序都有其独特的工作负载特性，如计算内存访问率，本地/远程内存访问和并发配置文件，随后会从每个组件创建特定的电源需求。其次，应用程序工作量，系统资源和功率分配之间存在复杂的关系。有效的功率分配模式必须完全评估系统主要部分之间的交互，并在正确的时间为正确的组件分配适当的功率。\n\n为了解决上述挑战，我们提出了一个多功能电源协调框架，该框架在基于NUMA的多核系统上实现了应用感知功率有界计算。该框架专注于并行应用程序，使用轻量级分析来获得应用程序的电源性能特性和可伸缩性。基于所获得的信息和给定的功率预算，该框架在处理器核和存储器节点之间分配可用功率，并确定参与核和各个NUMA节点的亲缘度。\n\n总的来说，这项工作做出了以下贡献：\n\n* 我们提出了一种实用的应用感知功率协调方法和实现。此方法可快速确定为NUMA多核系统上的应用程序提供（接近）最佳性能的硬件和电源分配。\n* 我们展示了包括功率和性能可扩展性以及存储器访问强度的应用特性指示在功率有界系统上引导跨组件功率协调。\n* 我们表明，使用多种软件和硬件机制（如协调并发，核心/内存亲缘性和组件功率级别限制）可以在相同的功率预算下显着提高性能。\n* 我们证明了核心亲缘性对NUMA架构上的功率限制具有相当大的功率和性能影响。\n\n## 相关工作\n\n#### 功率有限的高性能计算\n\n在过去的十年中，关注降低功耗和提高能效已成为众多技术创新背后的主要推动力，包括但不限于：多核架构，基于加速器的计算，功率感知组件，功率封顶和智能电源管理运行时系统。回想起来，我们可以将面向功率的计算机系统研究的观点分为三类：功率自觉（Power conscious）[5]，功率 - 性能权衡（power-performance tradeoff）[3]和功率限制（power-bounded）[10,25]。\n\n总体而言，功率限制计算承认不同系统级别的功率预算上限的存在，并探索同时提高性能和满足预算的创新技术。除了利用现有的电源管理技术，如功率感知组件[17]，功率限制[13,7]，线程分配和亲缘性[1,21]，功率限制计算进一步利用硬件过度分配[20]、资源分配[8]和工作量映射[11]提供的机会。\n\n#### 实现技术\n\n* 工作负载执行管理：并行应用程序的一个常见特性是大多数应用程序可以具有多个运行时配置，包括MPI进程数，线程数和进程/线程位置[11,5]。即使在具有相同工作负载的同一计算平台上，更改运行时配置也会对系统性能和功耗产生重大影响。\n* 核心和内存的亲缘性：在多核计算中，数据局部性和内存争用都会影响并行应用程序性能，从而影响系统能力[6,4]。将并行线程绑定到适当的处理器核心和内存模块有可能改善缓存局部性和应用程序性能。硬件亲缘性可以通过内核调用（如sched_setaffinity），系统工具（如taskset和hwloc），运行时环境（如OpenMP和openmpi）或作业调度程序来实现。\n* 功率预算和功率限额：强制分配功率预算的能力对于有限计算能力至关重要。只有当所有单元都符合自己的功率预算时，功率限制系统才能安全地将可用功率预算安排到那些关键计算单元。功率限额已经在软件，硬件和两者的组合中实现。现有的基于软件的功率预算方法包括动态电压和频率调度（DVFS）[15]，处理器和内存之间的联合功率管理，软件并发限制和线程打包。同时，最新的主要计算机组件如CPU，内存和GPU均支持基于硬件的功率限额功能[13,7,19,14]。对于我们的实现，我们使用RAPL来限制和测量功耗。\n* 跨组件功率协调：由于系统功率是组件功率的总和，因此有必要在系统组件之间协调功率以最大化应用性能。已经探索了几种方法来协调处理器和存储器之间的节点级的给定功率预算。基于反馈回路的控制理论监控应用程序性能和组件的功率，并使用反馈来决定处理器DVFS和内存功率状态的调整[2,12]。基于剖析的技术从可能的分布子集中收集性能和功率数据，并使用插值来确定最佳的过程和内存功率水平[23,25]。在我们之前的工作[10]中，我们研究了CPU和内存之间功率协调的分类模式，并得出结论：功率有限的调度器应该首先在给定约束功率预算的情况下为内存分配足够的功率。Zhang和Hoffmann [26]提出了一种在线混合协调技术，该技术使用RAPL设置硬件功率封顶，然后迭代地使用二进制搜索在每个维度中找到适当的处理器性能状态，核心数和插槽数。\n\n本文工作在几个方面区别于以前的节点级研究。首先，它表明最佳功率协调是特定于应用的，并提出有效的应用表征度量以确定跨组件功率协调。其次，我们提出了应用感知策略，根据应用程序的特性决定最优功率和资源配置，而无需在硬件和软件分配空间中进行搜索。第三，我们的策略针对NUMA多核架构，并在内存访问强度的背景下结合核心亲缘性对功率有界计算的影响。我们的工作通过提供节点级构建块来补充现有的集群级功率协调研究。\n\n## NUMA多核架构的功率分配问题\n\nNUMA体系结构在由多个多核处理器组成的现代服务器节点中是典型的。此类系统上的电源协调涉及处理器插槽，每个插槽内的CPU内核以及NUMA内存节点。\n\n#### NUMA系统概述\n\n我们使用能够运行OpenMP/MPI并行应用程序的基于同构多核的NUMA机器来抽象感兴趣的系统。这个抽象机器代表了现代主流同质HPC系统的构建模块。如图1所示，这种机器具有以下主要的架构和电源管理功能。\n\n{% asset_img Figure1.png [20] [20]%}\n\n* NUMA架构。该机器将处理器插槽和内存模块分成多个NUMA节点，并通过高速网络连接处理器。虽然每个处理器都可以访问整个共享内存空间，但远程内存访问会比本地内存访问产生明显更高的延迟。同时，来自多个核的当前本地存储器访问可能使内存带宽饱和并引起争用，这导致应用程序性能下降。\n* 处理器电源管理。所有处理器都支持电源监控和硬件功率限额。例如，英特尔处理器提供RAPL接口，用户可以使用该接口监控处理器Package，内核和DRAM域的功耗。此外，RAPL允许用户在每个域上设置上限。RAPL采用多个控制旋钮来强制执行处理器功率上限，包括内核的DVFS（P状态），电源状态（C状态）和时钟限制（T状态）。通过在一个或多个控制旋钮上设置上限，RAPL可以成功地限制上限内的整个处理器功耗。\n* 每核电源管理。每个核心在被激活时，可以按照用户通过每核心DVFS的指示在多个性能状态之间转换。每核心DVFS可能会或可能不会受到处理器功率限制的干扰，具体取决于总处理器功率需求是否超过其上限。如果是，则功率上限设置核心性能状态的上限。\n* 内存电源管理。每个NUMA存储器节点可以在多个功率电平下运行，例如由RAPL接口指定，每个电平对应于可用的最高存储器带宽。每个NUMA节点在空闲时可以自动转换到睡眠状态。\n\n#### 硬件和功率分配\n\n我们的功率分配框架将功率视为一种资源。对于由多个并发任务（MPI进程或OpenMP线程）组成的给定并行工作负载，我们的框架不仅分配硬件资源，包括执行的处理器插槽和内核的数量，还在同时执行工作负载的参与硬件之间分配功率。\n\n{% asset_img Figure2.png [20] [20]%}\n\n该框架利用表1中的一系列参数俩表示硬件和功率资源。传统的硬件实体包括处理器插槽，内核和内存节点。我们用 $S_k$ 表示 $N$ 个处理器系统上  $k\\in{1,\\cdots,N}$ 的第 $k$ 个处理器插槽，$C_{k,i}$ 表示 $M$ 核处理器上第 $k$ 个处理器插槽的第 $i$ 个核心，其中 $i\\in {1,\\cdots,M}$。系统的功率预算表示为 $P_b$。  \n\n给定由并发任务组成的并行工作负载 $W$ ，我们使用亲缘性映射向量 $\\overrightarrow{a}$ 来指定分配给其执行的硬件资源： $\\overrightarrow{a}=(a_{1,1},\\cdots,a_{k,i},\\cdots,a_{N,M})$， 其中 $a_{k,i}=0|1$ ，如果工作负载使用第 $k$ 个处理器的第 $i$ 个核心，则 $a_{k,i}= 1$ ，否则为 $a_{k,i} = 0$ 。\n\n此亲缘性映射向量明确指定处理器插槽和核心的分配，并隐式指定工作负载执行的内存节点分配。例如，在采用节点本地策略作为默认值的NUMA感知操作系统上，分配核心本地的相应存储器节点。此外， $\\overrightarrow{a}$ 指定线程并发性和线程核心亲缘性，这是性能和电源管理的重要因素。假设每个核心同时最多执行一个线程，则 $\\overrightarrow{a}$ 中的非零项数表示并发性。该假设适用于高性能计算系统的科学程序。为了强制执行硬件分配，我们的框架控制线程并发并设置线程核心关联。\n\n在功率限制计算的背景下，我们使用功率分布矢量 $\\overrightarrow{d}$ 来表示分配给处理器插槽及其各自的NUMA存储节点的功率预算，即， $\\overrightarrow{d}=(\\overrightarrow{d_{1}},\\cdots,\\overrightarrow{d_N})$  ，其中 $\\overrightarrow{d_k}$  是分配给第 $k$ 个处理器插槽及其相应存储器节点的功率预算。\n\n在这项工作中，我们不考虑单个内存通道，而是将NUMA内存节点作为最小功率管理单元。考虑到这一点，$\\overrightarrow{d_k}$ 可以进一步分配给第 $k$ 个插槽的组成核心和本地存储器节点，即 $\\overrightarrow{d_k}=(d_{c_{k,1}},\\cdots,d_{c_{k,M}},d_{mem_k})$ ，其中其中 $d_{c_{k,i}}$ 指定分配给第 $i$ 个核心的功率，$d_{mem_k}$ 指定分配给第 $k$ 个处理器插槽本地的存储器节点的功率。$d_{c_k}$ 可以通过单独设置其性能状态 $f_{k,i}$ 直接强制执行，或通过设置整个处理器的功率电平 $l_{p_k}$ 间接强制执行。可以通过设置第 $k$ 个NUMA存储器节点的功率电平 $l_{m_k}$ 来强制执行 $d_{mem_k}$。 \n\n在我们的框架中使用这两个向量 $\\overrightarrow{a}$ 和 $\\overrightarrow{d}$ 来为工作负载执行分配硬件和功率。它们共同确定并行工作负载执行环境配置 $e = {\\overrightarrow{a}，\\overrightarrow{d}}$。注意，未激活的核心，即 $a_{k,i} = 0$，将转换到其最低功率状态以节省功率。\n\n#### 功率有限的资源分配问题\n\nNUMA多核系统上的功率有限的跨组件功率协调可找到给定并行工作负载的最佳硬件资源分配和相应的功率分配。在数学上，问题可以表述为：\n\n给定并行工作负载 $W$，NUMA机器 $M$ 和功率预算 $P_b$，找到最佳并行工作负载执行环境配置 $e^* =(a,d)$，使得:  $perf(e^*,W,M) \\geq perf(e,W,M)$  ，且  $power(e^*,W,M)\\leq P_b$  。 \n\n我们注意到这个公式概括了多核架构上大多数功率有限的分配问题。从分析上讲，解决这种功率有限的分配问题进一步要求对并行工作负载执行的性能及其与环境配置 $e$ 的变化进行建模，这是一个复杂的问题。幸运的是，近乎最优的解决方案在现实世界中已经足够，并且可以通过应用程序分析和启发式方法的组合来获得这样的解决方案。\n\n## 工作负载特征\n\n为了避免直接建模并行应用程序执行的性能和功耗的困难，我们使用简单实用的模型简化方法。在这种方法中，我们使用三个指标捕获不同工作负载性能和功耗特性的影响：并行可扩展性、内存访问强度和组件的关键功率级别。\n\n#### 可扩展性\n\n性能可伸缩性，用并行加速比来衡量，描述了应用程序性能如何随着用于执行工作负载的核心数（ $n$ ）而变化。我们还可以应用类似的概念，功率可扩展性来描述应用程序功耗随 $n$ 的变化。\n\n如果我们能够以足够的精度估计性能和功率可扩展性，我们可以使用它们在给定的功率预算下找到接近最优的正确核心数 $n$。根据经验， $speedup(n)\\propto n$ 仅适用于理想或极度并行应用;对于大多数并行应用， $speedup(n)$ 是 $n$ 的非线性函数。这意味着我们可能需要分析大量执行配置以准确捕获并行应用程序的可伸缩性。\n\n幸运的是，对于性能和功耗，大多数并行应用程序的可伸缩性可以通过分段线性模型建模，该模型包括若干段，并且每个段通过线性关系近似。如图2所示，为应用SP和FT的功耗和性能可扩展性，我们看到FT可以通过性能和功率的核心数量进行线性扩展，而SP则不然。但是，我们可以使用两个段来估算SP的性能可扩展性，并使用一个段来估算其功率可扩展性。\n\n{% asset_img Figure3.png [20] [20]%}\n\n#### 内存访问强度\n\n虽然可以从可伸缩性确定核n的数量，但核心亲和力和存储器功率将根据应用的存储器访问模式来确定。在这项工作中，我们使用内存访问强度来表征并行工作负载内存访问模式，这反映在本地内存访问带宽，远程内存访问带宽和内存功耗上。\n\n内存访问强度从三个主要方面影响功率限制调度。首先，内存密集型应用程序的性能对内存功耗分配很敏感。对于内存密集型应用程序，即使内存功率预算略有降低，性能也可能会急剧下降。这与计算密集型应用程序进行了比较，后者的性能随着CPU功率分配而逐渐降低。这种差异部分原因是由于CPU功率范围大于存储器功率的事实。为避免对性能产生不利影响，功率限制分配应确保内存获得足够的功率，尤其是对于内存密集型应用程序。\n\n其次，内存密集型应用程序需要智能放置激活的核心和核心亲缘性。由于NUMA架构的性质，核心位置和亲缘性会影响内存争用和内存访问成本。一方面，将激活的核心放在同一个插槽上可能会使内存总线饱和并导致内存争用。另一方面，在插槽之间分配激活的核心可以增加具有更长延迟的远程存储器访问。最佳核心亲缘性在内存争用和远程访问之间进行权衡。\n\n第三，核心布局影响系统功耗; 如果其他未激活的插槽可以转换到睡眠状态，则将激活的核心放置在同一个插槽上会消耗更少的功率。\n\n{% asset_img Figure4.png [20] [20]%}\n\n图3显示了核心亲缘性对具有24个核心的双处理器机器上的stream和EP基准测试的功耗和性能的影响，其中stream是内存密集型的，而EP是计算密集型的。为stream分配12个核心，每6个绑定到一个处理器插槽上可以提供最大的加速; 进一步使用更多核心会导致更多功耗而不会提高性能。相比之下，将所有12个内核绑定到一个处理器会带来更差的性能，EP的不同之处在于其性能和功率不随核心亲缘性而变化。\n\n#### 关键组件功率分级（Power Levels）\n\n为了解决确定激活的核心、处理器和内存模块的电源状态的问题，我们借用了[10]中描述的关键组件功率分级方法。\n\n文献[10]中的方法考虑了每个应用程序的独特处理器和内存使用模式以及功耗特性，并通过一组功率级别来描述这些特性，这些功率级别反映了激活核心数量、核心性能状态和内存速度的影响 。在这项工作中，我们认为可以激活任意数量的核心，这与[10]不同，其中所有可用核心都必须运行应用程序。这种差异对于NUMA架构和不能很好扩展的应用程序至关重要。\n\n{% asset_img Figure5.png [20] [20]%}\n\n如图4所示，我们考虑CPU核心中总共四个关键功率级别，和内存模块的两个关键功率级别。我们注意到这些级别的确切值是特定于应用程序的，但它们的相对顺序在所有应用程序中保持相同。\n\n###### 关键CPU功率级别\n\n* $P_{cpu，L_1}$ ：CPU功率的上限，其中所有核心被激活并以最高性能状态运行。\n* $P_{cpu，L_2}$ ：激活所有核心并以最低性能状态运行时的CPU功率。\n* $P_{cpu，L_3}$ ：仅激活一个核心并以最大性能状态运行时的CPU功率。\n* $P_{cpu，L_4}$：仅激活一个核心并以最低性能状态运行时的CPU功率。 \n\n###### 关键内存功率级别\n\n* $P_{mem，L_1}$：内存以最高速度运行以支持所有核心数据时的内存功率上限。\n* $P_{mem，L_2}$：当内存支持以最大频率运行的一个核心数据时的内存功率。\n\n## 应用感知功率协调\n\n#### 关键设计思想\n\n为了快速逼近功率有界跨组件功率协调问题的最优解，我们开发了一种应用感知的分层功率协调方法，遵循以下三种技术：\n\n{% asset_img Figure6.png [20] [20]%}\n\n* 工作负载分类。我们基于并行可扩展性和内存访问强度分析对并行应用程序进行分类，并为每个类别定制功率协调策略。沿着每个表征维度，我们用三个值中的一个标记每个应用程序：低，中和高，这些是我们根据经验确定。例如，如图5所示，EP属于（高并行可伸缩性，低存储强度）的类别。\n* 搜索空间缩减。我们通过使用一小组数据执行配置来减少工作负载执行配置的搜索空间，这对于提供关键参考数据至关重要，并且很有可能成为最佳解决方案。枢轴执行配置将在第VI节中讨论。\n* 有序搜索。我们优先考虑执行配置的参数，并使用该顺序来导航搜索过程。换句话说，如果控制旋钮A具有比控制旋钮B更大的性能或功率影响，我们首先确定A的参数。\n\n#### 算法描述\n\n如图4所示，该算法分四步：\n\n**步骤1**：确定给定的功率预算是不可接受的、可接受的还是足够的。如果（  $P_b<P_{cpu,L_4} + P_{mem，L_2}$ ），算法返回“功率预算太低”。如果（ $P_b>P_{cpu,L_1} + P_{mem，L_1}$ ）或功率预算足够，则算法将最大功率分配给应用程序可能需要的处理器和内存，并设置从数据库执行配置中学习的线程并发性和亲缘性。此外，该算法可以判断工作负载不需要多少过多的功率预算。否则，如果（ $P_b > P_{cpu,L_4} + P_{mem，L_2}$ ）或功率预算可接受，则算法前进到以下步骤。\n\n**步骤2**：确定处理器内存的功率分配并确定内存功率分配的优先级。由于内存功耗预算会显着影响应用程序性能[10]并且内存功耗通常远低于处理器功耗，因此该算法可确保内存获得足够的预算，以最高内存速度运行以支持激活的核心。具体来说，如果功率预算大到足以激活所有核心，即（ $P_b > P_{cpu,L_2} + P_{mem，L_1}$），算法会将（ $P_{mem，L_1}$ ）分配给内存，即应用程序需要内存的最大功率。否则，它将（ $P_{mem,L_2}$ ）分配给内存。剩余功率预算分配给处理器。\n\n**步骤3**：确定激活核心的数量以及核心频率。该算法使用两个CPU电源控制旋钮 - 并发和核心速度 - 根据应用程序的特性在核心之间分配处理器能力。如果应用程序是可扩展的，则算法首先尝试激活与功率预算允许的核心数相同的核心，然后尽可能以更高的速度运行核心。理由是并发性可以最好地保留这些应用程序的性能和功效。对于可扩展性较差的应用程序，调度程序首先尝试以最高频率运行激活的核心，然后在功率预算允许的情况下激活更多核心。对于具有中等可伸缩性的应用程序，该算法同时确定目标并发性和核心速度，以匹配应用程序的内存强度和并行可伸缩性。\n\n**步骤4**：确定最佳核心亲缘性。默认情况下，调度程序将激活的核心打包到同一个处理器插槽，其中一个线程绑定到一个核心。此启发式方法可有效地用于计算密集型应用程序。此默认亲缘性对于自动将空闲插槽转换为深度睡眠状态的体系结构是有利的。对于内存密集型应用程序，该算法会比较打包核心并在插槽上均匀分布核心，并选择可提供更好性能的核心亲缘性。\n\n## 系统设计\n\n#### Coordinator软件系统\n\n我们构建了一个名为coordinator的原型系统，以支持NUMA多功能系统上的应用感知功率协调。如图6所示，协调器包括数据驱动的执行配置训练和推荐系统、用户界面和应用程序运行器，以及几个帮助工具，以提供用户友好的功率有限计算环境。\n\n{% asset_img Figure7.png [20] [20]%}\n\n* **应用程序运行器**  提供用户界面，将程序和要计算的问题大小以及功率预算作为输入，从推荐器获取并行工作负载执行配置（  $\\overrightarrow{a},\\overrightarrow{d}$ ），并创建启动作业的作业脚本，通过作业调度程序在功率有限的NUMA多核节点上执行配置（ $\\overrightarrow{a},\\overrightarrow{d}$ ）。\n* **配置推荐器** 实现决策引擎，它将元组（程序，问题，功率限制）作为输入，并将并行工作负载执行配置（ $\\overrightarrow{a},\\overrightarrow{d}$ ）返回给应用程序运行器。\n* **System Interface Helper** 包括几个定制的系统工具，如功率计读取器，RAPL和DVFS电源控制器，以及性能收集器。这些工具与系统内核，库和并行运行时环境进行交互，以设置执行环境，并自动收集和记录通过协调器管理的作业的性能和电源数据。\n\n在coordinator中，推荐器使用两种机制找到工作负载执行配置（ $\\overrightarrow{a},\\overrightarrow{d}$ ）。首先，它查询已知（程序，问题，功率限制）组合的知识库。如果没有找到条目，推荐器会咨询ConfigTrainner，它使用第V节中描述的调度策略来创建一组初始配置，但是一旦coordinator收集初始配置的实际性能数据，就切换到学习模式以创建新配置。\n\n我们使用两个数据库：KnowledgeBase，它存储消化和清洗的应用程序特定知识; PerfDB，它存储详细的每个作业级别的原始性能和功率数据。实质上，两个数据库都保留一组包含如下信息的条目：\n\n{% asset_img Figure8.png [20] [20]%}\n\n离线分析和运行时执行的原始数据都记录在PerfDB中。在有足够数量的新数据进入后，ConfigTrainner运行统计模块来消化数据并将消化的摘要数据保存到KnowledgeBase中。\n\n#### 枢轴执行配置 （Pivot Execution Configurations）\n\n在执行配置空间中，存在一组枢轴配置，其提供关于应用特征的更多见解而不是其他点。图7提供了具有两个NUMA节点和 $n$ 个核的NUMA系统的这种枢轴配置的示例集。\n\n{% asset_img Figure9.png [20] [20]%}\n\n图7中所示的系统上的枢轴配置集包括 **C1**：具有最小和最大核心频率的串行执行，**C2**：在两个处理器上具有一半核的并行执行，**C3**：在一个处理器上所有核并行执行， 和**C4**：并行执行所有可用核心，具有最小和最大核心频率。从配置文件数据中，我们直接或间接地得出应用程序的功率和性能特征如下，\n\n* 关键功率级别（Critical Power Levels）：具有最小和最大CPU频率的配置C1和C4，产生种CPU功率;具有最大CPU频率的配置C4和具有最小CPU频率的C1提供两种存储器功率。\n* 并行可扩展性：我们计算从C1（单核）到C3（同一处理器上的所有核）的性能数据的并行加速比，然后在两个段中计算C4，以确定应用程序是可扩展的、适度可扩展的还是可扩展性差的。\n* 内存访问强度：我们从内存功耗和本地带宽以及使用硬件性能计数器测量的跨插槽带宽中获取内存访问密度。\n* 核心亲缘性：我们比较配置C2和C3的性能数据;并分析本地内存带宽和远程内存访问，以估计内存争用程度和数据放置的影响。\n\n## 实验结果\n\n我们评估了我们在NUMA系统上提出的框架和协调算法，该系统在两个NUMA节点之间均匀分配了两个Intel 12核Haswell E5-2670 v3处理器和128GB DDR4 DRAM。所有内核均支持每核DVFS，12个频率范围为1.2GHz至2.3GHz，0.1MHz。我们使用RAPL测量各个处理器封装和DRAM的功耗[13]。\n\n我们在评估中使用表II中显示的并行基准列表。这些基准测试具有不同的工作负载特性，从高度可扩展，计算密集型到中等可扩展性，内存密集型。\n\n{% asset_img Figure10.png [20] [20]%}\n\n#### 应用程序特征\n\n我们使用多个执行配置分析每个基准测试的功能和性能，并分析收集的数据以获得工作负载特征的度量。\n\n**并行可扩展性。** 图8显示了每个基准测试程序如何在2.3 GHz的固定核心频率下按核心计数进行扩展。该图显示EP，Dgemm，BT，LU和FT是高度可扩展的应用程序，当使用更多内核时，其速度会增加。当核心数量从12增加到24时，它们的加速几乎翻倍。SP，RA和STREAM是适度可扩展的应用程序，其性能在核心数达到12之前就已经很好地扩展，但在使用超过12个核心时变得停滞不前。Kmeans和Ptrans是可扩展性很差的应用程序，即使使用全部24个核心，其最大加速比也小于6。\n\n***这些实验结果导致了一种启发式方法，即使用 $n$，$n / 2$ 和 $n/4$ 的执行配置中的性能数据足以将应用程序分为三类：可伸缩，可适度扩展和可扩展性差。***\n\n{% asset_img Figure11.png [20] [20]%}\n\n**访存强度和核心亲缘性**。内存密集型应用程序会导致大量数据从本地和远程内存移动，从而导致高内存带宽。如图8(b)所示，像Kmeans和SP这样的内存密集型应用程序可以使用一半可用核心实现超过10GB/s的速度，而EP和Dgemm等计算密集型应用程序几乎不需要内存访问。\n\n***由于本地内存访问会导致内存争用，从而显着降低性能，因此将核心分配到更多插槽会比将核心放置到一个处理器中的性能更高***。在第二个子类别中，当将核心分发到更多处理器时，像Kmeans和Ptrans这样的应用程序具有很大的远程与本地内存访问比率。例如，Kmean中的远程内存访问占总内存访问量的50％以上。对于此类型的应用程序，将核心整合到同一处理器可以提高性能、降低功耗。\n\n对于具有低内存密度的计算密集型应用程序，性能对亲缘性不敏感。因此，整合核心是首选的计划选项。结合应用程序的可伸缩性和内存强度，我们将它们聚类在图5所示的类别中。\n\n**工作负载功率水平**。图9总结了应用程序在关键功率水平下的功耗和性能，这验证了我们的算法设计原理并证明了枢轴配置的有用性。\n\n{% asset_img Figure12.png [20] [20]%}\n\n#### 功率分配策略评估\n\n将本文提出的方法于其他方法（包括最优）进行比较，得出本文方法可以得到和最优方法相近的效果，说明该方法的有效性。\n\n{% asset_img Figure13.png [20] [20]%}","tags":["Papers","Energy Modeling","ICPP"]},{"title":"论文阅读：Performance and Energy Analysis of OpenMP Runtime Systems With Dense Linear Algebra Algorithms (WAMCA 2017)","url":"/2019/08/27/论文阅读：Performance-and-Energy-Analysis-of-OpenMP-runtime-systems-with-dense-linear-algebra-algorithms-WAMCA-2017/","content":"\n## 摘要\n\n在本文中，我们通过非统一内存访问（NUMA）平台分析五个OpenMP运行时系统的性能和能耗。我们还选择了三种CPU级优化或技术来评估它们对运行时系统的影响：处理器具有Turbo Boost和C-States，以及通过Linux CPUFreq governor的CPU动态电压和频率调整。我们提出了一个实验研究，在性能和能耗方面，在密集线性代数算法（Cholesky，LU和QR）的三个主要内核上表征OpenMP运行时系统。我们的实验结果表明，OpenMP运行时系统可以被视为一种新的能量杠杆，Turbo Boost以及C-States会显着影响性能和能量。CPUFreq调控器在禁用Turbo Boost时受到的影响更大，因为两次优化都会因CPU热限制而降低性能。与使用GNU C编译器（GCC）libGOMP运行时的原始PLASMA算法相比，来自libKOMP的并发写扩展的LU分解实现了高达63％的性能增益和29％的能量降低。\n\n","tags":["Papers","Energy Modeling"]},{"title":"论文阅读：Impact of Parallel Programming Models and CPUs Clock Frequency on Energy Consumption of HPC Systems (AICCSA 2011)","url":"/2019/08/26/论文阅读：Impact-of-parallel-programming-models-and-CPUs-clock-frequency-on-energy-consumption-of-HPC-systems-AICCSA-2011/","content":"\n## 摘要\n\n能耗已成为高性能计算（HPC）领域的最大挑战之一。超级计算机在运营期间产生的能源成本与采购类似。因此，除了对环境的影响外，能量是HPC的限制因素。\n\n我们的研究旨在降低计算机系统的能耗，以运行并行HPC应用程序。在本文中，我们分析了共享存储器（OpenMP）和消息传递（MPI）的并行编程范例的可能影响，以及系统在CPU的不同时钟频率下的行为。\n\n结果表明，编程模型对计算机系统的能耗有重要影响。发现时钟频率降低对执行时间，能量效率和最大功耗的影响不仅取决于应用类型，还取决于其在特定编程模型中的实现。我们认为在选择并行编程模型时要考虑的另一个标准是对能耗的影响。\n\n## 研究内容\n\n我们的研究旨在降低计算机系统的能耗，以运行并行HPC应用程序。通过这种方式，我们希望为经济，环境和社会因素做出贡献。在本文中，我们分析了共享内存和消息传递的并行编程范例的可能影响，以及它们在CPU的不同时钟频率下呈现的行为。具体来说，我们使用OpenMP（共享内存并行编程模型）和MPI（消息传递编程模型）实现NAS并行基准测试，在双核处理器的双插槽服务器上运行。本文中提出的实验的重点仅限于计算节点，而不是互连网络。\n\n结果表明，编程模型对计算机系统的能耗有重要影响。结果发现，时钟频率降低对执行时间，能效和最大功率的影响不仅取决于应用类型，还取决于其在特定编程模型中的实现。我们相信这项研究可能是该地区未来工作的重要起点。\n\n#### 能耗度量\n\n功率是计算机消耗电能的速率。瓦特（W）是功率单位，相当于1焦耳/秒（1 J / s）。能量是计算机随时间消耗的总电能量，以焦耳或瓦特小时（Wh）为单位。\n\n测量能效的最常用指标是Green500使用的指标：每瓦性能（MFLOPS / W）。但是，也有其他指标。例如，Sun Microsystems定义了度量SWaP（Space，Wattage和Performance），它考虑了空间的测量来计算计算机的能量效率。\n\n通常，HPC平台中的工作旨在降低能耗但不降低功率。能耗与系统消耗的总电力成本有关。但是，计算机系统的最大功率决定了电气基础设施和冷却设备的容量。因此，我们决定在我们的实验中包括功率测量。\n\n#### 面向的编程模型\n\n共享内存的OpenMP，和分布式内存的MPI。\n\n#### 研究方法\n\n该方法利用电表来测量整个计算节点的能耗，利用```cpufreq-selector```来改变相应核心的频率，具体指令为``` cpufreq-selector -c 0 -f 1000000```,该指令表示将核心0的频率修改为1GHz。\n\n#### 平台的能耗范围\n\n我们进行了实验来量化程序运行对并行系统能耗的影响。测量在空闲状态下研究的系统的能量消耗，即仅运行操作系统的过程。我们还测量了平台在最高CPU时钟频率下针对不同NAS并行基准测试的最大峰值功率。我们确定了基准测试的问题大小，以便满足执行的主要内存要求，并且永远不会发生内存交换。\n\n服务器在空闲状态下消耗大约117W，最大峰值功率约为221W。也就是说，服务器接近空闲状态能耗的两倍。也就是说，服务器能够使空闲状态能耗几乎翻倍。这些结果证明了软件改变平台功耗的高容量，证明了其研究的重要性。\n\n## 实验结果\n\n通过更改CPU频率，能耗降低的结果如下：\n\n{% asset_img Figure1.png [20] [20]%}\n\n性能损失的结果如下：\n\n{% asset_img Figure2.png [20] [20]%}\n\n最大功率降低的结果如下：\n\n{% asset_img Figure3.png [20] [20]%}","tags":["Papers","Energy Modeling"]},{"title":"论文阅读：How Much Power Does Your Server Consume? Estimating Wall Socket Power Using RAPL Measurements (Comput Sci Res Dev 2016)","url":"/2019/08/25/论文阅读：How-much-power-does-your-server-consume-Estimating-wall-socket-power-using-RAPL-measurements-Comput-Sci-Res-Dev-2016/","content":"\n## 摘要\n\n来自墙上插槽（wall socket）的全系统电力输入对于理解和预算大规模数据中心的电力消耗非常重要。然而，测量全系统功率需要额外的仪器与外部物理设备，这不仅麻烦，而且昂贵且耗时。为了解决这个问题，本文中提出了RAPL接口获得的处理器Package功率模拟墙上插槽功率，该接口可在最新的英特尔处理器上获得。实验结果表明RAPL的Package功率与墙上插槽功率之间存在很强的相关性。基于这些观察，本文提出了一种经验功效模型来预测整个系统功率。实验中使用多个综合基准（Stress-ng，STREAM），高能物理基准（Par FullCMS）和非平凡应用基准（Parsec）验证模型。实验结果表明，该预测模型具有良好的准确率，最大误差率为5.6％。\n\n## 前期验证\n\n本文基于Stress-ng和Stream基准测试程序进行了实验观察，验证Package功率和墙上功率呈线性关系。Stress-ng的实验如下图所示：\n\n{% asset_img Figure1.png [20] [20]%}\n\n由该图可以看出，两者是呈线性关系，相关系数为0.999，通过线性拟合可以得到关系式：\n$$\nP_{wall}=1.214*P_{package}+20.221\n$$\n\n其中$P_{package}$表示利用RAPL测量的Package功率，$P_{wall}$表示墙上功率。同样的，基于Stream基准测试程序进行上述实验可以得到相似的结果，其拟合的关系式为：\n$$\nP_{wall}=1.212*P_{package}+25.580\n$$\n基于ParFullCMS和Parsec结果显示如下，也是呈线性关系的。\n\n {% asset_img Figure2.png [20] [20]%}\n\n## 墙上功率建模（Wall Power Modeling）\n\n如前几节所示，线性模型非常适合，但不同工作负载的系数会有所不同。因此需要一种方法来校准任何任意工作负载的模型。本文使用机器学习技术开发了一种用于墙上功率的通用功率模型。请注意，为简洁起见，在本文的其余部分中，仅使用Machine 1来显示结果。其他机器表现出类似的趋势。\n\n本文利用Stream, Stress-ng 和Parsec 基准测试程序的数据进行训练，并验证模型的有效性。然后利用ParFullCMS数据来测试模型的准确度。模型定义如下：\n\n公式（1）\n\n\n $$\nE=\\sum_{t=1}^{N}{(wall_t-f(pkg_t))^2} \\tag{1}\n $$\n\n其中 $N$ 为训练数据的数量， $wall_t$ 为墙上功率， $f(pkg)$ 的定义如下：\n\n\n$$\nf(pkg)=\\sum_{i=0}^{k-1}{a_i\\cdot y_i(pkg)} \\tag{2}\n$$\n\n其中 $A=(a_0,a_1,\\dots,a_{k-1})$ 是一个 $1\\times k$ 的向量。我们的目标是获得一个最优的 $f(x)$ ，使得 $E$ 达到最小。 $E$ 最小则其偏导数为0，那么有\n\n$$\n\\frac{\\partial E}{\\partial a_j}=\\frac{1}{N}\\sum_{t=1}^{N}2\\left ((wall_t) -\\sum_{i=0}^{k-1}a_i\\cdot y_i(pkg_t) \\right )y_j(pkg_t) \\tag{3}\n$$\n\n对该式进行简化，可以得到：\n\n$$\n\\sum_{t=1}^{N}wall_t y_j(pkg_t)=\\sum_{t=1}^{N}\\sum_{i=0}^{k-1}a_i\\cdot y_i(pkg_t)y_j(pkg_t) \\tag{4}\n$$\n\n用矩阵表示为：\n\n$$\nA=WY^T(YY^T)^{-1} \\tag{5}\n$$\n\n其中 $Y$ 是一个 $k\\times N$ 的矩阵，$Y_{i,t}=y_i(pkg_t)$ , $W=(wall_0,\\dots,wall_t)$ 。我们定义 $y_i(pkg)=pkg^i$ ,这意味着函数$f$由具有 $k$ 项的多项式定义， $A$ 成为从多项式回归得到的系数的向量。我们针对不同阶数的多项式 $k$ 求解上式，其中 $k$ 从1到4变化。\n\n通过实验表明，线性关系得到的结果最好。\n\n {% asset_img Figure3.png [20] [20]%}","tags":["Papers","Energy Modeling"]},{"title":"强化学习介绍","url":"/2019/08/24/强化学习介绍/","content":"\n## 参考\n\n* Q-learning算法的简明教程。https://blog.csdn.net/itplus/article/details/9361915\n\n","tags":["强化学习"]},{"title":"如何调整CPU频率","url":"/2019/08/24/如何调整CPU频率/","content":"\n## cpufreq-set \n\n#### 参考\n\n* 使用cpufreq给CPU临时调整主频。http://www.kwx.gd/CentOSApp/CentOS-Cpufreq-Set.html\n\n## cpufreq-selector\n\n#### 参考\n\n* cpufreq-selector的安装。https://bytefreaks.net/tag/cpufreq-selector\n* ubuntu系统更改CPU频率。 https://www.zhukun.net/archives/7572\n* cpufreq-selector参数。http://manpages.ubuntu.com/manpages/bionic/man1/cpufreq-selector.1.html\n\n## 注意\n\n并不是所有的系统都可以任意调整CPU频率，也就是userspace模式。\n\n> This is because your system is using the new driver called [**intel_pstate**](https://www.kernel.org/doc/html/v4.13/admin-guide/pm/intel_pstate.html). There are only two governors available when using this driver: `powersave` and `performance`.\n> The `userspace` governor is only available with the older `acpi-cpufreq` driver (which will be automatically used if you disable `intel_pstate` at boot time; you then set the governor/frequency with `cpupower`):\n>\n> - disable the current driver: add `intel_pstate=disable` to your kernel boot line\n> - boot, then load the `userspace` module: `modprobe cpufreq_userspace`\n> - set the governor: `cpupower frequency-set --governor userspace`\n> - set the frequency: `cpupower --cpu all frequency-set --freq 800MHz`","tags":["CPU Frequency"]},{"title":"PAPI:使用PAPI对程序性能进行分析","url":"/2019/08/24/PAPI-使用PAPI对程序性能进行分析/","content":"\n## 参考\n\nPAPI：使用PAPI对程序性能进行分析. https://blog.csdn.net/dnhan/article/details/8441078","tags":["PAPI"]},{"title":"RAPL Interface 介绍","url":"/2019/08/23/RAPL-Interface-介绍/","content":"\n## RAPL Interface\n\nRAPL 接口是由英特尔Snady Bridge架构首次引入，并且随后在英特尔架构的后续迭代中不断发展。RAPL背后的动机是暴露不同CPU域的能耗，并根据系统的功率预算限制域（domain）的能耗。在这方面，RAPL提供了两个基本功能：首先，它以高粒度和高采样率提供能耗测量；其次，它允许限制不同CPU组件的平均功率，这实质上限制了CPU的热输出。本文特别关注能量测量功能。\n\nRAPL支持过个电源域，支持的RAPL域的确切数量取决于处理器架构。在RAPL的上下文中，功率域是用于功率管理的物理上有意义的域（例如，处理器包，DRAM等）。每个电源域执行以下任务：\n\n* 测量域的能耗；\n* 允许在指定的时间窗口内限制该域的功耗；\n* 监控功率限制的性能影响；\n* 提供一些其他有用的信息，如能量测量单位、域支持的最小或最大功率。\n\n下图显示了电源域的层次结构。根据处理器架构，RAPL提供一下电源域的全部或部分：\n\n* Package：包域提供整个CPU插槽（socket）的能耗测量。它包括所有核心（core），集成显卡以及非核组件（最后以及缓存、内存控制器）的能耗；\n* Power Plane 0：Power Plane 0 (PP0) 域提供了单个插槽上所有处理器核心的能耗；\n* Power Plane 1:  Power Plane 1 (PP1)域提供了插槽上GPU的能耗测量；\n* DRAM： DRAM域提供了连接到集成存储器控制器的RAM的能耗测量。\n* PSys：英特尔Skylake推出了一个名为PSys的新RAPL域。它监视和控制整个SoC的热量和功率规格，当功耗源既不是CPU也不是GPU时，它特别有用。如下图所示，PSys包括PKG域，系统代理，PCH，eDRAM以及单个插槽SoC上的更多域的功耗。\n\n{% asset_img Figure1.png [20] [20]%}\n\n对于多插槽服务器系统，每个套接字都会报告自己的RAPL值。例如，双插槽计算系统对两个PKG都有两个单独的PKG读数，PP0读数，PP1读数等。\n\n并非所有英特尔架构都存在上图中的所有域。如前所述，支持的RAPL电源域数量因处理器架构而异。下表显示了由不同处理器架构支持的RAPL域的概述。服务器型号不支持PP1，它仅存在于桌面型号中。从Haswell开始，桌面型号也支持DRAM域。Haswell服务器型号不支持PP0和PP1。这意味着只有PKG域是普遍支持的电源域。对于Skylake而言，与PKG不同，PSys需要额外的系统级实现，因此所有Skylake版本都不支持。\n\n{% asset_img Figure2.png [20] [20]%}\n\nRAPL能量计数器可以通过32位寄存器的模式指定寄存器（Model-Specific Register，MSR）访问，这些寄存器报告从处理器启动时开始的能量消耗。计数器大约每毫秒更新一次。能耗可以以多种指定模式能量单位进行计算。Sandy Bridge使用15.3微焦耳的能量单位[61]，而Haswell和Skylake使用61微焦耳的单位。在一些CPU架构中，例如Haswell-EP，DRAM单元与CPU能量单元不同。在进行能量计算之前，可以从特定的MSR读取单位。在不同架构的情况下，不同能量单元没有具体含义。\n\n可以使用内核中的MSR驱动程序直接在Linux上访问MSR。下图显示了一个这样的例子。对于直接MSR访问，必须启用MSR驱动程序，并且必须为驱动程序设置读访问权限。直接从MSR读取RAPL域值需要在读取RAPL域（即PKG，PP0，PP1等）消耗值之前检测CPU模式并读取RAPL能量单位。\n\n{% asset_img Figure3.png [20] [20]%}\n\n一旦检测到CPU模式，就可以通过读取相应的“MSR状态”寄存器来读取每个PKG的RAPL域。例如，MSR_PKG_ENERGY_STATUS保存PKG域的能量读数。\n\nRAPL事件基本上报告了两种类型的事件：静态事件和动态事件。RAPL事件报告的静态事件是热规格，最大和最小功率上限以及时间窗口。来自芯片的RAPL域能量读数如PKG，PP0，PP1或DRAM是RAPL报告的动态事件。\n\n除了直接读取MSR之外，还可以从sysfs接口、perf事件或通过PAPI库读取RAPL读数。RAPL支持sysfs powercap接口是从Linux内核版本3.13启用的，perf_event_open支持需要Linux内核版本3.14。PAPI库用于收集与性能相关的数据。它与平台无关，它有一个RAPL接口，使用MSR驱动程序报告RAPL值。","tags":["RAPL"]},{"title":"OpenMP and MPI 学习资料","url":"/2019/08/23/OpenMP-and-MPI-学习资料/","content":"\n## 资料\n\n1. Parallel Programming in MPI and OpenMP.  http://pages.tacc.utexas.edu/~eijkhout/pcse/html/index.html\n\n2. MPI系列: 并行IO性能优化究竟是怎么玩的呢？. https://blog.csdn.net/BtB5e6Nsu1g511Eg5XEg/article/details/88084041\n\n","tags":["OpenMP","MPI"]},{"title":"论文阅读：Energy Measurement and Modeling in High Performance Computing With Intel RAPL (Doctoral Dissertation 2018)","url":"/2019/08/22/论文阅读：Energy-Measurement-and-Modeling-in-High-Performance-Computing-with-Intel-RAPL-Doctoral-dissertation-2018/","content":"\n## 摘要\n\n云计算范式的重大进步使得服务提供商使用云计算平台提供新旧服务，以实现弹性、可扩展性、可用性和成本效益等优势。此外，高性能计算社区到2020年实现E级计算的目标以及科学计算范式中生成和分析的数据的快速增长，为数据中心服务器系统数量的空前增长铺平了道路。例如，CERN现在每年生产、存储和分析大约30PB的和粒子物理相关的数据。社交网络，视频点播和大数据等应用的激增，只会增加数据中心服务器系统总数。如此庞大的耗电量大的服务器增加了数据中心的能源需求，因此HPC，科学计算和云计算的能效现在成为一个大问题。本文中研究了基于服务器的计算系统的能耗，并提出了用于测量、建模和分析这些系统的能效的实用解决方案。\n\n本文的工作广泛使用和分析了英特尔的运行平均功率限制（RAPL）作为能量测量工具。首先使用RAPL来分析应用程序的性能和能耗。其次，提出了两种策略来模拟计算系统的功耗：对CPU内部组件的功耗进行建模，如指令解码器、L2和L3高速缓存等，并使用操作系统计数器和RAPL对整个系统功耗进行建模。为了模拟功耗，本文使用了基于回归的模型，统计模型以及非线性加法模型。为了验证该发现，本文使用了来自数据中心的实际生产日志以及来自Amazon Elastic Compute Cloud（EC2）的实例。所提出的功率模型能够以可靠的精度预测功耗。第三，本文对RAPL作为功率测量工具进行了广泛的评估，并确定了RAPL在测量开销、准确性、粒度等方面的性能。这一综合分析还揭示了RAPL的一些开放性问题，这些问题可能会削弱其在某些情况下的可用性。本文也确定了相应的解决方案。最后，为了展示RAPL的适用性，本文分析了两个大型图形处理平台的能效：Apache Giraph和Spark的GraphX。\n\n## 研究分类\n\n* 测量运行科学工作负载的计算节点/服务器的功耗。获取计算节点的功率消耗是有益的，它有助于确定精确的能源支出，从而为系统分配适当的能源预算。此外，有助于适当地设置功率限制以最佳地利用定价变化（例如，当每小时电价较低时设置高功率限制，反之亦然）。\n* 计算系统的功率建模。预测计算系统的全系统功耗是数据中心内节能电源管理的基本信息。现有的功率测量工具（包括RAPL）不能提供完整的系统功耗，而是测量计算系统的有限组件（CPU，内存）的功耗。虽然CPU和内存消耗了大部分能量消耗，但完整的系统功耗是针对数据中心不同级别的能效目标的重要技术输入。\n* 分析科学计算工作负载的功耗行为以进行功耗优化。\n\n{% asset_img Figure1.png [20] [20]%}\n\n提高计算节点能效的方法：\n\n{% asset_img Figure4.png [20] [20]%}\n\n## 系统中功耗占比\n\n一些研究已经对数据中心内部的功耗进行了细分 [1,3]，如下图所示：\n\n{% asset_img Figure2.png [20] [20]%}\n\nOrgerie等人[2] 进一步提供典型服务器内部功耗的细分：CPU消耗约37.6％，内存消耗16.9％，磁盘消耗5.6％，PCI插槽消耗23.5％，主板和风扇消耗剩余的16.4％功率（见下图）。\n\n{% asset_img Figure3.png [20] [20]%}\n\n## 参考文献\n\n[1] M. Dayarathna, Y. Wen, and R. Fan. Data center energy consumption modeling: A survey. IEEE Communications Surveys Tutorials, 18(1):732–794, Firstquarter 2016.\n\n[2] J. Shuja, K. Bilal, S. A. Madani, M. Othman, R. Ranjan, P. Balaji, and S. U. Khan. Survey of techniques and architectures for designing energy-efficient data centers. IEEE Systems Journal, 10(2):507–519, June 2016. \n\n[3] Anne-Cecile Orgerie, Marcos Dias de Assuncao, and Laurent Lefevre. A survey on techniques for improving the energy efficiency of large-scale distributed systems. ACM Comput. Surv., 46(4):47:1–47:31, March 2014.\n\n ","tags":["Papers","Energy Modeling"]},{"title":"论文阅读：Using Performance-Power Modeling to Improve Energy Efficiency of HPC Applications （IEEE Computer 2016）","url":"/2019/08/05/论文阅读：Using-Performance-Power-Modeling-to-Improve-Energy-Efficiency-of-HPC-Applications/","content":"\n## 摘要\n\n要在HPC系统上开发节能应用程序，了解运行时、功耗和每个应用程序的独特特性之间的关系非常重要。在本文中，我们提出了一个功率和性能建模和节能框架，并使用此框架来模拟运行时、系统功率、CPU功率和内存功率。组合模型的性能计数器与应用程序信息结合使用，可以为识别可能降低能耗的应用程序修改提供基础。基于这些模型，我们开发了一个基于网页的假设预测系统，从理论上预测可能的优化结果。我们通过两个超级计算机Mira和SystemG 对两个应用程序，地震模拟和航空航天应用进行了验证。我们的计数器引导优化方法实现Mira上32,768个核心的能耗平均降低了48.65％，SystemG上256个核心的能耗降低了30.67％。\n\n## 研究背景\n\nHPC系统，特别是千万亿次超级计算机，目前消耗了大量的电力。目前500强名单中的前五大系统总耗电量超过50兆瓦，平均功耗为10兆瓦，平均性能为17.54千万亿次（http://www.top500.org/lists/2015/11/）。考虑到实现具有20MW功率的百亿亿次系统的愿望，人们认识到这样的系统将受到功率和能量消耗的极大限制，并且它需要独特的方法来平衡功率和性能。为此，理解运行时、功耗和每个大规模科学应用的独特特征（例如，循环结构，数据结构，数据移动，通信重叠，同步等）之间的关系是很重要的。关于这些关系的见解为应用程序优化提供了指导，以降低功率和能耗。优化可能涉及应用程序修改、系统调整或两者的组合。在本文中，我们将探讨这些组合。\n\n有许多应用程序优化方法可以减少运行时间，例如算法优化、循环嵌套优化、编译器优化技术等。还有许多编程模型、语言和运行时系统，如果经过深思熟虑，也可以减少运行时间。\n\n大多数供应商在硬件级别使用功率监视技术来动态地降低各种资源的功耗，简单的像旋转磁盘和降低空闲核心，复杂的实现异步时钟电路。如今，几乎所有微处理器都包含许多动态资源分配技术，以节省电力，同时按需提供性能。\n\n此外，还有***两种基于软件的技术可以降低任意工作负载的功耗。第一种是动态电压和频率调节（DVFS），其中根据策略和需求在一些时间窗口内动态调整CPU频率。另一种是动态并发限制（DCT），这种技术可以在类似的约束条件下在运行时调整并发级别。***\n\n***直观地节省能量意味着降低功率或减少运行时间，或两者兼而有之***。因此，该领域的所有研究可分为三类：（1）减少时间和功率;（2）在牺牲增加功率的同时减少时间;（3）在牺牲时间增加的情况下降低功率。功耗（$E$）是时间（$T$）范围的平均功率（$W$：平均功率）的能量，即$E = T * W$。为了阐明这三个类别，我们假设时间的百分比变化是 $a(0 <a <1)$，并且与进行修改的基线相比，功耗的百分比变化是 $b（0 <b <1）$。下面，我们提供三个类别的简单数学分析。\n\n（1）同时降低时间和功率\n\n假设时间降为 $T*(1-a)$,功率降为 $W*(1-b)$ ,那么相应的能耗降为$T*(1-a)*W*(1-b) = (1-a)(1-b)*T*W<T*W$,在这种情况下，能耗节省了 $1-(1-a)(1-b)=a+b-ab$ 。\n\n在[3]中，作者使用DVFS和DCT通过同时节能（平均6％）和性能改进（平均14％）实现了能量显着降低（平均19％）。在[6]中采用了类似的方法，平均节能4.18％，性能提升高达7.2％。在我们之前的工作[8]中，使用DVFS，DCT和代码修改，我们能够将运行时间降低多达14.15％并同时将功耗降低多达12.50％。\n\n（2）降低时间，增加功率\n\n假设减少的时间是 $T*(1-a)$，并且增加的功耗是 $W*(1+b)$ ，我们得到的能量：$T*(1-a)*W*(1+b)=(1-a)(1+b)* T* W$。如果 $(1-a)(1+b)*T*W <T*W$ ，即 $b-a-ab <0$，则发生能量减少。如果 $b≤a$，则发生节能。这种方法在通过资源利用率的增加（例如，并发性的增加）来减少运行时的方法中是常见的。\n\n（3）降低功率，增加时间\n\n假设时间增加到 $T*(1+a)$, 功率减少到 $W*(1-b)$，最终的能耗为 $T*(1+a)*W*(1-b)=(1+a)(1-b)*T*W$。如果 $(1+a)(1-b)*T*W<T*W$，也就是 $a-b-ab<0$，则能耗降低。如果 $a≤b$，则发生节能。这种方法在使用DVFS的方法中很常见。***理论上大多数应用程序都花费时间等待CPU之外的其他所有事情，因此降低CPU频率可以比性能成本节省更多功率。***这一概念促成了IBM（BlueGene），SiCortex（MIPS）和Calxeda（ARM）等供应商开发的新架构。\n\n在本文中，我们使用性能和功率建模方法，利用前两个类别来指导节能应用程序的开发，因为BG/Q只有固定的CPU频率设置（1.6GHz）。\n\n## 性能和功率建模\n\n有必要准确地测量或估计功耗。由于高频下的直接在线功率测量是不切实际的，因此硬件性能计数器已被广泛用作估计功耗的有效代理。硬件性能计数器已经包含在大多数现代架构中，并且暴露在商业硬件上的用户空间中。性能计数器通过计算特定事件（如高速缓存未命中、流水线停顿、浮点运算、字节输入/输出、字节读/写等）来监视系统组件（如处理器、内存、网络和I/O）。可以在硬件级别收集此类事件的统计信息，几乎没有开销。这使得性能计数器成为监视应用程序，分析其硬件资源使用情况以及估计其运行时和功耗的有力手段。\n\n以前关于功率建模和估计的大部分工作都是基于性能计数器[5,4,2,11,7,1,10,8,13,17]。这些方法使用性能计数器来监视多个系统组件。然后，作者尝试将这些数据与每个系统组件消耗的功率相关联。该相关性用于推导可以估计每个系统组件的功耗的模型。其结果的准确性取决于性能计数器的选择/可用性，评估的基准/应用以及所使用的特定统计数据拟合方法。许多上述方法使用一小组性能计数器（通常少于10个计数器）进行功率建模。在我们最近的工作[8]中，我们针对指标开发了四种不同的模型：基于40个性能计数器的运行时，系统功耗，CPU功率和内存功率。我们发现用于每个不同模型的性能计数器并不相同。在研究六种科学应用时，我们发现共有37种不同的性能计数器用于模型，从模型到模型只有3或4个计数器是相同的。\n\n为了开发运行时和功耗模型，**我们在一个系统上收集了40个可用的性能计数器，这些计数器具有不同的系统配置（核心数，节点数）和应用程序问题大小。然后，我们使用Spearman相关和主成分分析（PCA）来识别主要性能计数器($r_1,r_2,\\cdots r_n (n<40)$)，这些计数器与度量运行时、系统功率、CPU功率或内存功率高度相关。然后我们使用非负多元回归分析来生成基于一小部分主要计数器和CPU频率（$f$）的四个模型。**\n\n对**运行时间$t$建模**如下：\n\n$$\n t=\\beta_0+\\beta_1*r_1+\\cdots+\\beta_n*r_n+\\beta*\\frac{1}{f} \\tag{1}\n$$\n\n在这里，$\\beta_0$是截距，$\\beta_n$表示性能计数器$r_n$的回归系数，$\\beta$是CPU频率$f$的系数。\n\n类似地，我们可以使用以下等式对**CPU功耗 $p$ 进行建模**：\n\n$$\n p=\\alpha_0+\\alpha_1*r_1+\\cdots +\\alpha_n*r_n+\\alpha*f^3  \\tag{2}\n$$\n\n在这里，$\\alpha_0$是截距，$\\alpha_n$表示性能计数器$r_n$的回归系数， $\\alpha$是CPU频率$f$的系数。系统功率和存储器功率模型的等式与等式2类似。\n\n## 建模与节能框架\n\n图1是我们基于计数器的建模和节能框架的功能的总图。我们使用MuMMI [16]收集性能计数器以及我们希望关联的四个指标，并将数据上传到MuMMI数据库。所有性能计数器都根据执行的总周期数进行标准化，以便为每个计数器创建性能事件率。接下来，执行Spearman相关和主成分分析（PCA）以识别与四个指标相关的重要计数器。然后，使用等式1和2，基于减少的计数器组和CPU频率，使用非负多元回归分析来生成四个模型中的每一个。我们之前的工作表明运行时和功率模型对于所使用的六种科学应用，预测误差率平均低于7％。MuMMI提供基于Web的建模系统，可根据计数器的数据和MuMMI数据库中的四个指标自动生成运行时和功率模型。\n\n{% asset_img Figure1.png [20] [20]%}\n\n在指标的四个模型的基础上，我们实施了一个计数器排名方法，以确定哪些测量计数器做出了重大贡献。然后，这些计数器用于指导应用程序修改，以实现运行时和功耗的减少。\n\n#### 计数器相关性分析与排序\n\n一旦我们获得了运行时、系统功耗、CPU功率和内存功率的模型，我们就会确定四个模型中每个模型的最重要的性能计数器。\n\n{% asset_img Figure2.png [20] [20]%}\n\n排名算法如图2所示，其工作原理如下：首先，创建计数器列表，其由具有最高系数百分比的计数器组成。根据运行时间、系统功率、CPU功率和存储器功率的顺序，这些计数器的系数与四个模型的所有系数之和的比率最高。其次，按照相同的顺序，我们从计数器列表中删除无效的计数器（小于1％的计数器）。最后，我们使用成对的Spearman相关性来分析和排序这些计数器之间的相关性，以识别对模型最有效贡献的计数器，以形成最终的计数器列表。进行修剪使得如果具有较高等级的计数器与较低等级的计数器高度相关，则消除具有较低等级的计数器。结果列表的计数器用于指导应用程序修改。\n\n#### 节能策略推荐\n\n众所周知，性能计数器的值与影响性能和功耗的应用程序的属性相关。许多代码优化仅专注于改进缓存重用以减少应用程序运行时间，因为已知内存访问是大多数体系结构的主要瓶颈。但是，这些努力通常基于来自几次运行的性能数据，而很少考虑数据依赖性，问题大小和/或系统配置。此外，他们倾向于忽视功耗问题。在这项工作中，性能和功耗模型是根据不同的系统配置和问题大小生成的，因此可以广泛了解应用程序对底层架构的使用。这样可以更好地了解应用程序在给定体系结构上的能耗。例如，如果我们将计数器 $r_1$ 和 $r_2$ 作为最重要的计数器，其中 $r_1$ 在运行时模型中占主导地位，而 $r_2$ 在功率模型中占主导地位，并且发现两者都是不相关的，那么我们对应用程序的修改将集中在两个计数器上。通过这种方式，我们的修改不仅可以减少应用程序运行时间，还可以降低功耗。但是，使用通用、功能无意识的性能工具，如gprof，TAU，ScoreP，HPCToolkit，HPM Toolkit和CrayPat，对计数器 $r_2$ 的影响也许完全不被注意。\n\n请考虑以下事项：假设$r_i$，$r_j$和$r_k$为三个性能计数器，这些计数器对运行时模型（公式1）或功率模型（公式2）（系统、CPU、或内存的功率模型）有着显著的贡献。其中$r_i$被认为是最重要的。$r_i$和$r_j$的相关值为0.9，与$r_k$的相关值为0.6。如果$r_i$的值减少20%，则$r_j$的值降低18%（0.9*20%），$r_k$的值减少12%（0.6 * 20%）。在此假设下，我们使用等式1和2来预测对运行时和功耗的理论影响。\n\n通常，基于运行时和功率模型以及计数器相关性，我们开发了一个基于Web的假设预测系统，用于在理论上预测可能的优化结果，如图3所示，例如，给定应用程序PMLB [15] ，如果TLB_IM的数量减少20％，相关计数器将根据它们与TLB_IM的相关值减少，运行时间减少4.13％，平均节点功率几乎相同，CPU和内存功耗也减少了一点。\n\n{% asset_img Figure3.png [20] [20]%}\n\n然后立即出现一个问题，即如何将计数器$r_i$的值减少20％。这需要彻底了解应用程序特征以及影响该特定度量标准的底层架构部分。在[12]中，讨论了几种典型的代码性能模式，并映射到一些可以帮助代码优化的硬件度量。重要的是要意识到像PAPI预设[9]这样的通用性能计数器可能很容易被用户误解为不同的体系结构。用户必须在体系结构手册中查找确切的定义，并了解应用程序特征和底层体系结构单元如何影响计数器。\n\n## 案例研究：性能计数器引导的能源优化\n\n在本节中，我们使用两个科学应用：并行航空航天应用PMLB [15]和并行地震模拟eq3dyna [14]，来讨论在两个功率感知超级计算机Mira，和SystemG上的性能计数器引导的能量优化。\n\n#### PMLB on SystemG \n\n图4显示了四个模型的性能计数器排名，使用15个不同的PMLB计数器，SystemG上的问题大小为128x128x128。我们将图2中的排名算法应用于四个模型中的每一个的计数器。将它们从最重要到最小排序，它们是：TLB_IM（指令转换后备缓冲器（TLB）未命中），VEC_INS（向量/ SIMD指令），TLB_DM和L2_ICM。 \n\n{% asset_img Figure4.png [20] [20]%}\n\nTLB_IM排名最高，其次是VEC_INS。我们使用成对的Spearman相关来分析两个计数器之间的相关性，如下所示：\n\n{% asset_img Figure5.png [20] [20]%}\n\n我们发现计数器TLB_IM仅在运行时模型中有贡献，并且它与TLB_DM和L2_ICM相关。然而，VEC_INS在系统功率，CPU功率和存储器功率的模型中有所贡献，并且与任何其他计数器无关。因此，我们专注于对SystemG上的计数器TLB_IM和VEC_INS进行优化。从理论上讲，使用我们的假设预测系统，将TLB_IM的数量减少20％可以使运行时间减少4.13％;将VEC_INS加速20％导致节点功率降低1.85％。\n\nSystemG上的Linux系统支持两种页面大小，默认为4KB，大页面为2MB。单个2MB大页面只需要一个TLB条目，而等量的内存需要使用4KB页面的512个TLB条目。因此，为性能受TLB未命中约束的应用程序启用此类页面大小可能具有显着的益处。在这里，我们使用libhugetlbfs为应用程序执行启用了2MB页面，以减少TLB未命中。我们还对代码进行了矢量化，并使用编译器选项-ftree-loop-distribution来执行循环分配，以提高大循环体上的缓存性能，并允许进行进一步的循环优化，如矢量化。\n\n这些优化的结果如图5所示. SystemG每个节点有8个核心。我们观察到应用程序运行时间平均减少了11.23％（图5（a）），系统功率平均增加了0.01％（图5（b））。图5（c）中的CPU功率平均增加了2.13％，图5（d）中的存储器功率平均增加了0.61％。总的来说，这意味着平均节能11.28％。据观察，平均节能百分比（11.28％）大于运行时间改善百分比（11.23％），这意味着减少运行时间和功率会导致更大的节能。\n\n{% asset_img Figure6.png [20] [20]%}\n\n## 总结\n\n使用我们的基于性能计数器的建模和节能框架，我们开发了一个基于Web的假设预测系统，从理论上预测可能的优化结果。**我们相信这个框架可以应用于在其他架构上执行的大规模科学应用，包括GPGPU等硬件和Intel-Xeon Phi等多核加速器，并且可以使用一个架构上的这些应用的功率和性能模型来预测具有类似架构的大规模系统的功耗和性能。我们的方法代表了一种通用的全面优化方法，专注于最有效地利用可用资源，平衡运行时间与功耗。通过这种方式，我们希望我们的方法能够为应用程序和系统开发人员提供额外的指导，以开发下一代节能应用程序和超级计算机。**\n","tags":["Papers","Energy Modeling","Journal"]},{"title":"Pareto最优相关介绍","url":"/2019/08/04/Pareto最优相关介绍/","content":"\n## Pareto Optimality（帕累托最优）\n\n帕累托最优是指资源分配的一种理想状态，即假定固有的一群人和可分配的资源，从一种分配状态到另一种状态的变化中，在没有使任何人境况变坏的前提下，也不可能再使某些人的处境变好。换句话说，就是不可能再改善某些人的境况，而不使任何其他人受损。 \n\n## Pareto解\n\n多目标规划中，由于存在目标之间的冲突和无法比较的现象，一个解在某个目标上是最好的，在其他的目标上可能比较差。Pareto 在1986 年提出多目标的解不受支配解(Non-dominated set)的概念。其定义为：假设任何二解S1及S2对所有目标而言，S1均优于S2，则我们称S1 支配S2，若S1没有被其他解所支配，则S1 称为非支配解（不受支配解），也称Pareto解。 \n\n## Pareto Front\n\nPareto解的集合即所谓的Pareto前沿。座落在Pareto front 中的所有解皆不受Pareto Front 之外的解（以及Pareto Front 曲线以内的其它解）所支配，因此这些非支配解较其他解而言拥有最少的目标冲突，可提供决策者一个较佳的选择空间。在某个非支配解的基础上改进任何目标函数的同时，必然会削弱至少一个其他目标函数。\n\n## 参考\n\n[1] Pareto. https://blog.csdn.net/scutwjh/article/details/46129405\n\n","tags":["统计学"]},{"title":"Q-Q图介绍","url":"/2019/08/04/Q-Q图介绍/","content":"\n## 什么是Q-Q图？\n\nQ-Q图（Quantile-Quantile Plots）是一种散点图，横坐标为某一样本的分位数，纵坐标为另一样本的分位数，横坐标与纵坐标组成的散点图代表同一个累计概率所对应的分位数。分位数是某些值低于该分位数的值，例如，中位数是一个分位数，其中50%的数据低于该点，50%高于该点。Q-Q图的目的是确定两组数据是否来自同一分布。在Q-Q图上绘制45度角;如果两个数据集来自共同分布，则这些点将落在该参考线上。\n\n{% asset_img Figure1.png %}\n\n上图显示了水平轴上理论正态分布的分位数。它与y轴上的一组数据进行比较。这种特殊类型的Q-Q图称为常规Q-Q图。这些点没有聚集在45度线上，实际上遵循曲线，表明样本数据不是正态分布的。\n\n## 如何创建Q-Q图？\n\n示例问题：以下数据是否来自正态分布？\n\n7.19, 6.31, 5.89, 4.5, 3.77, 4.25, 5.19, 5.79, 6.79.\n\n（1） 步骤1：将数据从小到大排序。\n\n3.77， 4.25，4.50，5.19，5.89，5.79，6.31，6.79，7.19\n\n（2）步骤2：绘制正态分布曲线。将曲线分成n + 1个段。我们有9个值，因此将曲线分成10个大小相等的区域。对于此示例，每个段是区域的10％（因为100％/ 10 = 10％）。\n\n{% asset_img Figure2.png %}\n\n（3）步骤3：在该步骤中找到每个段的z值（截止点）。这些段是区域，因此请参考z表（或使用软件）获取每个段的z值。\n\nz值为：\n\n- 10% = -1.28\n\n- 20% = -0.84\n\n- 30% = -0.52\n\n- 40% = -0.25\n\n- 50% = 0\n\n- 60% = 0.25\n\n- 70% = 0.52\n\n- 80% = 0.84\n\n- 90% = 1.28\n\n- 100% = 3.0\n\n  \n\n{% asset_img Figure3.png %}\n\n（4）第4步：根据正态分布截止点绘制数据集值（步骤1）（步骤3）：\n\n{% asset_img Figure4.png %}\n\n此Q-Q图上的数据几乎是一条直线，表示数据大致满足正态分布。\n\n**注意：**\n\n> 此示例使用标准正态分布，但如果认为你的数据可能来自不同的正态分布（即具有不同均值和标准偏差的分布），那么你可以使用它。\n>\n> 对于许多统计测试来说，正态性假设是一个重要的假设；假设你是从正态分布的人群中取样的。正态Q-Q图是评价正态性的一种方法。但是，你不必使用正态分布作为数据的比较；你可以使用任何连续分布作为比较（例如威布尔分布或均匀分布），只要你可以计算分位数。\n\n## 参考\n\n[1] Q-Q Plots: Simple Definition & Example.  https://www.statisticshowto.datasciencecentral.com/q-q-plots","tags":["统计学"]},{"title":"论文阅读：Energy Efficiency Modeling of Parallel Applications (SC18)","url":"/2019/08/03/论文阅读：Energy-Efficiency-Modeling-of-Parallel-Applications-SC18/","content":"\n## 摘要\n\n随着功率限制和成本的增加，能效在高性能计算（HPC）中变得越来越重要。工作负载和系统特性构成了一个复杂的优化搜索空间，其中能效和性能的最佳设置通常不同。因此，我们必须确定性能和能效的权衡选择，以找到它们之间的理想平衡。我们提出了一种创新的统计模型，该模型仅使用用户可控参数准确预测帕累托最优性能和能效折衷选项。我们的方法也可以容忍测量和模型误差。我们使用多个HPC内核研究模型训练和验证，然后探索将模型应用于更复杂的工作负载（包括AMG和LAMMPS）的可行性。我们可以从最少12次运行校准精确模型，预测误差小于10％。我们的结果确定了权衡选项，能够以低于20％的性能损失为代价，将能效提高40％。对于AMG，我们将所需的样品测量时间从13小时减少到74分钟（约90％）。\n\n## 研究背景\n\n目前，功率限制限制了超级计算机中CPU核心和计算节点的数量。我们必须开发创新方法来预测并行计算的性能和能源使用之间的关系。根据情况，在应用开发和部署中，性能和能效之间的可用权衡选择至关重要。系统资源管理必须通过在运行时正确配置应用程序来最大限度地满足给定功率预算。此外，程序员需要实用的工具来有效地识别和选择权衡选项，以优化其并行应用程序的能源效率。\n\n不幸的是，许多因素影响了权衡。这些因素包括应用程序特征，如计算强度，内存和通信访问模式，以及系统因素，如缓存设计，内存和网络带宽。因此，优化这种多目标问题的工具[4]必须搜索大而复杂的空间。\n\n***帕累托边界通常代表能源使用与性能之间的权衡选择***。因此，可以通过预测帕累托前沿的最佳配置的模型来估计权衡选项。我们提出了一种回归建模技术，可以预测帕累托最优能量效率和性能权衡选项，但不需要完整的遍历搜索空间。\n\n与现有的基于模型的方法[5]，[6]，[7]，[8]相比，我们的技术具有一些优势，可以提高并行计算的能效。首先，它只需要一组最小的输入变量，超级计算机用户可以自己简单地访问和控制。相比之下，大多数现有模型[5]，[6]建立在几个直接反映能效的运行时测量上，例如计算强度，高速缓存未命中率，停顿周期，存储器访问次数和网络通信量。虽然这些模型提供了有价值的见解，但这些参数对于应用程序用户来说很难控制。获取这些测量值的过程也增加了将这些模型自动化为实用工具的难度。其次，我们的模型在预测的权衡选项中考虑样本测量误差和模型预测误差。第三，大多数现有模型不直接给出帕累托效率配置。\n\n我们证明了我们的模型以低成本准确地预测了混合MPI/OpenMP程序的最佳配置的Pareto前端。我们提出了一项研究，评估代表性并行内核和应用程序模型的拟合和方差。通过研究，我们发现我们的方法和模型可以成功识别与广泛的搜索优化空间方法的测量数据一致的权衡选项。此外，构建我们的模型只需要一小组样本测量，这样可以最大限度地减少训练所需的工作量和资源。总的来说，我们的模型是实用的自动化工具的理想选择。\n\n具体而言，本文提出了以下贡献：\n\n（1）使用并行应用程序用户可以直接控制的参数进行能源和性能权衡;\n\n（2）一种从少量输入测量中预测能效和性能权衡选项的实用方法;\n\n（3）准确预测并行应用响应的多目标能效和性能模型;\n\n（4）在给定测量和/或建模误差的情况下，权衡区方法可改善Pareto优化。\n\n## 研究方法\n\n#### 模型预测器\n\n{% asset_img Figure1.png %}\n\n初始步骤选择模型输入参数或预测器，可以准确地模拟我们的响应：系统能效和性能。之前的工作[29]表明系统特性，工作负载特性，并发性，CPU频率缩放和观察到的系统响应之间存在复杂的关系。我们使用表I中的定义来表达这些关系，如等式1和2所示。\n$$\nE(w_n,s_m)=F_e(n_i,c_j,f_k)\\tag{1}\n$$\n\n$$\nP(w_n,s_m)=F_p(n_i,c_j,f_k)\\tag{2}\n$$\n\n#### 模型形式化\n\n为了制定多元回归模型，我们首先使用节点数量，核心数量和CPU频率设置作为模型输入来分析一组代表性软件内核的响应。观察到的曲线性能和能量效率响应意味着模型需要多项式项。\n\n多项式的不灵活性可以极大地影响基本多项式拟合。它可能导致预测响应中的不期望的振荡，或者由小样本子集过度影响的总响应形状。为了最小化这种不灵活性的影响，我们从使用普通最小二乘回归的B样条分段多项式模型开始。我们发现样条在我们的实验中始终优于基本多项式。\n\n样条函数用于沿一系列点或节点拟合平滑曲线。我们构造了从多项式函数中连接每一对点或样条的曲线。B样条或基本样条函数可改善结的连续性，否则可能会影响模型的连续性。\n\n我们有几种配置选项可以调整模型的准确性和效率。我们考虑包括样条的多项式度和自由度的选项。增加这些模型参数允许样条曲线拟合更复杂的曲线。我们还考虑了项，线性和非线性项之间的相互作用，转换以减少数据分布偏差的影响，以及采样方法。\n\n为了指导模型调整，我们观察每个预测因子在响应中驱动的可变性水平，并使用预测变量之间预期相互作用的知识边缘。例如，增加核心数会驱动产生非线性响应的资源争用。增加CPU频率通常会驱动线性响应，直到节点内的核心争用开始占主导地位。这些观察引导我们进行以下模型设置和简化：\n\n（1）B样条自由度为3;\n\n（2）节点和核心数是二次多项式项;\n\n（3）CPU频率是一个线性项;\n\n（4）节点和核心数有一个交互项;\n\n（5）核心数和频率有互动项;\n\n（6）频率和节点数没有交互项;\n\n（7）响应的自然对数变换。\n\n为了通过实验评估模型设置，我们使用迭代方法来评估数据分布和相关性，模型拟合度和系数量值。例如，我们通过实验将模型拟合与CPU频率作为多项式或线性项进行比较，发现线性项选项在我们的研究测试案例中提供了平均RMS误差的轻微改善（2.3％）。我们还通过实验确定了模型欠拟合和过度拟合之间的过渡点处的最优多项式项顺序和B样条自由度。例如，核心数量和频率交互项的近零系数证实我们可以将其从模型中移除而几乎没有影响。\n\n因此，我们在均匀HPC群集上运行的并行应用的能效和性能统计模型使用公式3和4。\n$$\nlog_e(e_\\eta)\\sim bs(n_i)+bs(c_j)+f_k+bs(c_j):f_k+bs(n_i):bs(c_j)\\tag{3}\n$$\n\n$$\nlog_e(p_\\mu)\\sim bs(n_i)+bs(c_j)+f_k+bs(c_j):f_k+bs(n_i):bs(c_j)\\tag{4}\n$$\n\n这些方程基于Wilkinson符号，它被回归分析工具（如MAT LAB，或R和Python编程库）所接受。所使用的运算符\"~\"表示模型的构成，“+”表示在模型中添加项，“:”表示两项之前的交互关系。\n\n除了能效和性能率之外，模型还可以基于等式5和6来获取例如总能量和总时间的累积响应。\n$$\nlog_e(e_T)\\sim bs(n_i)+bs(c_j)+f_k+bs(c_j):f_k+bs(n_i):bs(c_j)\\tag{5}\n$$\n\n$$\nlog_e(t_T)\\sim bs(n_i)+bs(c_j)+f_k+bs(c_j):f_k+bs(n_i):bs(c_j)\\tag{6}\n$$\n\n我们将自然指数应用于模型预测以反转对数变换。\n\n公式7显示了方程3到6的右侧扩展。每个模型有20个预测项（1个截距，1个线性项，2$\\times$3个样条B样条项，1$\\times$3个样条B样条$\\times$3个样条B- 样条相互作用项，1$\\times$3样条B样条$\\times$1个线性项。我们收集预测因子和响应训练数据，然后使用最小二乘回归来确定各项系数，$\\beta_1$ 到$\\beta_{19}$。\n\n{% asset_img Figure2.png %}\n\n#### 模型评估\n\n为了评估模型，我们使用相关分析，$k$交叉验证，RMS误差和$R^2$统计。我们从许多测量样本中推导出这些量，以便对模型精度进行统计上显着的验证。我们在第V，VI和VII节中的结果表明，一小部分测量数据足以满足模型的系统和工作负载特定系数。\n\nSpearman相关系数$\\rho$是预测因子和响应之间相关性的非参数度量。接近零的值表示弱相关性。当我们选择预测变量时，我们使用此统计量来验证假设。\n\n$R^2$ 统计量衡量模型与训练数据的拟合程度，$R^2$ 接近100％表示更好的拟合。RMS误差是预测误差或回归残差的标准偏差。它衡量密切观察的数据如何适应模型生成的数据预测。接近零的RMS误差值表示模型预测与观测数据之间的紧密拟合。\n\n$k$交叉验证方法将数据集划分为$k$个等大小的子集。$k-1$个子集用作模型训练数据，剩余子集是模型测试数据。我们重复这个过程来测试整个数据集的模型精度。我们使用3交叉验证来确认模型不会过度拟合数据的子集。\n\n#### 帕累托前沿评估\n\n 我们计算观察到的和预测的帕累托前沿之间的RMS误差，但也使用进一步的特定技术来评估预测前沿的准确性。我们使用以下指标评估帕累托前沿准确度：\n\n（1）重叠点数，即在观察和预测前沿中出现的点数;\n\n（2）观察前沿上的非重叠点数，按预测前沿距离最近邻居的距离分组;\n\n（3）预测前沿上的非重叠点数，按观察前沿距离最近邻居的距离分组;\n\n（4）预测的和观察的每个目标的最小值和最大值（能效或性能）;\n\n（5）预测的和观察的每个目标的权衡范围与线程和CPU频率处于最大设置时的值相比较。\n\n我们测量到最近邻居的距离占搜索空间维度的百分比。例如，我们每个节点维度的线程数有4个增量，从4到44，步长为4.从36到40的距离为1/11 = 9％，36到44为2/11 = 18％。此选择可以跨尺寸标准化。\n\n#### 测量和建模误差\n\n由于系统的非确定性，性能和功率测量表现出实验误差和噪声。这些测量误差通常是分布的，是由一系列随机因素引起的。正态性测试可以验证我们的功率和性能测量是否正常分布。我们使用Q-Q（分位数 - 分位数）图来直观地比较我们的测量数据分布与标准正态分布。我们使用$t$分布来分析测量置信区间。我们的模型使用的$log_e$变换减轻了正态分布偏差。\n\n模型预测表现出预测误差。因此，当我们确定性能和能效之间的权衡选择时，我们必须考虑测量和预测误差。错误限制内的有效权衡选项位于靠近帕累托前沿的区域，而不是仅直接位于其上。我们引入了权衡区（trade-off zone）的概念，其中包括帕累托前沿附近的所有值，这些值在统计上与前面的值无法区分。\n\n{% asset_img Figure3.png %}\n\n图1显示了我们构建权衡区的过程：\n\n(1) 根据权衡参数绘制数据集（在我们的例子中，能效和性能）;\n\n(2) 沿帕累托最优点绘制帕累托前沿;\n\n(3) 水平和垂直延伸帕累托前沿外部界限，以包含前面的在各自轴上误差范围内的点（我们还使用此曲线计算预测的帕累托前沿的与观察值的RMS误差）;\n\n(4) 通过轴误差限制来缩放和平移帕累托前沿，以设置权衡区的内部界限;\n\n(5) 关闭两条曲线，创建一个代表权衡区的多边形。\n\n当我们补偿每个轴的误差极限时，权衡区多边形包围可能是帕累托最优的点集。这些要点为能效和性能提供了权衡选择。由于测量和预测的误差限制可能不同，我们为测量和预测的Pareto前沿单独设置误差限制。\n\n我们的模型仅将测量数据用于响应变量，这提供了两个重要的好处。首先，我们的拟合模型系数不会受到响应测量中随机误差的影响。这意味着我们的回归估计倾向于训练数据的平均值，加上或减去测量误差。其次，我们的模型可用于对看不见的预测数据进行预测，因此我们实际上可以通过少量训练测量来探索大的参数空间。\n\n通过确保与程序初始化和关闭时间相比总体执行时间较长，并且与系统功率计数器的时间分辨率相比，执行时间较长，我们可以将测量误差水平控制在5％左右。在具有较大测量误差的较少受控环境中，随着更多数据点落入误差限制内，权衡区的大小将增加。搜索空间的完整实验测量扫描将受到增加的测量误差的类似影响。我们使用估计的测量误差和模型误差来评估观察到的和预测的权衡区域之间的对齐或重叠水平。\n\n## 实验概述\n\n#### 平台\n\n我们在Cray XC系统上进行实验，如表II所示。我们的运行最多使用86个，专门分配44个核心节点，或总共3,784个核心。我们使用Python编程平台[35]进行相关性分析，拟合模型系数，评估响应，并绘制结果。Nimrod工具包用于协调实验任务。\n\n{% asset_img Figure4.png %}\n\n#### 能耗测量\n\nCray XC系统具有节点级传感器，用于测量温度，电流和电压。Cray电源管理计数器（pm_counters）提供实时功率和能量测量，以10Hz的频率更新。CrayPAT是一种性能分析工具，它使用性能计数器（包括pm_counters和硬件性能计数器（HWPC））来评估程序行为。它检测程序，在运行时收集指定的计数器，并报告收集的计数器。当程序启动或终止时，也可以直接从Linux sysfs文件夹/sys/cray/pm_counters读取Cray pm_counters。我们使用pm_counters监控所有节点的能耗和功率。为了评估能效，我们使用每焦耳的操作数（例如，Flops/J，Bytes/J，Updates/J）。\n\n#### 参数配置\n\n表III列出了我们在研究中使用的配置参数和相关范围。这些参数生成具有484种组合的全因子设计。\n\n{% asset_img Figure5.png %}\n\n#### 实验\n\n我们在两个主要阶段进行研究实验：\n\n（1）使用程序内核进行模型设计和评估;\n\n（2）使用应用程序的模型评估。\n\n程序内科和应用程序都使用混合MPI/OpenMP编程模型。我们配置实验作业，为每个CPU插槽分配一个MPI Rank，为每个CPU核心分配一个OpenMP线程。我们使用Scatter线程放置策略在可用插槽和节点之间统一分发OpenMP线程。对于每个实验，我们收集表III中列出的完整484个样品组合，对于三个程序内核和两个应用程序总共进行2,420次测试。\n\n## 程序Kernel测试\n\n本节说明我们可以针对特定计算常用的几个科学内核以低成本准确地预测帕累托最优能量和性能权衡选项。我们选择Parallel Research Kernels（PRK）[1]，这包含着一系列程序，涵盖并行HPC应用程序中遇到的通信、计算和同步的常见模式。PRK具有性能指标报告，这使我们能够专注于功耗属性，以识别能源优化机会。在PRK中可用的混合MPI/OpenMP kernels中，我们专注于以下三个内核：\n\n（1）Stencil：一个内核，它执行数据并行模板操作到二维数组;\n\n（2）Transpose：一个强调通信和内存带宽的内核;\n\n（3）Nstream：一个易并行内核，它可以计算内存带宽。\n\n**这里我们以Stencil来说明本文方法的操作过程。**\n\n#### Stencil内核\n\n模板的模型响应项是MFlops/J中的能量效率和MFlops/s中的性能。我们使用模板半径2，网格大小400k，并设置迭代，以确保运行时间至少是测量采样频率的10倍。\n\n{% asset_img Figure6.png %}\n\n我们评估了几种生成模型训练数据的方法，包括均匀采样，随机采样和拉丁超立方采样。图2显示了我们的11核心数×11频率搜索空间，其中包含均匀或非随机样本、随机样本和拉丁超立方体样本，这些样本从每行和每列中随机选择样本。 \n\n我们使用RMS误差和 $R^2$ 统计数据评估每种采样方法，如第III-C节所述。我们使用统一采样在我们的测试案例中获得最少的观察结果。**我们的方法需要12个样本或10％的搜索空间进行模型训练（4个核心数 $\\times$ 3个频率样本）**。我们的核心数分别为8,20,32和44个核心，频率分别为1.2,1.8和2.2 GHz。我们还在节点数为20,42,64和86的情况下评估模型，总数据集大小为484个样本。\n\n{% asset_img Figure7.png %}\n\n图3包括95％ $t$-分布置信区间下5个样本平均值的误差条。对于我们的实验，测量误差范围约为5％。我们希望使用我们的模型设置工具将包括一个校准步骤，用于计算每个响应变量的测量置信区间。该策略消除了每个训练样本的样本重复，以计算其置信区间。相反，如果回归结果的统计显着性不在设定限度内，我们会提醒用户。\n\n{% asset_img Figure8.png %}\n\n图4显示了64个节点上模板的实验观察和模型预测Pareto前沿。前面的点不是帕累托最优，因为前面的点总是提供一个参数的改进而对另一个参数的影响较小。我们沿着测量和预测的帕累托前沿缩小了权衡区域，误差率为5％。\n\n线程数和频率之间的相互作用决定了帕累托前沿的形状。图4显示数据点按线程数量分组，并随着频率变化而旋转。这种旋转定义了帕累托前沿的形状，它设定了能量与性能的权衡范围。\n\n{% asset_img Figure9.png %}\n\n表IV显示了完整的121个观察值和预测值之间的RMS误差，能效为4.8％，性能为4.8％。帕累托前沿的RMS误差为能效效率的5.1％和性能的11.4％，我们按照第III-E节中的步骤3）进行计算。表IV中的Pareto Front部分显示了类似的观察和预测的Pareto点计数，除了一个重叠点（4个线程或0.1 GHz）的9％或一个搜索步骤之外的所有非重叠点。\n\n表IV还显示了最大核心和线程的 $Baseline$ 性能和能量效率，以及它们沿帕累托前沿的最小值和最大值，$P_{min}$ 和$P_{max}$。\n\n观察到的和预测的能效增益是相似的（约40％）。性能提升接近20％。观测和模型预测的Pareto前沿提供了一致的视图，核心和频率调整可以提供40％的能效增益，同时对性能的影响最小 。\n\n{% asset_img Figure10.png %}\n\n{% asset_img Figure11.png %}\n\n图5和图6中的表面表示在CPU频率和线程数搜索空间中观察到的和预测的能量效率和性能。我们在这些曲面上绘制Pareto点以在搜索空间中显示它们的上下文。\n\n图6显示随着频率和核心数量的增加，性能会提高，然后会趋于平稳。平衡标志着权衡区的开始，但是如图5所示，由于资源争用，能源效率在该位置显著下降。能效与性能之间的这种差异意味着，与仅最小化运行时间的策略相比，调整可显着提高能效。\n\n#### 真实应用测试\n\n实验中还选择了真实的并行应用程序，AMG，LAMMPS。对于AMG，能耗减少15%，性能损失20%；对于LAMMPS，能耗减少30%，但是性能损失30%。\n\n#### 3-交叉验证\n\n我们使用交叉验证来表明我们的模型不会过度拟合数据的子集。通过3交叉验证，我们将数据集随机分成三个大小相等的子集。两个子集用作模型训练数据，其余子集用作模型测试数据。我们重复该过程三次以测试整个数据集中的模型精度。\n\n{% asset_img Figure12.png %}\n\n表VIII显示了研究内核/应用的能效模型的交叉验证结果。每个内核的数据集有484个样本，因此数据集分为两个部分，一部分包含两fold，每fold中有161个样本，一部分包含一fold，共162个样本。我们显示每个fold的预测值百分比低于20％，10％和5％以及fold的RMS误差。跨越fold的相对均匀的RMS误差结果表明我们的能效模型不会过度拟合任何数据子集。\n\n{% asset_img Figure13.png %}\n\n表IX显示了使用相同数据集的性能模型的结果。整个fold的一致RMS误差结果表明，我们的性能模型也不会过度拟合任何数据子集。 \n\n## 参考\n\n[1] Parallel Research Kernels. https://github.com/ParRes/Kernels","tags":["Papers","Energy Modeling","SC"]},{"title":"论文阅读：Energy-Dfficient Application Resource Scheduling Using Machine Learning Classifiers (ICPP18)","url":"/2019/08/02/论文阅读：Energy-dfficient-Application-Resource-Scheduling-using-Machine-Learning-Classifiers-ICPP18/","content":"\n## 摘要\n\n高性能计算（HPC）中的资源调度通常旨在最小化应用程序运行时间而不是优化能量效率。大多数关于降低功率和能量消耗的现有研究强加了允许很少或没有性能损失的约束，这改善但仍然没有最大化能量效率。通过优化能量效率而不是应用执行时间，我们可以降低运行科学应用的成本。本文提出使用由低级硬件性能计数器驱动的机器学习分类来预测在应用程序运行时期间使用的最节能的资源设置，这与静态资源调度不同，动态地适应不断变化的应用程序行为。我们使用四种复杂的生物信息学HPC应用程序评估我们在大型共享内存系统上的方法，将对基本的Race调度的能量消耗平均降低20％，并最多时能达到38％。运行时间平均增加31％的代价之下是功耗降低了39％，我们从中推断出未来过度配置、功率受限的集群吞吐量将增加24％的可能性。这项工作证明了低开销分类方法适用于在应用程序运行时期间动态优化能量效率。\n\n## 研究背景\n\n在未来的百亿亿次系统中，能源和电力消耗将是首要的制约因素。例如，这些系统预计有严格的运行预算，如20MW。此外，E级操作系统需要有效地降低每一次科学计算的成本。目前已经存在大量研究工作，通过直接优化科学计算时间开销来最大化HPC的性能。但是最近的研究（理论和实践）证明，为应用程序分配最大的资源并没有比智能地根据特定应用程序的需求调整资源使用策略更加节能。因此，一些研究在保证应用程序性能的同时降低能耗，来进一步减少科学计算的开销。然而，目前很少有工作来积极地减少系统能耗。即使运行时间增加，也要最大限度地减少应用程序的能耗，可以大大降低科学洞察力的成本（以焦耳为单位），并在过度配置的功耗受限系统（例如未来E级计算机）中增加应用的吞吐量，允许更多应用程序同时在集群上执行。\n\n由于亿亿次级计算节点的复杂性和应用程序的动态特性，最大限度地减少E级系统的能耗，其资源需求在执行期间会有所不同。在节点内，可以调整许多不同的资源，这些资源会影响计算效率，包括动态电压和频率调整（DVFS），多插槽和核心分配以及HyperThreads的使用。这些资源的最节能配置因不同的应用程序而异，甚至在单个应用程序中也会因多个阶段的过渡而变化。 \n\n本文提出了再运行时动态监控应用程序和系统的方法，利用机器学习分类来预测应用程序执行时最节能的资源设置。该方法有两个不同的优点。首先，它可以应用于新的应用程序而无需修改分类器或应用程序，因为它不需要应用程序级别的插桩或挂钩。其次，分类开销低，使其适合在计算节点上原位运行。本文首先评估了15种不同的分类技术，并在四插槽x86计算节点上利用21个常用HPC基准测试和协同设计应用程序测试了他们在正确获取的节能配置的能力。实验发现，由于基础系统的复杂性使得许多分类方法不适用于预测节能配置的问题，但少数方法很有希望。然后，本文选择原有的15个分类技术中的5个，并评估它们动态管理四个高性能基因组装配应用程序的能力。这些代表了一些计算密集度最高的生物信息学应用程序，最常用的应用程序仅在单个共享内存节点上运行。因此，有一些HPC系统，如NERSC-Genepool [36]，主要用于同时执行许多单节点应用，如基因组装配和比较分析。\n\n本文的评估提供以下见解。首先，选择一个能够处理观察到的运行时行为与能量系统设置的复杂非线性映射的分类器非常重要。与维持最高性能所需的策略相比，较差的分类可以导致能量消耗的非平凡增加，例如，在我们探索的一个案例中，增加22％。然而，鉴于一个非常强大的分类，所提议的方法平均减少20％的能量消耗 - 只比离线Oracle高出5.4％的能耗。我们计算将此行为扩展到过度配置的功率受限群集可以将总吞吐量提高24％。所有这些结果都是在没有应用程序的先验知识且没有应用程序级别的修改的情况下实现的。我们得出结论，通过部署机器学习分类器来动态调整资源使用情况，可以显着提高每焦耳的科学洞察力（scientific insight）。\n\n综上所述，本文的贡献如下：\n\n（1）提出优化能源效率而不是运行时间，以降低科学计算的成本。\n（2）建立了15种不同的机器学习分类技术评估的问题复杂性，只有一些适用于优化能源效率。\n（3）通过在运行时准确预测能量系统设置，证明有足够强大的分类器可以大大降低能耗。\n\n## 如何最大化能源效率\n\n集群能效可简单地定义为***每焦耳能量完成的应用比率***。如果每个应用程序执行代表某些科学洞察力单元，则该指标表示在运营成本（能源消耗）方面的科学洞察力的成本。因此，通过最小化应用能耗，最大化能效直接降低了科学洞察力的成本。然而，减少能量（Energy）消耗比简单地减少电功率（Power）更困难，因为***能量是时间和功率的乘积***，并且很难在不牺牲对方的情况下改善能量。例如，提高处理器速度通常会缩短应用程序运行时间，但必要的功率增加会导致能耗增加。简而言之，最大化能源效率并不意味着尽可能少地使用电力 - 这需要在执行时间和功耗之间进行最佳折中。\n\n最近的能量感知方法在保持应用性能的同时降低了能量。由于这些方法不以减少应用程序的速度为代价，因此它们通过降低功率来严格降低能耗。虽然通过简单地消除应用程序运行时的约束来最小化能耗是很诱人的，但是如果不考虑低功率资源设置对执行时间的影响可能导致更差的能量消耗。\n\nHPC集群中的典型资源管理方法主要是尝试优化应用程序完成时间，仅考虑功率消耗以达到不违反总集群功率约束的程度，并完全忽略能耗。虽然有各种技术可以将作业分配给节点，但通常可以通过尽可能快地运行各个计算节点来实现最小化其运行时间 - 这种方法我们称之为Race。使用Race方法使节点上的资源调度变得容易，但它不像能够理解系统配置如何在每个应用程序基础上最性能和功率进行折中的更智能的方法那样节能。原因是尽可能快地投入工作可以最大限度地缩短执行时间，但功率的增加使节省的时间相形见绌，从而导致高能耗。\n\n除了降低成本之外，最大化能效还将提高功率受限环境中的整体系统吞吐量。在过度配置（Over-provisioned）的集群中，如果节点在Race设置中运行，硬件可以消耗比基础设施实际提供给系统更多的总功率。优化能源效率可以提高总体集群吞吐量：（1）允许更多应用程序并行运行，因为每个应用程序的功耗较低，而（2）由于其对能耗的影响仍在考虑应用程序运行时间。因此，需要新的资源管理方法，即使整体运行时间增加，也只关注最小化能耗以降低科学成本（以焦耳为单位）。\n\n## 学习能源效率\n\n识别能量有效的资源设置组合具有挑战性，因为系统没有通用的最佳设置 - 它取决于应用程序及其配置，甚至根据不同的输入而变化。即使在具有均匀节点和完全均匀的应用行为的并行系统中，由于制造变化，最佳设置也会发生显着变化。此外，许多应用程序在执行期间通过不同的阶段进行。例如，应用程序可能在计算和内存密集型处理之间进行转换，从而导致最节能的设置在运行时期间发生变化。因此，在启动应用程序时静态选择单个设置并不是最佳选择，而是需要采用动态方法。\n\n本文探索了调整系统设置以最小化应用能耗的学习方法。具体来说，我们调整插槽（Socket）分配，使用HyperThreads和处理器DVFS。学习组件为这些资源的组合选择设置，使得在应用程序执行期间的任何时刻，系统都在其最节能的状态下运行。\n\n本文的目标是让学习器在不需要任何应用程序级别更改的情况下进行最节能的设置。因此，我们使用现有的硬件性能计数器作为特征（Features）。然后，学习器确定相应的函数来将这些特征的一些子集映射到最节能系统设置。但是，现代计算节点中的系统设置具有非常复杂的交互关系，因此尽管存在这种复杂性，但使用能够生成准确映射的学习机制至关重要。 \n\n{% asset_img Figure1.png [20] [20]%}\n\n我们只使用两个特征 - 性能计数器POWER_DRAM（内存使用量度量）和EXEC（CPU使用量度量）来简单地说明这种复杂性。图1a显示了关于标准化性能计数器值的训练数据（21个常见HPC基准）的行为。每个数据点是在我们的评估系统上以单一资源配置运行的训练应用程序的平均记录POWER_DRAM和EXEC行为。有88种独特的资源配置或可能的标签，它们考虑了Socket计数S的不同组合，是否使用了HyperThreads HT，以及DVFS频率（例如2.1 GHz）。属于特定应用的所有88个数据点被分配相同的标签 - 具有该应用的最佳能量效率的资源配置;即，应用程序的所有88个数据点具有相同的颜色。通过这种标记，一个好的学习器将识别次优行为并产生最节能的设置来代替使用。***问题显然很复杂，并没有出现直观的模式将CPU和内存使用情况映射到最节能的系统设置中***。\n\n为了成功地将这些特征映射到准确的预测中，学习器必须能够处理这种复杂性，而不是所有机器学习机制都可以。考虑图1b表示使用线性内核的支持向量机（SVM）分类器的准确性。阴影区域表示SVM分类器预测的标签（系统设置），在训练集上的召回率仅为45.6%，这清楚地表明该分类器没有效果。相比之下，图1c展示了一个具有径向基函数（RBF）内核的SVM，它可以实现71.0％的召回率，但可能还有进一步改进的余地。\n\n## 系统设置的分类\n\n我们建议在运行时预测能量有效设置，而不是在产生结果之前估计所有可能系统设置的行为。与许多先前在HPC系统中管理功率/能量的工作一样，我们使用硬件性能计数器来测量应用和系统行为。\n\n{% asset_img Figure2.png [20] [20]%}\n\n图2展示了我们提出的方法。当应用程序在计算节点上运行时，硬件性能计数器会在后台定期轮询。对于我们的实验，我们使用PCM工具收集性能计数器数据。对数据进行缩放，然后使用主成分分析（PCA）进行处理，以确定哪些特征与能量效率相关。我们还使用特征选择来限制分类器使用的硬件计数器的数量，以减少运行时开销。该分类器预测要使用的最节能的设置，然后在系统上启动。该过程在下一个间隔重复进行。\n\n####  训练数据\n\n在使用之前必须训练一个分类器。为了收集训练数据，我们通过在所有可能的设置中运行基准应用程序并收集硬件性能计数器结果来描述基准应用程序在目标平台上的行为。换句话说，如果存在N个不同的可接受的设置，则每个应用程序执行N次，或者在每个设置中执行一次。对于M训练应用，训练集中有$N\\times M$个特征向量。\n\n训练数据的获取可能非常耗时，但只需要对每个平台进行一次，并且可以通过缩短应用程序执行时间来在合理的时间内完成。选择能够代表将在系统上使用的应用程序的基准测试程序可以提高分类器在运行时期间准确预测设置的可能性。此外，应将训练集中的基准测试程序以不同的模式运行,以涵盖硬件计数器的各种可能的用例。\n\n应用能源效率（EE）定义为每单位能源（J）完成的工作量。一般而言，在我们的评估中，完整的应用程序执行是完成工作的度量。与许多使用性能计数器的先前工作一样，我们的分类器需要一种措施来量化运行时的应用程序进度。底层硬件性能计数器没有用于量化真实应用程序进度的指标（已完成工作），但先前的工作已成功使用系统执行的指令数量（INST）。一些先前的工作甚至试图仅测量那些被认为在测量应用程序进度中有用的指令，例如，忽略自旋锁或并行化/同步指令。使用INST是优化总应用能源效率的不完美解决方案，但正如实验评估所展示的那样，已经足够了。然后，该类别使用以下公式作为量化训练过程中的能量效率： \n$$\nEE=\\frac{INST}{J}\\tag{1}\n$$\n对于M个应用程序中的每一个程序，使用该应用程序的最节能设置来标记N个特征向量。因此，分类器学习有效和低效的行为，以便在观察到类似的运行时行为时产生一个有效的预测：\n$$\nFeatVec_{mn}\\mapsto \\underset{i\\in N}{\\arg max EE_i},    \\forall m\\in M, \\forall n\\in N\\tag{2}\n$$\n对于应用程序执行，总指令计数不是固定的 : 计数通常随着应用程序执行时间而增加，例如，由于诸如PCM或内核任务的后台进程。因此，重要的是要注意使用公式2标记最节能的配置。在计算能量效率时使用指令计数有两个原因：首先，可以在执行期间的任何时候量化能量，使其成为运行时行为分析的有用指标。第二，更重要的是，公式1是当时发生的事件的函数。总能量需要知道在应用程序执行期间将发生的所有事件，这就引入了一种可能性，即分类器可能正在学习关于应用程序输入的一些知识，而不是硬件事件与能量消耗对应的方式。利用指令数量有助于避免这种陷阱。\n\n#### 性能计数器\n\n性能计数器指标反映了不同层次粒度，即系统、插槽和核心。为简单起见，我们限制为系统范围的数据。表1列出了我们实验中所选择的性能计数器。\n\n{% asset_img Figure3.png [20] [20]%}\n\n性能计数器也会转换为采样速率（根据需要），这是为了在不缩放值的情况下改变采样间隔所必需的。因为我们使用PCM来收集性能计数器指标，所以我们读取的硬件计数器比我们处理的更多（表1）。实际上，现成的解决方案只能通过读取和处理所使用的性能计数器来减少开销。大多数先前的工作都积极地限制它们访问的硬件计数器，以减少采样开销并减少其模型中的计算。\n\n\n\n## 实验设计\n\n本节描述了我们的实验设置，包括评估系统，用于训练和评估的应用程序以及测试的分类算法。我们对四插槽，80-物理核心系统进行评估，其中512 GB DRAM运行Ubuntu Linux 14.04 LTS，内核为4.4.0。使用HyperThreads，有160个计算线程可用，即每个插槽上有20个物理线程和20个虚拟线程。\n\n#### 用于训练的应用程序\n\n> NAS Parallel Benchmarks [4], Lawrence Liver\u0002more Lab’s Co-design benchmarks (AMG [16], Kripke [27], LULESH[23], Quicksilver [29]), and Argonne’s CESAR Proxy-apps (XSBench [48], RSBench [47]). Other applications include CoMD [28], Berke\u0002ley’s HPGMG-FV [2], a partial diferential equation solver (jacobi), and STREAM [33].  \n\n#### 用于评估的应用程序\n\n> HipMer [14], IDBA [41], Megahit [30] and metaSPAdes [37]. \n\n这四种应用也可以被认为是更广泛的HPC应用的代表。它们实现复杂的管道，具有多个不同的阶段，需要不同的资源调整才能有效地运行 - 有些是计算密集型的，有些是I / O密集型的，有些是通信密集型的。确切地说，使用哪些阶段以及它们对性能的贡献程度在很大程度上取决于程序的配置和输入数据集。尽管他们正在解决同样的问题，但它们的实现方式却各不相同，有不同的编程语言，不同的算法和不同的数据低点。例如，HipMer最多可以有20个不同的阶段，而Megahit可能只有几个阶段。总的来说，这些应用程序提供了一系列不同的生物信息学方法的广泛覆盖（频率计数，图形遍历，对齐，排序等）。因此，这些应用程序是我们使用分类在运行时预测适当设置的方法的主要候选者。\n\n***与训练应用程序一样，我们将每个评估应用程序配置为使用160个线程运行，但使用80个线程的metaSPAdes除外。在实验中我们固定了应用程序的输入和配置，但它们支持各种配置和输入，这些配置和输入会影响性能和能耗行为。*** 为了获取实验中的评估基准，我们在每个DVFS设置中运行这些程序来获取DVFS特征，其中分配了所有160个虚拟核心（对于metaSPAdes，所有80个物理核心用作基线）。从这些结果我们得到了一个DVFS Oracle，它知道，对于每个应用程序，能量最有效的静态DVFS频率 - 每个应用程序都有不同的最节能的静态设置。另请注意，此数据不用于训练分类器。\n\n#### 分类算法\n\n实验中选择了15中算法用于训练，各个算法得到的召回率如图4所示。根据预测效果，选择了5种算法，\n\n* ET：一个极随机的决策树，类似于随机森林。\n* GB：在偏差损失函数的负梯度上拟合多个回归树。\n* KNN：训练数据中最近邻居的简单多数投票（默认情况下，k = 5）。\n* MLP：神经网络使用lbfgs，tanh激活函数和四层优化对数损失函数。\n* SVM：使用径向基函数（RBF）内核的最大边际分类。\n\n{% asset_img Figure4.png [20] [20]%}\n\n## 实验评估\n\n#### 减少能耗开销\n\n论文的实验，主要评估了五种分类算法和使用数据库Oracle的性能，如图5所示，该方法能够显著减少能耗开销。\n\n{% asset_img Figure5.png [20] [20]%}\n\n#### 预测间隔和特征选择\n\n该部分评估了不同间隔下该方法的性能，以及选择不同的特征下方法的性能。\n\n{% asset_img Figure6.png [20] [20]%}\n\n{% asset_img Figure7.png [20] [20]%}\n\n#### 方法本身的开销\n\n论文也剖析了该方法各个部分的开销。\n\n{% asset_img Figure8.png [20] [20]%}\n\n#### 使用不同的分类器\n\n对于不同部分的预测，使用不同的分类器，实验表明，对于使用单一的分类器，有的程序能达到很好的效果，而使用不同的分类器，在有的程序上能达到很好的效果，但是有的程序上，能耗开销会很大。\n\n{% asset_img Figure9.png [20] [20]%}","tags":["Papers","Energy Modeling","ICPP"]},{"title":"HPL参数优化","url":"/2019/07/31/HPL参数优化/","content":"### 1. 实验平台KNL配置\nIntel Xeon Phi Processor 7210 ( 16GB, 1.30 GHz, 64 core )\nProcessor name : Intel(R) Xeon Phi(TM) 7210\nPackages (sockets) : 1\nCores : 64\nProcessors (CPUs) : 256\nCores per package : 64\nThreads per core : 4\n\nRAM: 96GB\nMCDRAM: 16 GB\n\n理论峰值\n**n 1*64*1.3*32=2662.4 Gflops**\n\n### 2. HPL.dat文件中需要优化的参数\n\n```Bash\nHPLinpack benchmark input file\nInnovative Computing Laboratory, University of Tennessee\nHPL.out      output file name (if any)\n6            device out (6=stdout,7=stderr,file)\n1            # of problems sizes (N)\n50000 100000 150000 200000  Ns\n10            # of NBs\n1 2 4 8 16 32 64 128 256 512     NBs\n0            PMAP process mapping (0=Row-,1=Column-major)\n1            # of process grids (P x Q)\n1            Ps\n1            Qs\n16.0         threshold\n3            # of panel fact\n0 1 2        PFACTs (0=left, 1=Crout, 2=Right)\n2            # of recursive stopping criterium\n2 4          NBMINs (>= 1)\n1            # of panels in recursion\n2            NDIVs\n3            # of recursive panel fact.\n0 1 2        RFACTs (0=left, 1=Crout, 2=Right)\n1            # of broadcast\n0            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)\n1            # of lookahead depth\n0            DEPTHs (>=0)\n2            SWAP (0=bin-exch,1=long,2=mix)\n64           swapping threshold\n0            L1 in (0=transposed,1=no-transposed) form\n0            U  in (0=transposed,1=no-transposed) form\n1            Equilibration (0=no,1=yes)\n8            memory alignment in double (> 0)\n```\n\n***需要优化的主要有N，NB，PxQ等***\n\n### 3. 根据内存情况，获取理论最优的N值\n\n根据KNL的MCDRAM为16G，N*N*8=16G，得到N约为46000\n从46000左右开始设置N值，进行测试。\n\n* log信息提取命令\n\n```Bash\nawk -F: '/WR/' knl003_hpl.o31829 > 30000_128_8_8.log\n```\n* 阶段性结果\n\n|N|NB|Ps|Qs|Result（Gflops）|\n| ------ | ------ | ------ |--------|-----|\n|30000|\t128|\t8|\t16|\t9.435e+02|\n|30000\t|128\t|16\t|16\t|9.086e+01|\n|30000\t|256\t|8\t|16\t|6.042e+02|\n|35000\t|128\t|8\t|16\t|1.034e+03|\n|35000\t|64\t|8\t|16\t|8.820e+02|\n|35000\t|128\t|14\t|14\t|6.002e+02|\n|35000\t|128\t|1\t|128\t|6.019e+02|\n|35000\t|128\t|10\t|16\t|7.427e+02|\n|35000\t|128\t|8\t|8\t|1.149e+03|\n|35000\t|128\t|8\t|10\t|8.718e+02|\n|39200\t|128\t|8\t|8\t|1.227e+03|\n|39200\t|175\t|8\t|8\t|1.208e+03|\n|41600\t|128\t|8\t|8\t|1.074e+03|\n|32768\t|128\t|8\t|8\t|1.111e+03|\n\n\n更改运行脚本\n\n```Bash\n#!/usr/bin/bash\n \n \n#PBS -N knl003_hpl\n#PBS -l nodes=1,walltime=01:00:00\n \ncd /home/asc0146/haomeng/code/hpl/bin/Linux_Intel64/test1/\nexport KMP_AFFINITY=scatter,verbose\nexport OMP_NUM_THREADS=4\nexport MKL_NUM_THREADS=4\nmpiexec -np 64 ./xhpl | tee HPL.out\n```\n进行实验\n\n\n|N\t|NB|\tPs|\tQs|\tResult（Gflops）|\n|-----|-----|-----|-----|-----|\n|35000|\t128|\t8\t|8\t|效果很差|\n\n\n* 参数选择指导\n\n参考[Developer Guide for Intel](https://software.intel.com/en-us/mkl-linux-developer-guide-configuring-parameters).\nThe most significant parameters in HPL.dat are P, Q, NB, and N. Specify them as follows:\n\n  * P and Q - the number of rows and columns in the process grid, respectively.\nP*Q must be the number of MPI processes that HPL is using.\nChoose P ≤ Q.\n\n  * NB - the block size of the data distribution.\nThe table below shows recommended values of NB for different Intel® processors:\n{% asset_img HPL.png \"KNL推荐配置\" %}\n\n  * N - the problem size:\nFor homogeneous runs, choose N divisible by NB*LCM(P,Q), where LCM is the least common multiple of the two numbers.\nFor heterogeneous runs, see Heterogeneous Support in the Inte；l Optimized MP LINPACK Benchmark for how to choose N.\n\n***NOTE***\n\nIncreasing N usually increases performance, but the size of N is bounded by memory. In general, you can compute the memory required to store the matrix (which does not count internal buffers) as 8*N*N/(P*Q) bytes, where N is the problem size and P and Q are the process grids in HPL.dat. A general rule of thumb is to choose a problem size that fills 80% of memory. When offloading to Intel Xeon Phi coprocessors, you may choose a problem size that fills 70% of memory, to leave room for additional buffers needed for offloading. Choose N and NB such that N > > NB.\n\n* 最新优化情况\n\n    * 优化结果\n\n|N|\tNB|\tPs|\tQs\t|Result（Gflops）|\n|----|----|----|-----|-----|\n|3920\t|128\t|8\t|16\t|9.435e+02|\n","tags":["并行"]},{"title":"HPC性能评测","url":"/2019/07/31/HPC性能评测/","content":"高性能计算集群的性能评测大致分为机器级、算法级和程序级的性能评测。\n\n* 机器级\n\n\n机器级的性能评测主要包括CPU和存储器的某些基本性能指标、并行通讯开销以及机器的成本、价格和性/价比，有些是由厂商在销售时直接提供给用户的，是广大用户对并行计算机的第一印象，是引进和购买并行计算机时最主要的选择依据。\n\n\n\n* 算法级\n\n算法级的性能评测主要包括加速、效率和可扩展性等，最初是为了评价并行算法的性能提出的，用在并行机性能评测主要是测并行系统的加速比和可扩展性。并行系统的加速比是指对于一个给定的应用，并行算法（或并行程序）的执行速度相对于串行算法的执行速度加快了多少倍。***可扩展性是在确定的应用背景下，并行系统性能随处理器数的增加而按比例提高的能力***。\n\n* 程序级\n\n程序级的性能评测主要是使用一组基准测试来测试和评价并行系统的各种性能，包括基本测试、数学库测试和并行测试程序等。\n","tags":["并行"]},{"title":"并行程序性能分析软件（Extra-P和Score-P）安装过程","url":"/2019/07/31/并行程序性能分析软件（Extra-P和Score-P）安装过程/","content":"### Extra-P配置安装\n\n#### 安装位置\n* 实验室台式机虚拟机Ubuntukylin17.10\n\n#### 软件包依赖\n\n* QT4 或 QT5\n* Cube（>=4.3）\n* Python3\n* PyQT\n* MatPlotlib\n\n#### 安装过程\n\n* 安装Qt4或Qt5\n\n```Bash\nsudo apt-get install qt4-default\nsudo apt-get install qt5-default\nsudo apt-get install qt4-dev-tools\nsudo apt-get install qt5-dev-tools\n```\n\n* 安装python3\n\n```Bash\nsudo apt-get install python3\n```\n\n* 安装PyQt\n\n```Bash\nsudo apt-get install pyqt4-dev-tools\nsudo apt-get install pyqt5-dev-tools\n```\n\n* 安装Cube \n\n下载Cube源码包cube-4.3.tar.gz\n\n```Bash\n./configure\nmake\nmake all\n```\n\n使用QT5的话编译过程中会出现一些问题，选用Qt4能正常编译\n\n* 安装 MatPlotLib\n\n```Bash\nsudo apt-get install python3-pip\nsudo python -m pip install -U pip\nsudo python -m pip install -U matplotlib\n```\n\n#### 编译Extra-P\n\n```Bash\nmkdir build\ncd build\n../configure --with-cube=/opt/cube CPPFLAGS=\"-I/usr/include/python3.6m/\"\nmake\nmake install\n```\n\n### score-P配置安装\n\n```Bash\nmkdir build\ncd build\n../configure \nmake\nmake install\n```\n","tags":["并行"]},{"title":"LLVM入门学习","url":"/2019/07/31/LLVM入门学习/","content":"### 1. LLVM各工具使用\n\n* Convert C to IR\n\n```\nclang -emit-llvm -S multiply.c -o multiply.ll\n```\n\nOr\n\n```\nclang -cc1 -emit-llvm testfile.c -o testfile.ll\n```\n\nOr\n\n```\nclang test.c -S -emit-llvm -o test.ll\n```\n\n\n\n* Convert IR to bc\n\n```\nllvm-as test.ll –o test.bc\n```\n\n\n\n* Converting LLVM bitcode to target machine assembly\n\n```\nllc test.bc –o test.s\n```\n\nOr \n\n```\nclang -S test.bc -o test.s\n```\n\n\n\n* Converting bc to IR\n\n```\nllvm-dis test.bc –o test.ll\n```\n\n\n\n* Transforming LLVM IR\n\n```\nopt –passname input.ll –o output.ll\n```\n\n\n\n* Linking llvm bc\n\n```\nllvm-link test1.bc test2.bc –o output.bc\n```\n\n\n\n* Executing llvm bc\n\n```\nlli output.bc\n```\n\n\n\n\n\n### 2. IRBuilder\n\n可以批量的插入指令\n\n* 在之前前面插入指令\n\n```\nInstruction *pi = ...;\nIRBuilder<> Builder(pi);\nCallInst* callOne = Builder.CreateCall(...);\nCallInst* callTwo = Builder.CreateCall(...);\nValue* result = Builder.CreateMul(callOne, callTwo);\n```\n\n* 在基本块后面插入指令\n\n```\nBasicBlock *pb = ...;\nIRBuilder<> Builder(pb);\nCallInst* callOne = Builder.CreateCall(...);\nCallInst* callTwo = Builder.CreateCall(...);\nValue* result = Builder.CreateMul(callOne, callTwo);\n```\n\n但IRBuilder方法对于常数的指令会被优化掉\n\n\n\n### 3. 遍历Funciton或BasicBlock\n\n除了使用\n\n```\nfor(auto F=M.begin(),E=M.end();F!=E;F++)\n```\n\n还可以使用\n\n```\nfor(Module::iterator F = M.begin(), E = M.end();F!=E;++F)\n```\n\n注意，这块要使用比要得到的高一级的迭代器，即如果得到Function，则使用Module::iterator;\n\n如果得到BasicBlock，则使用Function::iterator\n\n如果遍历Instruction，可使用BasicBlock::iterator,或\n\n如果遍历Instruction的参数，可使用Instrunction::op_iterator\n\n* Function 中有一个函数size()，可以得到该函数中基本块的数量\n\n\n\n### 4. LLvm编译DEBUG版本的命令\n\n```\nexport CC=gcc\n\nexport CXX=g++\n\n./configure --prefix=/home/haomeng/.local --sysconfdir=/etc --enable-shared --enable-libffi --enable-targets=all --disable-expensive-checks --disable-assertions --with-binutils-include=/usr/include --with-python=/usr/bin/python2 --disable-optimized --enable-debug-runtime\n\nmake REQUIRES_RTTI=1 -j 60\n\nmake install\n\n```\n\n### 5. Pass\n\n在LLVM框架中，Pass用于对LLVM IR进行优化，对IR进行处理与分析，生成优化后的代码。`opt`命令可以用来运行pass对IR进行处理。\n\n优化类型\n\n* opt 自带的优化\n\n步骤如下：\n\n```\nclang -S -O0 -emit-llvm example.c\n\nopt -O0 -S example.ll\n\nopt -O1 -S example.ll\n\nopt -O2 -S example.ll\n\nopt -O3 -S example.ll\n\n为了能够看到opt所调用的优化Pass，可以加入参数\n\n--debug-pass=Structure\n\n```\n\n参考：http://llvm.org/docs/CommandGuide/opt.html \n\n\n\n* 自己写Pass进行优化\n\n参考：http://llvm.org/docs/WritingAnLLVMPass.html\n\n\n\n* 在一个Pass里面调用别的Pass\n\ngetAnalysis函数\n\n\n\n* 通过Pass manager 对Pass进行管理\n\n\n\n* Analysis Pass 分析IR但不对IR进行修改，其结果可以在多个Pass中使用，直到IR改变\n\n没有更改IR内容就返回false\n\n### 6. LLVM的Use-Def获取\nAlternatively, it’s common to have an instance of the User Class and need to know what Values are used by it. The list of all Values used by a User is known as a use-def chain. Instances of class Instruction are common User s, so we might want to iterate over all of the values that a particular instruction uses (that is, the operands of the particular Instruction):\n```\nInstruction *pi = ...;\n \nfor (Use &U : pi->operands()) {\n  Value *v = U.get();\n  // ...\n}\n\n```\n\n### 7. LLVM中Def-Use获取\nFrequently, we might have an instance of the Value Class and we want to determine which Users use the Value. The list of all Users of a particular Value is called a def-use chain. \n\n* 函数的def-use\n\n```\nFunction *F = ...;\n \nfor (User *U : F->users()) {\n  if (Instruction *Inst = dyn_cast<Instruction>(U)) {\n    errs() << \"F is used in instruction:\\n\";\n    errs() << *Inst << \"\\n\";\n  }\n```\n或者\n```\nFunction *F = ...;\nfor (Value::use_iterator U = F->use_begin(), e = F->use_end(); U != e; ++U) {\n  if (Instruction *Inst = dyn_cast<Instruction>(&*(U->getUser()))) {\n    errs() << \"F is used in instruction:\\n\";\n    errs() << *Inst << \"\\n\";\n}\n```\n\n* 指令的Def-Use\n```\nInstruction *A = ...;\n \nfor (User *U : A->users()) {\n  if (Instruction *Inst = dyn_cast<Instruction>(U)) {\n    errs() << \"A is used in instruction:\\n\";\n    errs() << *Inst << \"\\n\";\n  }\n```\n或\n```\nInstruction *A = ...;\nfor (Value::use_iterator i = A->use_begin(), e = A->use_end(); i != e; ++i) {\n  if (Instruction *U = dyn_cast<Instruction>(&*(i->getUser()))) {\n  ...\n  }\n}\n```\n\n### 8. 遍历LLVM IR指令的操作数\n\n通过User中提供的op_iterator迭代器来遍历Instruction中的操作数\n```\nInstruction* V = ...\nfor (User::op_iterator op = V->op_begin(), e = V->op_end(); op != e; ++op){\n    if (Instruction *U = dyn_cast<Instruction>(op->get())) {\n...\n    }\n}\n```\n\n### 9. 获取Basic Block的前驱基本块\nLLVM已经提供了遍历基本块的所有前驱的函数\n```\nBasicBlock* B = ...\nfor (auto it = pred_begin(B), et = pred_end(B); it != et; ++it)\n{\n  BasicBlock* predecessor = *it;\n  ...\n}\n```","tags":["LLVM"]},{"title":"物理CPU和逻辑CPU的区别","url":"/2019/07/31/物理CPU和逻辑CPU的区别/","content":"A physical core is what it sounds like - an actual physical processor core in your CPU. Each physical core has its own circuitry and its own L1 (and usually L2) cache can read and execute instructions separately (for the most part) from the other physical cores on the chip.\n\nA logical core is more of a programming abstraction than an actual physical entity. A simple definition of a logical core is that it is a processing unit that is capable of executing its own thread in parallel with other logical cores. In fact you could say that a logical core is the same as a thread.\n\nYou can have multiple logical cores per physical core. However logical cores share resources with other logical cores operating on the same physical core, so having more logical cores will not necessarily get you the same performance increase as having more physical cores.\n\nIn the case of intel hyperthreading (HT), you have two logical cores per physical core, so a quad-(physical) core i7 processor will have eight logical cores. However the two logical cores within one physical core cannot truly operate in parallel with respect to each other. This is because HT works by having one logical core operate while the other logical core is waiting and has nothing to do (for example when it is waiting on a cache or memory fetch).\n\nWell then how can these logical cores be considered in parallel? Well most of the time they can be because during typical CPU operation you will almost never see continuous execution of a single thread on every clock cycle - there are always gaps when one logical core is waiting for something and the second logical core can kick in and do its job.","tags":["CPU"]},{"title":"PAPI安装问题","url":"/2019/07/31/PAPI安装问题/","content":"### 解决方法\nIt seems kernel didn't let me access to performance events because of security reasons. You have to set that.\n(由于安全原因，似乎内核不允许访问性能事件,必须对它进行设置)\n\n```shell\nsudo sh -c 'echo -1 >/proc/sys/kernel/perf_event_paranoid'\n```\n","tags":["PAPI","RAPL"]},{"title":"PAPI安装RAPL模块","url":"/2019/07/31/PAPI安装RAPL模块/","content":"### Configuring PAPI to support RAPL\nWhen configuring PAPI, you need to provide the --with-components=rapl option. Basically, you need to install PAPI like this:\n```\n$ tar xzvf papi-5.3.2.tar.gz\n$ cd papi-5.3.2/src\n$ ./configure --with-components=rapl &&make &&make install\n```\n### Checking the PAPI installation\nOnce PAPI is installed, make sure it is capable of reading RAPL information. For instance, you can run this [rapl-read](http://eztrace.gforge.inria.fr/tutorials/tutorial_rapl/rapl-read.tgz) program. You may need to modify the `Makefile` in order to specify the installation directory of PAPI. Once compiled, running the `rapl-read` program should result in the following output:\n\n```Bash\n$ ./rapl_plot\nFound rapl component at cid 2\nFound: rapl:::THERMAL_SPEC_CNT:PACKAGE0\nFound: rapl:::MINIMUM_POWER_CNT:PACKAGE0\nFound: rapl:::MAXIMUM_POWER_CNT:PACKAGE0\nFound: rapl:::MAXIMUM_TIME_WINDOW_CNT:PACKAGE0\nFound: rapl:::PACKAGE_ENERGY_CNT:PACKAGE0\nFound: rapl:::PP1_ENERGY_CNT:PACKAGE0\nFound: rapl:::DRAM_ENERGY_CNT:PACKAGE0\nFound: rapl:::PP0_ENERGY_CNT:PACKAGE0\nFound: rapl:::THERMAL_SPEC:PACKAGE0\nFound: rapl:::MINIMUM_POWER:PACKAGE0\nFound: rapl:::MAXIMUM_POWER:PACKAGE0\nFound: rapl:::MAXIMUM_TIME_WINDOW:PACKAGE0\nFound: rapl:::PACKAGE_ENERGY:PACKAGE0\nFound: rapl:::PP1_ENERGY:PACKAGE0\nFound: rapl:::DRAM_ENERGY:PACKAGE0\nFound: rapl:::PP0_ENERGY:PACKAGE0\n[...]\n4.7213 0.0 (* Average Power for rapl:::MAXIMUM_TIME_WINDOW:PACKAGE0 *)\n4.7213 3.0 (* Average Power for rapl:::PACKAGE_ENERGY:PACKAGE0 *)\n4.7213 0.2 (* Average Power for rapl:::PP1_ENERGY:PACKAGE0 *)\n4.7213 0.8 (* Average Power for rapl:::DRAM_ENERGY:PACKAGE0 *)\n4.7213 0.1 (* Average Power for rapl:::PP0_ENERGY:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::THERMAL_SPEC_CNT:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::MINIMUM_POWER_CNT:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::MAXIMUM_POWER_CNT:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::MAXIMUM_TIME_WINDOW_CNT:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::PACKAGE_ENERGY_CNT:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::PP1_ENERGY_CNT:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::DRAM_ENERGY_CNT:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::PP0_ENERGY_CNT:PACKAGE0 *)\n4.8218 46156882941.9 (* Average Power for rapl:::THERMAL_SPEC:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::MINIMUM_POWER:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::MAXIMUM_POWER:PACKAGE0 *)\n4.8218 0.0 (* Average Power for rapl:::MAXIMUM_TIME_WINDOW:PACKAGE0 *)\n4.8218 2.9 (* Average Power for rapl:::PACKAGE_ENERGY:PACKAGE0 *)\n4.8218 0.2 (* Average Power for rapl:::PP1_ENERGY:PACKAGE0 *)\n4.8218 0.8 (* Average Power for rapl:::DRAM_ENERGY:PACKAGE0 *)\n```\n### Can't open fd for cpu0: No such file or director\nHowever, You may have the following error:\n```\n$ ./rapl_plot\nFound rapl component at cid 2\nNo rapl events found: Can't open fd for cpu0: No such file or director\n```\nThis usually means that the msr kernel module that permits to read the energy counters is not loaded. This should be fixed by running modprobe:\n```\n$ sudo modprobe msr\n```\n### Can't open fd for cpu0: Operation not permitted\nAnother possible error is:\n```\n$  ./rapl_plot\nFound rapl component at cid 2\nNo rapl events found: Can't open fd for cpu0: Operation not permitted\n```\nIn that case, you may have to run the program as sudo:\n```\n$ sudo ./rapl_plot\n[...]\n```\n","tags":["RAPL"]},{"title":"RAPL介绍","url":"/2019/07/31/RAPL介绍/","content":"### 介绍RAPL的链接 \n\n1. RUNNING AVERAGE POWER LIMIT， https://01.org/zh/blogs/2014/running-average-power-limit-%E2%80%93-rapl?langredirect=1 \n\n2. Reading RAPL energy measurements from Linux, http://web.eece.maine.edu/~vweaver/projects/rapl/index.html \n \n3. Energy measurements in Linux，https://blog.chih.me/read-cpu-power-with-RAPL.html \n \n4. Intel® Power Governor, https://software.intel.com/en-us/articles/intel-power-governor\n","tags":["RAPL"]},{"title":"OpenMP编译成LLVM IR","url":"/2019/07/29/OpenMP编译成LLVM-IR/","content":"\nhttps://clang-omp.github.io/\n\n# 介绍\n\n目前clang/llvm编译器已经支持OpenMP，目前，OpenMP 3.1已经被clang/llvm 3.7完全支持。\n\n# 方法\n\n这是一个openmp程序\n\n```\n\n#include <omp.h>\n\n#include <stdio.h>\n\nint main() {\n\n#pragma omp parallel\n\nprintf(\"Hello from thread %d, nthreads %d\\n\", omp_get_thread_num(), omp_get_num_threads());\n\n}\n\n```\n\n将更改程序转化为相应的IR代码：\n\n```\n\nclang -fopenmp -emit-llvm -S test.c -o test.ll\n\n```\n\nIR代码如下：\n\n```\n\n; ModuleID = 'test.bc'\n\ntarget datalayout = \"e-m:e-i64:64-f80:128-n8:16:32:64-S128\"\n\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n%ident_t = type { i32, i32, i32, i32, i8* }\n\n@.str = private unnamed_addr constant [35 x i8] c\"Hello from thread %d, nthreads %d\\0A\\00\", align 1\n\n@.str.1 = private unnamed_addr constant [23 x i8] c\";unknown;unknown;0;0;;\\00\", align 1\n\n@0 = private unnamed_addr constant %ident_t { i32 0, i32 2, i32 0, i32 0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.1, i32 0, i32 0) }, align 8\n\n; Function Attrs: nounwind uwtable\n\ndefine i32 @main() #0 {\n\n  call void (%ident_t*, i32, void (i32*, i32*, ...)*, ...) @__kmpc_fork_call(%ident_t* @0, i32 0, void (i32*, i32*, ...)* bitcast (void (i32*, i32*)* @.omp_outlined. to void (i32*, i32*, ...)*))\n\n  ret i32 0\n\n}\n\n; Function Attrs: nounwind uwtable\n\ndefine internal void @.omp_outlined.(i32* noalias %.global_tid., i32* noalias %.bound_tid.) #0 {\n\n  %1 = alloca i32*, align 8\n\n  %2 = alloca i32*, align 8\n\n  store i32* %.global_tid., i32** %1, align 8\n\n  store i32* %.bound_tid., i32** %2, align 8\n\n  %3 = call i32 @omp_get_thread_num()\n\n  %4 = call i32 @omp_get_num_threads()\n\n  %5 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str, i32 0, i32 0), i32 %3, i32 %4)\n\n  ret void\n\n}\n\ndeclare i32 @printf(i8*, ...) #1\n\ndeclare i32 @omp_get_thread_num() #1\n\ndeclare i32 @omp_get_num_threads() #1\n\ndeclare void @__kmpc_fork_call(%ident_t*, i32, void (i32*, i32*, ...)*, ...)\n\nattributes #0 = { nounwind uwtable \"disable-tail-calls\"=\"false\" \"less-precise-fpmad\"=\"false\" \"no-frame-pointer-elim\"=\"true\" \"no-frame-pointer-elim-non-leaf\" \"no-infs-fp-math\"=\"false\" \"no-nans-fp-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+fxsr,+mmx,+sse,+sse2\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\n\nattributes #1 = { \"disable-tail-calls\"=\"false\" \"less-precise-fpmad\"=\"false\" \"no-frame-pointer-elim\"=\"true\" \"no-frame-pointer-elim-non-leaf\" \"no-infs-fp-math\"=\"false\" \"no-nans-fp-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+fxsr,+mmx,+sse,+sse2\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\n\n!llvm.ident = !{!0}\n\n!0 = !{!\"clang version 3.8.0-2ubuntu4 (tags/RELEASE_380/final)\"}\n\n```\n\n其中***mpc_fork_call***是OpenMP定义的运行时函数，用来生成线程池，每个线程将执行函数***omp_outlined***中的代码，该函数的代码就是对应并行域中的代码。\n\n\n{% asset_img example1.png [20] [10]%}\n\nOver!!!!\n","tags":["LLVM"]},{"title":"LLVM Pass工程建立过程","url":"/2019/07/29/LLVM-Pass工程建立过程/","content":"一般的Pass工程建立方法需要利用LLVM源码目录进行编译，本文介绍了另一种Pass工程建立和编译方法，与cmake相结合进行Pass编译。\n### 1. 环境安装\n* 安装LLVM和clang编译器\n\n```Bash\nsudo apt-get install clang\nsudo apt-get install clang++\nsudo apt-get install llvm\n```\n### 2. LLVM Pass工程目录\n该测试工程LLVM_Test主要包含两个文件夹cmake和src，其具体文件组织形式如下图所示。**需要注意的是，利用该工程编译Pass时只需要在src目录下添加相应的Pass源码即可，其他文件不需要修改**。\n{% asset_img example1.png %}\n\n\n具体内容如下：\n* cmake目录中的FindLLVM.cmake\n\n```Bash\n# - Find LLVM \n# This module can be used to find LLVM.\n# It requires that the llvm-config executable be available on the system path.\n# Once found, llvm-config is used for everything else.\n#\n# The following variables are set:\n#\n# LLVM_FOUND                 - Set to YES if LLVM is found.\n# LLVM_VERSION               - Set to the decimal version of the LLVM library.\n# LLVM_INCLUDE_DIRS          - A list of directories where the LLVM headers are located.\n# LLVM_LIBRARY_DIRS          - A list of directories where the LLVM libraries are located.\n# LLVM_LIBRARIES             - A list of libraries which should be linked\n# LLVM_DYNAMIC_LIBRARY       - A single dynamic llvm shared library\n# LLVM_DYNAMIC_LIBRARY_FOUND - Whether found the dynamic llvm shared library\n# LLVM_OPT                   - opt program in llvm\n# \n# Using Following macros to set static library:\n# llvm_map_components_to_libraries(OUTPUT_VARIABLE ${llvm components})\n# \n# tutorial:\n#   1.  select default LLVM version:\n#       cmake .. -DLLVM_RECOMMEND_VERSION=\"3.5\"\n#   2.  set include dir and link dir:\n#       include_directories(${LLVM_INCLUDE_DIRS})\n#       link_directories(${LLVM_LIBRARY_DIRS})\n#   3.a link static libraries:\n#       llvm_map_components_to_libraries(LLVM_IRREADER_LIRARY irreader)\n#       target_link_libraries(target\n#           ${LLVM_LIBRARIES}\n#           ${LLVM_IRREADER_LIRARY}\n#           )\n#   3.b link a dynamic library:\n#       target_link_libraries(target ${LLVM_DYNAMIC_LIBRARY}) \n#\n# 14-10-26: \n#    LLVM_RECOMMAND_VERSION --> LLVM_RECOMMEND_VERSION\n#    update tutorial\n# \n# version: 0.9.1\n#    add LLVM_FLAGS_NDEBUG means llvm build with NDEBUG\n#\n# version: 0.9\n#    remove LLVM_{C/CPP/CXX}_FLAGS which import -DNDEBUG\n#\n#\nif(NOT DEFINED LLVM_RECOMMEND_VERSION)\n   set(LLVM_RECOMMEND_VERSION \"\" CACHE STRING \"Switch the llvm version\")\n   set_property(CACHE LLVM_RECOMMEND_VERSION PROPERTY STRINGS \"\" \"3.4\" \"3.5\" \"3.9\")\nendif()\n\n\nif(NOT(DEFINED LLVM_ROOT) )\n\tif(NOT \"${LLVM_VERSION}\" EQUAL \"{LLVM_RECOMMEND_VERSION}\")\n\t\tunset(LLVM_CONFIG_EXE CACHE)\n\t\tunset(LLVM_DYNAMIC_LIBRARY CACHE)\n\tendif()\n\t# find llvm-config. perfers to the one with version suffix, Ex:llvm-config-3.2\n\tfind_program(LLVM_CONFIG_EXE NAMES \"llvm-config-${LLVM_RECOMMEND_VERSION}\" \"llvm-config\")\n   find_program(LLVM_OPT NAMES \"opt-${LLVM_RECOMMEND_VERSION}\" \"opt\")\n\n\tif(NOT LLVM_CONFIG_EXE)\n\t\tset(LLVM_FOUND False)\n      message(FATAL_ERROR \"Not Found LLVM (LLVM_RECOMMEND_VERSION=${LLVM_RECOMMEND_VERSION})\")\n\telse()\n\t\tset(LLVM_FOUND True)\n\tendif()\n\n\t# Get the directory of llvm by using llvm-config. also remove whitespaces.\n\texecute_process(COMMAND ${LLVM_CONFIG_EXE} --prefix OUTPUT_VARIABLE LLVM_ROOT\n\t\tOUTPUT_STRIP_TRAILING_WHITESPACE )\n\nendif()\n\nmacro(_llvm_config _var_name)\n    execute_process(COMMAND ${LLVM_CONFIG_EXE} ${ARGN} \n        OUTPUT_VARIABLE ${_var_name}\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n        )\nendmacro()\n\nset(LLVM_INSTALL_PREFIX  ${LLVM_ROOT})\nadd_definitions(-D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS)\n\n_llvm_config(LLVM_VERSION --version)\nSTRING(REGEX REPLACE \"^([0-9]+)\\\\.[0-9]+(svn)?\\\\.?[0-9]*\" \"\\\\1\" LLVM_VERSION_MAJOR \"${LLVM_VERSION}\")\nSTRING(REGEX REPLACE \"^[0-9]+\\\\.([0-9]+)(svn)?\\\\.?[0-9]*\" \"\\\\1\" LLVM_VERSION_MINOR \"${LLVM_VERSION}\")\n_llvm_config(LLVM_LD_FLAGS --ldflags)\n_llvm_config(LLVM_LIBRARY_DIRS --libdir)\n_llvm_config(LLVM_INCLUDE_DIRS --includedir)\nstring(REGEX MATCH \"-l.*\" LLVM_LIBRARIES ${LLVM_LD_FLAGS})\n_llvm_config(LLVM_C_FLAGS --cflags)\nif(LLVM_C_FLAGS MATCHES \"-DNDEBUG\")\n   add_definitions(-DLLVM_FLAGS_NDEBUG)\nendif()\n\nfind_library(LLVM_DYNAMIC_LIBRARY \n\tNAMES \"LLVM\" \"LLVM-${LLVM_VERSION}\"\n   PATHS ${LLVM_LIBRARY_DIRS}\n   )\n\nif(NOT LLVM_DYNAMIC_LIBRARY)\n\tset(LLVM_DYNAMIC_LIBRARY_FOUND False)\nelse()\n\tset(LLVM_DYNAMIC_LIBRARY_FOUND True)\nendif()\n\nmacro(llvm_map_components_to_libraries _var_name)\n    _llvm_config(${_var_name} --libs \"${ARGN}\")\nendmacro()\n\nmessage(STATUS \"Found LLVM Version ${LLVM_VERSION} \")\n\n```\n* 主目录的CMakeLists.txt\n\n```\ncmake_minimum_required(VERSION 2.8)\nproject(Test)\n\nset(CMAKE_MODULE_PATH \n   ${CMAKE_MODULE_PATH}\n   ${CMAKE_SOURCE_DIR}/cmake\n   )\n\nif(NOT CMAKE_BUILD_TYPE)\n   set(CMAKE_BUILD_TYPE \"Release\")\nendif()\n\nfind_package(LLVM)\n\nadd_subdirectory(src)\n```\n* src目录中的CMakeLists.txt\n\n```\naux_source_directory(. DIR_SRCS)\ninclude_directories(\n\t${LLVM_PROF_INCLUDE_DIRS}\n\t${PROJECT_BINARY_DIR}\n\t${LLVM_INCLUDE_DIRS} \n   ../include\n\t)\nlink_directories(\n   ${LLVM_LIBRARY_DIRS} \n   )\n\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wall --std=c++11 -fno-rtti\")\nset(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -DNO_DEBUG\")\nset(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG}\")\n\nadd_library(Test SHARED\n\t${DIR_SRCS}\n\t)\n\ntarget_link_libraries(Test\n\t${LLVM_DYNAMIC_LIBRARY}\n\t)\n\n```\n* src中的FunctionTest.cpp文件是LLVM Pass的一个示例，在该目录中可以编写相应的Pass\n\n```c++\n#include <llvm/Pass.h>\n#include <llvm/IR/Function.h>\n#include <llvm/IR/Module.h>\n#include <llvm/IR/Instructions.h>\n#include <llvm/IR/Constants.h>\n#include <llvm/Support/raw_ostream.h>\n#include <llvm/IR/InstIterator.h>\n#include <llvm/IR/Operator.h>\n#include <llvm/Analysis/AliasAnalysis.h>\nusing namespace llvm;\nnamespace{\n    class MyTest:public FunctionPass\n    {\n        public:\n            static char ID;\n            MyTest():FunctionPass(ID){}\n            bool runOnFunction(Function &F) override;\n    };\n}\nchar MyTest::ID = 0;\nstatic RegisterPass<MyTest> X(\"MyTest\",\"My Test\",false,false);\nbool MyTest::runOnFunction(Function &F) {\n\n    Function *tmp = &F;\n    errs()<<tmp->getName()<<\"\\n\";\n    // 遍历函数中的所有基本块\n    for (Function::iterator bb = tmp->begin(); bb != tmp->end(); ++bb) {\n        // 遍历基本块中的每条指令\n        for (BasicBlock::iterator inst = bb->begin(); inst != bb->end(); ++inst) {\n            if (inst->isBinaryOp()) {\n\t\t\terrs()<<*inst<<\"\\n\";\n            }\n        }\n    }\n\n    return false;\n}\n\n```\n\n### 3. 编译过程\n\n```\ncd LLVM_Test/\nmkdir build\ncd build/\ncmake ..\nmake\n```\n编译出来的.so文件在LLVM_Test/build/src目录下。具体过程如下图所示：\n{% asset_img example2.png %}\n\n### 4. Pass调用\n利用该工程编译之后，我们就可以调用相应的Pass了，具体调用过程如下：\n\n```\nopt -load LLVM_Test/build/src/libTest.so -MyTest test.ll \n```\n","tags":["LLVM"]}]